<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>SDE：重新理解DDPM和SMLD</title>
    <link href="/2025/03/25/SDE%20diffusion/"/>
    <url>/2025/03/25/SDE%20diffusion/</url>
    
    <content type="html"><![CDATA[<p>参考资料：</p><ul><li><a href="https://spaces.ac.cn/archives/9209">生成扩散模型漫谈（五）：一般框架之SDE篇</a></li><li><a href="https://arxiv.org/abs/2403.18103">Tutorial on Diffusion Models for Imaging and Vision</a></li></ul><span id="more"></span><h1 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h1><p>通常来说，初次接触DDPM是一个让人困惑的事情，因为似乎有许多不太一样的扩散模型，他们和DDPM的区别有些难以捉摸。这对于一个想要构建起知识体系的学习者来说是糟糕的。因此，通过SDE阐述扩散模型的方法非常值得学习，它提供了一个更一般的视角，使我们不必再依赖各种各样的直觉。</p><p>让我们先从扩散模型的前向过程开始：</p><script type="math/tex; mode=display">x_t = \sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\epsilon_t,</script><p>这是一个迭代方程，每一个新的状态都是基于上一个状态进行更新的。这类型（即迭代）的方程通常可以和<strong>常微分方程</strong>（ODE）——即未知函数只包含一个自变量的微分方程——联系起来。例如，考虑一个最简单的匀速直线运动，每隔时间 $\Delta t$ 更新一次位移，则</p><script type="math/tex; mode=display">S_{t+1}=S_t + \Delta S,</script><p>其中 $\Delta S$ 是一个常数。这个方程也可以写成连续的形式：</p><script type="math/tex; mode=display">\frac{S(t+\Delta t) - S(t)}{\Delta t} = \frac{\Delta S}{\Delta t}=v,</script><p>当 $\Delta t\rightarrow 0$ 时，方程写作 $\mathrm{d}S/\mathrm{d}t=v$ 。虽然这个例子有些过于简单，但是足够了。</p><p>同理，既然扩散过程也是迭代，是否可以被写成微分方程？由于扩散过程具有随机性，需要借助<strong>随机微分方程</strong>（SDE）。</p><h1 id="随机微分方程"><a href="#随机微分方程" class="headerlink" title="随机微分方程"></a>随机微分方程</h1><p>为了假装比较专业，我们先从一些标准形式开始。首先是常微分方程：</p><script type="math/tex; mode=display">\mathrm{d}x = f(t, x)\mathrm{d}t</script><p>其中 $x$ 是关于 $t$ 的函数。常微分方程表明函数的导数不仅与自变量 $t$ 有关，还和当前函数值 $x(t)$ 有关。仅此而已。</p><p>这个函数是确定性的，如果再加一个随机项：</p><script type="math/tex; mode=display">\begin{equation}\label{continuous SDE}\mathrm{d}x = f(t, x)\mathrm{d}t + g(t, x) \mathrm{d}w,\end{equation}</script><p>这就得到了随机微分方程，其中 $\xi(t)$ 是一个噪声函数。此外，这里的 $w$ 是<strong>布朗运动</strong>，它满足以下性质：</p><ul><li>初始条件：$w(0)=0$</li><li>独立增量：对于任意 $0\le t<em>1 &lt; t_2 &lt; \cdots &lt; t_n$ ，布朗运动的增量 $w(t_2-t_1), w(t_3-t_2),\cdots,w(t_n-t</em>{n-1})$ 是相互独立的。</li><li>增量正态分布： 对于任意 $t$ 和 $\Delta t&gt;0$ ，布朗运动的增量服从均值为 $0$ ，方差为 $\Delta t$ 的正态分布：</li></ul><script type="math/tex; mode=display">w(t+\Delta t) - w(t) \sim \mathcal{N}(0, \Delta t).</script><ul><li>连续性：布朗运动是连续的，没有跳跃。</li></ul><p>根据增量正态分布的性质，可以得到 $\mathrm{d}w\sim\mathcal{N}(0, \mathrm{d}t)$ ，理论上与 $\xi(t)\sqrt{\mathrm{d}t}$ 同分布。这就是为什么将离散SDE写作</p><script type="math/tex; mode=display">\begin{equation}\label{discrete SDE}x_{t+\Delta t} - x_t = f(t, x_t)\Delta t + g(t, x_t) \sqrt{\Delta t} \epsilon, \qquad \epsilon\sim \mathcal{N}(0, \mathbf{I}).\end{equation}</script><p>这里我们不推导其与微分形式$\eqref{continuous SDE}$的等价性，因为常规的微分方法其实不适用于布朗运动（微分的方差无穷大），这一块我就完全不懂了。</p><h1 id="前向过程"><a href="#前向过程" class="headerlink" title="前向过程"></a>前向过程</h1><p>下面我们尝试将前向过程写成SDE的形式。为了将其连续化，首先定义一个连续的噪声表，步长 $\Delta t= 1/N$ ，因此 $\beta(\frac{t}{N})=\beta_t$ 。此外，为了统一自变量的范围，规定 $\beta(t/N)= \beta(t)/N = \beta(t)\Delta t$ 。</p><p>从常规的迭代公式开始，</p><script type="math/tex; mode=display">x_t = \sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}\epsilon_{t-1},</script><p>我们代入连续的噪声表：</p><script type="math/tex; mode=display">x_t = \sqrt{1-\beta\left(\frac{t}{N}\right)}x_{t-1} + \sqrt{\beta\left(\frac{t}{N}\right)} \epsilon_{t-1},</script><p>同样，其它变量也变成连续形式：</p><script type="math/tex; mode=display">x(t+\Delta t) = \sqrt{1-\beta(t)\Delta t}x(t) + \sqrt{\beta(t)\Delta t} \epsilon(t),</script><p>下面做一些近似：</p><script type="math/tex; mode=display">x(t+\Delta t) \approx \left(1-\frac{1}{2}\beta(t)\Delta t\right)x(t) + \sqrt{\beta(t)\Delta t} \epsilon(t),</script><p>整理得到：</p><script type="math/tex; mode=display">x(t+\Delta t)-x(t) \approx -\frac{1}{2}\beta(t)\Delta tx(t) + \sqrt{\beta(t)}\sqrt{ \Delta t}\epsilon(t),</script><p>这就得到了离散SDE形式。我们将其转换为连续的：</p><script type="math/tex; mode=display">\begin{equation}\label{foward diffusion SDE}\mathrm{d}x = -\frac{1}{2}\beta(t)x\Delta t + \sqrt{\beta(t)}\mathrm{d}w, \end{equation}</script><p>即 $f(x,t)=-\frac{1}{2}\beta(t)x, \quad g(x, t)= \sqrt{\beta(t)}$ 。</p><h1 id="逆向随机微分方程"><a href="#逆向随机微分方程" class="headerlink" title="逆向随机微分方程"></a>逆向随机微分方程</h1><p>任何SDE都有一个相应的逆向SDE。了解这一点其实也就足够了，可以直接跳到结果部分。下面给出一个逆向过程的推导，参考<a href="https://spaces.ac.cn/archives/9209">生成扩散模型漫谈（五）：一般框架之SDE篇</a>。</p><p>对于一般形式$\eqref{continuous SDE}$的SDE，我们可以将其写成Diffusion中条件概率的形式：</p><script type="math/tex; mode=display">p(x_{t+\Delta t}|x_t) = \mathcal{N}\left(x_t+f(t, x)\Delta t, g^2(t, x)\Delta t\right)</script><p>为了寻求逆分布，我们也采用DDPM中相同的推导方式，即贝叶斯定理：</p><script type="math/tex; mode=display">p(x_t|x_{t+\Delta t}) = \frac{p(x_{t+\Delta t}|x_t)p(x_t)}{p(x_{t+\Delta t})}=p(x_{t+\Delta t}|x_t)\exp\left(\log p(x_t) - \log p(x_{t+\Delta t})\right)</script><p>代入高斯分布得：</p><script type="math/tex; mode=display">p(x_t|x_{t+\Delta t}) \propto \exp\left(-\frac{\|x_{t+\Delta t}-x_t-f(x, t)\Delta t\|^2}{2g^2(x,t)\Delta t} + \log p(x_t) - \log p(x_{t+\Delta t})\right)</script><p>由于我们关心的是 $\Delta t\rightarrow 0$ 的情形，可以将 $\log p(x_{t+\Delta t})$ 展开：</p><script type="math/tex; mode=display">\log p(\boldsymbol{x}_{t+\Delta t})\approx \log p(\boldsymbol{x}_t) + (\boldsymbol{x}_{t+\Delta t} - \boldsymbol{x}_t)\cdot \nabla_{\boldsymbol{x}_t}\log p(\boldsymbol{x}_t) + \Delta t \frac{\partial}{\partial t}\log p(\boldsymbol{x}_t)</script><p>代入得：</p><script type="math/tex; mode=display">p(x_t|x_{t+\Delta t}) \propto \exp\left(-\frac{\|x_{t+\Delta t}-x_t-f(x, t)\Delta t\|^2}{2g^2(x,t)\Delta t} - (x_{t+\Delta t} - x_t)\cdot \nabla_{x_t}\log p(x_t) - \Delta t \frac{\partial}{\partial t}\log p(x_t)\right)</script><p>将 $(x<em>{t+\Delta t} - x_t)\cdot \nabla</em>{x_t}\log p(x_t)$ 合并到前面的分子中，并省去 $\Delta t$ 的二次项，可得</p><script type="math/tex; mode=display">\begin{aligned} p(x_t|x_{t+\Delta t}) \propto&\, \exp\left(-\frac{\Vert x_{t+\Delta t} - x_t - \left[f(x_t, t) - g(x_t, t)^2\nabla_{x_t}\log p(x_t) \right]\Delta t\Vert^2}{2 g(x_t, t)^2\Delta t}\right) \\ \approx&\,\exp\left(-\frac{\Vert x_t - x_{t+\Delta t} + \left[f_{t+\Delta t}(x_{t+\Delta t}) - g_{t+\Delta t}^2\nabla_{x_{t+\Delta t}}\log p(x_{t+\Delta t}) \right]\Delta t\Vert^2}{2 g_{t+\Delta t}^2\Delta t}\right) \end{aligned}</script><p>换回到SDE的形式，可得</p><script type="math/tex; mode=display">x_t = x_{t+\Delta t} - \left[f_{t+\Delta t}(x_{t+\Delta t}) - g^2(x_{t+\Delta t}, t+\Delta t)\nabla_{x_{t+\Delta t}}\log p(x_{t+\Delta t}) \right]\Delta t - g(x_{t+\Delta t}, t+\Delta t)\sqrt{\Delta t}\epsilon.</script><p>注意等式右边不包含 $x<em>t$，因为我们必须用 $x</em>{t+\Delta t}$ 来导出 $x_t$ 。对于微分形式，则全部都用 $x$ 即可：</p><script type="math/tex; mode=display">\begin{equation}\label{reverse SDE}\mathrm{d}x = \left[f(x, t)-g^2(x, t)\nabla_{x}\log p(x)\right]\mathrm{d}t + g(x, t)\mathrm{d}w. \end{equation}</script><p>注意这里等式右边的符号。反向过程和 $\mathrm{d}x$ 的方向是相反的，所以右边又反转了一次正负号。</p><h1 id="反向去噪"><a href="#反向去噪" class="headerlink" title="反向去噪"></a>反向去噪</h1><p>结合前向过程的SDE形式$\eqref{foward diffusion SDE}$以及标准的反向SDE方程$\eqref{reverse SDE}$ ，可以给出DDPM反向去噪的SDE方程：</p><script type="math/tex; mode=display">\begin{equation}\label{reverse diffusion continuous SDE}\mathrm{d}x = -\beta(t)\left[\frac{x}{2}+\nabla_{x}\log p(x)\right]\mathrm{d}t + \sqrt{\beta(t)}\mathrm{d}w.\end{equation}</script><p>实际应用时，回到离散的形式：</p><script type="math/tex; mode=display">\begin{equation}\label{reverse diffusion discrete SDE}x_{t} - x_{t+\Delta t} =-\beta(t+\Delta t)\left[\frac{x_{t+\Delta t}}{2}+\nabla_{x_{t+\Delta t}}\log p(x_{t+\Delta t})\right]\Delta t + \sqrt{\beta(t+\Delta t)}\sqrt{\Delta t}\epsilon_t.\end{equation}</script><p>这个式子中未知的部分是 $\nabla<em>{x</em>{t+\Delta t}}\log p(x_{t+\Delta t})$ ，也就是SMLD中的<strong>分数</strong>。这里做一个前情提要（其实是我自己忘记了）：</p><ul><li>SMLD的核心思想是通过预测对数似然函数的梯度 $\nabla_x\log p(x)$，然后利用朗之万方程（带有随机项的梯度下降）从分布中采样。</li><li>为了实现对分数的预测，需要用到分数匹配的技术。其中最流行的是去噪分数匹配，通过构建条件分布的分数来监督神经网络。</li><li>在推理过程中，采用退火采样，在初期用较大的噪声采样，后期用较小的噪声，避免在初期陷入低密度区域（预测不准），导致错误的结果。</li></ul><p>如果我们沿着$\eqref{reverse diffusion discrete SDE}$推导出离散的反向过程，会发现它和DDPM完全一致，这当然符合我们的预期：从前向过程推导出$f$ 和 $g$ ，然后应用到逆向SDE的公式中，应当符合反向过程的SDE。这被称为<strong>方差保留</strong>（VP）SDE。</p><p>另一方面，SMLD中的反向过程并不是这么做的，说明其前向应当也是不一样的。在SMLD中并没有真正意义上定义过前向过程，因为它是直接从高斯分布出发的。但注意到它在训练时采用了一系列噪声尺度 $\sigma_i(i=1,2,\dots,N)$ ，我们可以手动给出一个马尔科夫链：</p><script type="math/tex; mode=display">x_t = x_{t-1} + \sqrt{\sigma^2_t-\sigma^2_{t-1}}\epsilon_{t-1}.</script><p>这使得当 $x<em>{t-1}$ 的方差为 $\sigma</em>{t-1}$ 时，$x_t$ 的方差为 $\sigma_t$ 。我们同样可以根据这个式子，导出其SDE形式。根据</p><script type="math/tex; mode=display">x(t+\Delta t) = x(t) + \sqrt{\sigma(t+\Delta t)^2 - \sigma(t)^2}\epsilon_t，</script><p>当 $\Delta t\rightarrow 0$ 时，有</p><script type="math/tex; mode=display">x(t+\Delta t) = x(t) +  \sqrt{\frac{\mathrm{d[\sigma(t)^2]}}{\mathrm{d}t}\Delta t} \epsilon_t，</script><p>因此 $f(x, t)=0, g(x,t)= \sqrt{\frac{\mathrm{d[\sigma(t)^2]}}{\mathrm{d}t}}$ ，则SDE为：</p><script type="math/tex; mode=display">\mathrm{d}x = \sqrt{\frac{\mathrm{d[\sigma(t)^2]}}{\mathrm{d}t}}\mathrm{d}w.</script><p>紧接着，直接导出反向SDE：</p><script type="math/tex; mode=display">\mathrm{d}x = -\left[\frac{\mathrm{d[\sigma(t)^2]}}{\mathrm{d}t}\nabla_{x}\log p(x)\right]\mathrm{d}t +\sqrt{\frac{\mathrm{d[\sigma(t)^2]}}{\mathrm{d}t}}\mathrm{d}w.</script><p>将 $\frac{\mathrm{d[\sigma(t)^2]}}{\mathrm{d}t}$ 简记为 $\alpha(t)$ ，则有</p><script type="math/tex; mode=display">\mathrm{d}x = -\alpha(t)\nabla_{x}\log p(x)\mathrm{d}t +\sqrt{\alpha(t)}\mathrm{d}w.</script><p>我们就得到了<strong>朗之万方程</strong>，由此验证SMLD也可以表达为SDE以及逆向SDE。</p>]]></content>
    
    
    
    <tags>
      
      <tag>神经网络</tag>
      
      <tag>Diffusion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>持久同调性简介</title>
    <link href="/2024/10/16/%E6%8C%81%E4%B9%85%E5%90%8C%E8%B0%83%E6%80%A7%E7%AE%80%E4%BB%8B/"/>
    <url>/2024/10/16/%E6%8C%81%E4%B9%85%E5%90%8C%E8%B0%83%E6%80%A7%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<p>这篇笔记从单纯复形开始，经过同调群、贝蒂数以及过滤等概念，给出了持久同调性的概念和计算方法。其中的主要内容基于ETH的课堂笔记 <a href="https://ti.inf.ethz.ch/ew/courses/TDA24/Script.pdf">TDA24/Script.pdf</a> ，同时添加了一些结论的证明过程（如有关欧拉-庞加莱公式的证明）和对原文中不甚清晰的部分的进一步说明，这使得它可能是目前最简明的有关持久同调的中文笔记。</p><p>完全理解这些内容需要一些抽象代数（同态基本定理）和拓扑学（同胚、度量空间）的基础，但他们不会花费太久的时间。如果不是有志于专业的数学，拓扑数据分析（TDA）不需要全面地掌握某一学科，这使得我们可以快速地理解和使用它。</p><p>TDA对于我来说是一个完全陌生的领域，并且我没有接受过任何指导或训练，因此笔记中可能包含不准确的地方（尤其是其中的练习）。但我相信这是一个好的开始。</p><span id="more"></span><div>  <iframe src="/pdfjs/web/viewer.html?file=/pdf/持久同调性简介.pdf" width="100%" height="1000px" frameborder="0"></iframe></div> ]]></content>
    
    
    
    <tags>
      
      <tag>数学笔记</tag>
      
      <tag>拓扑数据分析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>交换代数笔记</title>
    <link href="/2024/05/06/%E4%BA%A4%E6%8D%A2%E4%BB%A3%E6%95%B0/"/>
    <url>/2024/05/06/%E4%BA%A4%E6%8D%A2%E4%BB%A3%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>交换代数笔记，作者陶安博。</p><span id="more"></span><div>  <iframe src="/pdfjs/web/viewer.html?file=/pdf/commutative algebra.pdf" width="100%" height="1000px" frameborder="0"></iframe></div> ]]></content>
    
    
    
    <tags>
      
      <tag>数学笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VAE 和 DDPM ：证据下界</title>
    <link href="/2024/05/05/DDPM/"/>
    <url>/2024/05/05/DDPM/</url>
    
    <content type="html"><![CDATA[<p>从证据下界出发将VAE和Diffusion Model相联系，是一个常见的思路，也是两者主要的相似之处：同属于近似似然模型。似然模型通过（近似）最大似然直接学习分布的概率密度（或质量）函数，而近似似然模型通过某种变分方法或马尔可夫链来近似估计目标分布。在这里，近似值就是证据下界。</p><span id="more"></span><h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>在没有输入条件的情况下，生成式模型的目标是从通过一个网络，将一个随机分布变换为另一个分布，并使得该分布与特定的数据分布（图像，点云）尽可能得相近。</p><p><img src="/2024/05/05/DDPM/1714744539507.png" alt="神经网络拟合数据分布" style="zoom:30%;display: block; margin-left: auto; margin-right: auto;"></p><p>设数据分布为 $p<em>{\text{data}}(x)$ ，神经网络学习到的分布为 $p</em>{\theta}(x)$ ，神经网络中的可学习参数为 $\theta$ ，我们需要衡量两个分布的相似性。根据最大似然，我们从 $p_{\text{data}}(x)$ 中采样一系列数据</p><script type="math/tex; mode=display">\left\{x^1,x^2,\dots,x^m\right\},</script><p>则目标为最大化 $p_{\theta}(x^i)$ ，即</p><script type="math/tex; mode=display">\theta^* = \arg \max_{\theta} \prod_{i=1}^{m}p_{\theta}(x).</script><p>改写为对数似然</p><script type="math/tex; mode=display">\theta^* = \arg \max_{\theta}\log\left( \prod_{i=1}^{m}p_{\theta}(x)\right)=\arg\max_{\theta}\sum_{i=1}^{m}\log p_{\theta}(x^i).</script><p>根据大数定律，我们可以将上式进一步表达为期望的形式</p><script type="math/tex; mode=display">\theta^* =\arg\max_{\theta}\sum_{i=1}^{m}\log\left(p_{\theta}(x^i)\right)\approx \arg\max_{\theta}\mathbb{E}_{x\sim p_{\text{data}}}[\log p_{\theta}(x)]=\arg\max_{\theta}\int_{x}p_{\text{data}}(x)\log p_{\theta}(x)dx.</script><p>我们将其减去一个 $\theta$ 无关的量，则其等价于最小化两个分布的 KL 散度。</p><script type="math/tex; mode=display">\begin{aligned}\theta^* = \arg\max_{\theta}\int_{x}p_{\text{data}}(x)\log p_{\theta}(x)dx-\int_{x}p_{\text{data}}(x)\log p_{\text{data}}(x)dx\\=\arg\max_{\theta}\int_{x}p_{\text{data}}(x)\log \frac{p_{\theta}(x)}{p_{\text{data}}(x)}dx=\arg\min_{\theta}\text{KL}(p_{data}\| p_{\theta}).\end{aligned}</script><h1 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h1><p>AE 的思想是：通过一个 Encoder 将原始数据编码，然后用一个 Decoder 将其解码。而 VAE 进一步要求中间的潜在变量服从简单的高斯分布。VAE 的两端是同一个数据，也即所谓“自编码”。其工作流程大概是：通过一个 Encoder 将原始数据送到一个高斯分布，并要求该高斯分布与标准正态分布接近。然后从该分布中随机采样，输入到 Decoder 中，恢复出原始数据。通过适当的训练，编码器能够将原始数据映射到服从标准高斯分布的潜在空间，而解码器能够从中预测合适的数据分布。</p><p><img src="/2024/05/05/DDPM/1_ET6FM_KEmwa2N4qgW2MglQ.png" alt="VAE架构" style="zoom:35%;display: block; margin-left: auto; margin-right: auto;"></p><p>VAE 的假设就是 code 服从标准高斯分布，因此包含两个损失：一个是解码后的重建损失，度量解码结果和原始结果的相似性；另一个是编码分布和标准高斯分布的相似性，即 KL 散度。下面将更具体地推导为什么这两个损失能够实现生成式模型的目标。</p><p>通过一个 Decoder $D$ 学习数据分布，其输入为服从简单先验分布的随机变量 $z$ ，输出为接近数据分布的 $x$ 。为了定义损失函数，我们需要计算 $p_{\theta}(x)$ ，可以表示为</p><script type="math/tex; mode=display">p_{\theta}(x)=\int_z p(z)p_{\theta}(x|z)dz.</script><p>其中 $p(z)$ 已知，而 $p<em>{\theta}(x|z)$ 是较难计算的，且对参数 $\theta$ 不可导。为了计算便利，我们假设预测值实际上是高斯分布的均值，则 $p</em>\theta(x|z)$ 可以近似表示为以 $G(z)$ 为均值的高斯分布上的概率。 即</p><script type="math/tex; mode=display">p_{\theta}(x|z)\propto \exp(-\|G(z)-x\|_2).</script><p>这种技巧也叫重参数化（或随机反向传播），保证了梯度的传播。</p><p><img src="/2024/05/05/DDPM/1714746405676.png" alt="重参数化使得梯度能够反向传播" style="zoom:30%;display: block; margin-left: auto; margin-right: auto;"></p><p>然而在实际计算时，我们没有办法直接最大化 $p_{\theta}(x)$ ，因为积分操作是难以实现的。取而代之的是最大化它的证据下界（Evidence lower bound，ELBO）。具体来说，我们可以定义任意一个分布 $q(\cdot|x)$ ，它都会满足</p><script type="math/tex; mode=display">\int_z q(z|x)dz =1,</script><p>从而引出下面的等式</p><script type="math/tex; mode=display">\log p_\theta(x) = \log p_{\theta}(x)\int_z q(z|x)dz=\int_z q(z|x)\log p_{\theta}(x)dz.</script><p>根据贝叶斯定理，$p<em>{\theta}(z, x) =p</em>{\theta}(z|x)\cdot p_\theta(x)$ ，因此</p><script type="math/tex; mode=display">\log p_\theta(x) =\int_z q(z|x)\log\left(\frac{p_{\theta}(z, x)}{p_{\theta}(z|x)}\right)dz.</script><p>我们对原式进行放缩得到</p><script type="math/tex; mode=display">\begin{aligned}\log p_\theta(x) &=\int_z q(z|x)\log\left(\frac{p_{\theta}(z, x)}{q(z|x)}\frac{q(z|x)}{p_{\theta}(z|x)}\right)dz\\&=\int_z q(z|x)\log\left(\frac{p_{\theta}(z, x)}{q(z|x)}\right)dz+\int_z q(z|x)\log\left(\frac{q(z|x)}{p_{\theta}(z|x)}\right)dz\\&=\int_z q(z|x)\log\left(\frac{p_{\theta}(z, x)}{q(z|x)}\right)dz+\text{KL}(q(z|x)\|p_{\theta}(z|x)).\end{aligned}</script><p>KL 散度是恒大于等于零的，可以由 $\log$ 函数放缩来证明：设有两个概率分布 $f(x),g(x)$ ，则</p><script type="math/tex; mode=display">\begin{aligned}\text{KL}(f(x)\|g(x)) &= \int_xf(x)\log\left(\frac{f(x)}{g(x)}\right)dx\\&=-\int_xf(x)\log\left(\frac{g(x)}{f(x)}\right)dx\\&\ge -\int_xf(x)\left(\frac{g(x)}{f(x)}-1\right)dx\\&=-\int_x\left[g(x)-f(x)\right]dx=0\end{aligned}</script><p>因此 $\text{KL}(q(z|x)|p_{\theta}(z|x)) \ge 0$ ，则</p><script type="math/tex; mode=display">\log p_{\theta}(x) \ge \int_z q(z|x)\log\left(\frac{p_{\theta}(z, x)}{q(z|x)}\right)dz=\mathbb{E}_{q(z|x)}\left[\log\left(\frac{p_{\theta}(z,x)}{q(z|x)}\right)\right]=L_b</script><p>因为 $\log p<em>\theta(x)$ 实际上只与 $p</em>\theta(x|z)$ 有关，即只与解码器有关，而与编码器无关。因此我们可以通过调整 $q(z|x)$ ，使其与后验分布 $p<em>\theta(z|x)$ 相同，此时 $\log p</em>\theta(x)=L<em>b$ 。因此当解码器不变时，最大化 $L_b$ 也就是等价于最小化 $\text{KL}(q(z|x)|p</em>{\theta}(z|x))$ 。即最大化 $L_b$ 。而 $q(z|x)$ 实际上就是 VAE 的 Encoder。</p><p>下面求解 $L_b$ 的最大化。我们将其拆成两部分：</p><script type="math/tex; mode=display">\begin{aligned}L_b&=\int_z q(z|x)\log\left(\frac{p_{\theta}(z, x)}{q(z|x)}\right)dz= \int_z q(z|x)\log\left(\frac{p_{\theta}(x|z)p_\theta(z)}{q(z|x)}\right)dz\\&= \int_z q(z|x)\log\left(\frac{p_\theta(z)}{q(z|x)}\right)dz+ \int_z q(z|x)\log p_{\theta}(x|z)dz\\&=-\text{KL}(q(z|x)\| p_\theta(z)) +  \int_z q(z|x)\log p_{\theta}(x|z)dz.\end{aligned}</script><p>最大化 $L<em>b$ 首先要最小化第一项，也就是要求 $q(z|x)$ 接近于先验分布 $p</em>{\theta}(z)$ （实际上，这里 $p_\theta(z)=p(z)$ ，因为 $z$ 的选取与 $\theta$ 无关）。其次要最大化第二项，其本质是重建损失，即通过 VAE 后输入和输出的相似性。模型最终回归到了机器学习中常见的形式：重建损失+正则项。</p><h1 id="DDPM"><a href="#DDPM" class="headerlink" title="DDPM"></a>DDPM</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>去噪扩散概率模型（Denoising Diffusion Probabilistic Models，DDPM）的思想是：首先定义一个前向扩散过程，其含义是不断向原始数据 $x<em>0$ 添加高斯噪声，得到 $x</em>{0:T}$ 。然后定义一个 Denoise 模块，其作用是输入当前图像 $x<em>t$ 和步骤 $t$ ，输出图像中包含的噪声，并与 $x_t$ 相加得到 $x</em>{t-1}$ ，以此类推，就可以从噪声中恢复原始图像。</p><p><img src="/2024/05/05/DDPM/1714823867081.png" alt="去噪过程" style="zoom:60%;display: block; margin-left: auto; margin-right: auto;"></p><p>值得注意的是，在整个链条中，每个 Denoise 模块是完全一样的，这也是为什么我们需要输入额外的步骤值 $t$ 。而为了降低网络拟合的难度，Denoise 不直接产生 $x<em>{t-1}$ ，而是预测 $x_t$ 中包含的噪声，即 $x</em>{t}-x_{t-1}$ 。通过学习这样一个去噪过程，DDPM 能够从任意一个高斯噪声中恢复具有高真实度的图像。如果是为了 text to image 或其它任务，只需要在 Denoise 的输入中增加一个额外的条件输入。当然，实际上的去噪模块和下图中还有些不同，这也会得到详细说明。</p><p><img src="/2024/05/05/DDPM/1714824422281.png" alt="去噪模块" style="zoom:30%;display: block; margin-left: auto; margin-right: auto;"></p><p>假设原始数据分布为 $q(x_0)$ ，总步骤数为 $T$，添加的噪声为 $\epsilon \sim \mathcal{N}(0,\mathbf{I})$ ，下面给出 DDPM 训练和推理的步骤及原理。</p><h2 id="前向扩散过程"><a href="#前向扩散过程" class="headerlink" title="前向扩散过程"></a>前向扩散过程</h2><p><img src="/2024/05/05/DDPM/1714828330773.png" alt="前向扩散过程" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>首先从原始数据分布中采样一个数据 $x_0\sim q(x_0)$ ，也就是一张干净的图像。我们需要往其中不断地加入噪声。正式地，我们定义这一过程为，</p><script type="math/tex; mode=display">q(x_t|x_{t-1}):=\mathcal{N}(x_{t};\sqrt{1-\beta_t}x_{t-1},\beta_t\mathbf{I}).</script><p>其含义是根据预定义的权重 $\beta<em>t$ ，我们将 $\sqrt{1-\beta_t}x</em>{t-1}$  作为均值，$\sqrt{\beta_t}$ 作为标准差，定义了一个新的高斯分布，也就是 $x_t$ 服从的分布。这也可以写成更直观的形式：</p><script type="math/tex; mode=display">x_t = \sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta_t}\epsilon,\ \epsilon\sim \mathcal{N}(0,\mathbf{I}).</script><p>在原来的理解中，前向扩散需要不断地向数据中添加噪声，有些繁琐。但实际上，我们可以通过重参数来解决这一点。令 $\alpha_t=1-\beta_t$ ，则</p><script type="math/tex; mode=display">x_t = \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_{t-1}.</script><p>我们将 $x_{t-1}$ 继续拆开，</p><script type="math/tex; mode=display">\begin{aligned}x_t &= \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_t}\epsilon_{t-1}\\&=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}\epsilon_{t-2}+\sqrt{1-\alpha_t}\epsilon_{t-1}.\end{aligned}</script><p>根据高斯分布的再生性，我们可以合并后面两项得到</p><script type="math/tex; mode=display">\begin{aligned}x_t &=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_t\alpha_{t-1}}\overline\epsilon_{t-2}.\end{aligned}</script><p>我们会发现该形式和前面保持了一致。换言之，添加两次噪声可以用添加一次噪声来表示，那么同理，添加 $T$ 次噪声也是一样的。继续迭代，得到</p><script type="math/tex; mode=display">x_t =\sqrt{\alpha_t\alpha_{t-1}\cdots\alpha_{1}}x_{0}+\sqrt{1-\alpha_t\alpha_{t-1}\cdots\alpha_{1}}\overline\epsilon=\sqrt{\overline\alpha_t}x_{0}+\sqrt{1-\overline\alpha_t}\epsilon.</script><p>这也解释了为什么要用 $\sqrt{\beta_t}$ 的形式而非 $\beta_t$ ：带了根号的形式优雅地合并了所有步骤。因为 $\beta_t\in[0,1]$ ，$\overline\alpha_t$ 是递减的，所以随着 $t$ 的增大，原始数据权重越来越小，噪声权重越来越大，这实现了前向扩散的目标。</p><h2 id="反向扩散过程"><a href="#反向扩散过程" class="headerlink" title="反向扩散过程"></a>反向扩散过程</h2><p>反向过程的目标是学习上述过程的逆过程 $q(x_{t-1}|x_t)$。和 VAE 一样，首先我们需要知道优化的目标。在 VAE 中，我们知道</p><script type="math/tex; mode=display">\log p_{\theta}(x) \ge \mathbb{E}_{q(z|x)}\left[\log\left(\frac{p_{\theta}(z,x)}{q(z|x)}\right)\right],</script><p>将这里的编码器 $q(z|x)$ 替换成前向过程 $q(x_{1:T}|x_0)$ ，则有</p><script type="math/tex; mode=display">\log p_{\theta}(x_0) \ge \mathbb{E}_{q(x_{1:T}|x_0)}\left[\log\left(\frac{p_{\theta}(x_{1:T},x)}{q(x_{1:T}|x_0)}\right)\right]=\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log\left(\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}\right)\right],</script><p>令</p><script type="math/tex; mode=display">L=-\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log\left(\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}\right)\right]=\mathbb{E}_{q(x_{1:T}|x_0)}\left[\log\left(\frac{q(x_{1:T}|x_0)}{p_{\theta}(x_{0:T})}\right)\right]</script><p>经过一些推导，可以将上式分解为一系列项：</p><script type="math/tex; mode=display">\begin{aligned}L&= \mathbb{E}_{q( x_{0:T})} \Big[ \log\frac{q( x_{1:T}\vert x_0)}{p_\theta( x_{0:T})} \Big] \\&= \mathbb{E}_q \Big[ \log\frac{\prod_{t=1}^T q( x_t\vert x_{t-1})}{ p_\theta( x_T) \prod_{t=1}^T p_\theta( x_{t-1} \vert x_t) } \Big] \\&= \mathbb{E}_q \Big[ -\log p_\theta( x_T) + \sum_{t=1}^T \log \frac{q( x_t\vert x_{t-1})}{p_\theta( x_{t-1} \vert x_t)} \Big] \\&= \mathbb{E}_q \Big[ -\log p_\theta( x_T) + \sum_{t=2}^T \log \frac{q( x_t\vert x_{t-1})}{p_\theta( x_{t-1} \vert x_t)} + \log\frac{q( x_1 \vert  x_0)}{p_\theta( x_0 \vert  x_1)} \Big] \\&= \mathbb{E}_q \Big[ -\log p_\theta( x_T) + \sum_{t=2}^T \log \Big( \frac{q( x_{t-1} \vert  x_t,  x_0)}{p_\theta( x_{t-1} \vert x_t)}\cdot \frac{q( x_t \vert  x_0)}{q( x_{t-1}\vert x_0)} \Big) + \log \frac{q( x_1 \vert  x_0)}{p_\theta( x_0 \vert  x_1)} \Big] \\&= \mathbb{E}_q \Big[ -\log p_\theta( x_T) + \sum_{t=2}^T \log \frac{q( x_{t-1} \vert  x_t,  x_0)}{p_\theta( x_{t-1} \vert x_t)} + \sum_{t=2}^T \log \frac{q( x_t \vert  x_0)}{q( x_{t-1} \vert  x_0)} + \log\frac{q( x_1 \vert  x_0)}{p_\theta( x_0 \vert  x_1)} \Big] \\&= \mathbb{E}_q \Big[ -\log p_\theta( x_T) + \sum_{t=2}^T \log \frac{q( x_{t-1} \vert  x_t,  x_0)}{p_\theta( x_{t-1} \vert x_t)} + \log\frac{q( x_T \vert  x_0)}{q( x_1 \vert  x_0)} + \log \frac{q( x_1 \vert  x_0)}{p_\theta( x_0 \vert  x_1)} \Big]\\&= \mathbb{E}_q \Big[ \log\frac{q( x_T \vert  x_0)}{p_\theta( x_T)} + \sum_{t=2}^T \log \frac{q( x_{t-1} \vert  x_t,  x_0)}{p_\theta( x_{t-1} \vert x_t)} - \log p_\theta( x_0 \vert  x_1) \Big] \\&= \mathbb{E}_q [\underbrace{D_\text{KL}(q( x_T \vert  x_0) \parallel p_\theta( x_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q( x_{t-1} \vert  x_t,  x_0) \parallel p_\theta( x_{t-1} \vert x_t))}_{L_{t-1}} \underbrace{- \log p_\theta( x_0 \vert  x_1)}_{L_0} ]\end{aligned}</script><p>这个过程实际上就是把第 0 项、第 $T$ 项和中间项拆分开了，得到了 $L<em>T,L</em>{t-1}$ 和 $L<em>0$ 。而重要的是，$L_T$ 是一个常数，因为 $x_0$ 是已知图像，$x_T$ 是纯噪声。$L_0$ 同样可以视作已知项。而 $L</em>{t-1}$ 中的 KL 散度直接将 $p<em>\theta(x</em>{t−1}|x<em>t)$ 与前向过程后验 $q( x</em>{t-1} \vert  x_t,  x_0)$ 进行比较。这也和 VAE 的结果是相当类似的。</p><p>让我们进一步处理这个前向过程后验。应用贝叶斯定理，</p><script type="math/tex; mode=display">q(x_{t-1} \vert x_t, x_0) =\frac{q(x_t,x_0, x_{t-1})}{q(x_t,x_0)}=\frac{q(x_t|x_{0},x_{t-1})q(x_0,x_{t-1})}{q(x_t,x_0)}= q(x_t \vert x_{t-1}, x_0) \frac{ q(x_{t-1} \vert x_0) }{ q(x_t \vert x_0) } .</script><p>得益于重参数化的结果， $x<em>t$ 可以用 $x</em>{t-1}$ 表示，也可以用 $x_0$ 表示，并且他们都是正态分布，可以直接得到概率密度的表达式 $\exp \left(-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}\right)$。因此有</p><script type="math/tex; mode=display">\begin{aligned}q(x_t|x_{t-1},x_0)&\propto \exp \left(-\frac{1}{2}\frac{(x_t-\sqrt{\alpha_t}x_{t-1})^2}{\beta_t}\right),\\q(x_{t-1}|x_0)&\propto \exp \left(-\frac{1}{2}\frac{( x_{t-1} - \sqrt{\bar{\alpha}_{t-1}}  x_0)^2}{1-\bar{\alpha}_{t-1}}\right),\\q(x_{t}|x_0)&\propto \exp \left(-\frac{1}{2}\frac{( x_{t} - \sqrt{\bar{\alpha}_{t}}  x_0)^2}{1-\bar{\alpha}_{t}}\right).\end{aligned}</script><p>代入并整理同类项，得到</p><script type="math/tex; mode=display">\begin{aligned}q(x_{t-1} \vert x_t, x_0) &= q(x_t \vert x_{t-1}, x_0) \frac{ q(x_{t-1} \vert x_0) }{ q(x_t \vert x_0) } \\&\propto \exp \Big(-\frac{1}{2} \big(\frac{( x_t - \sqrt{\alpha_t}  x_{t-1})^2}{\beta_t} + \frac{( x_{t-1} - \sqrt{\bar{\alpha}_{t-1}}  x_0)^2}{1-\bar{\alpha}_{t-1}} - \frac{( x_t - \sqrt{\bar{\alpha}_t}  x_0)^2}{1-\bar{\alpha}_t} \big) \Big) \\&= \exp \Big(-\frac{1}{2} \big(\frac{ x_t^2 - 2\sqrt{\alpha_t}  x_t \color{blue}{ x_{t-1}} \color{black}{+ \alpha_t} \color{red}{ x_{t-1}^2} }{\beta_t} + \frac{ \color{red}{ x_{t-1}^2} \color{black}{- 2 \sqrt{\bar{\alpha}_{t-1}}  x_0} \color{blue}{ x_{t-1}} \color{black}{+ \bar{\alpha}_{t-1}  x_0^2}  }{1-\bar{\alpha}_{t-1}} - \frac{( x_t - \sqrt{\bar{\alpha}_t}  x_0)^2}{1-\bar{\alpha}_t} \big) \Big) \\&= \exp\Big( -\frac{1}{2} \big( \color{red}{(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}})}  x_{t-1}^2 - \color{blue}{(\frac{2\sqrt{\alpha_t}}{\beta_t}  x_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}}  x_0)}  x_{t-1} \color{black}{ + C( x_t,  x_0) \big) \Big)}\end{aligned}</script><p>其中 $C(x<em>t,x_0)$ 是与 $x</em>{t-1}$ 无关的部分。由于这个分布还是高斯分布，我们可以求取它的均值和方差：</p><script type="math/tex; mode=display">\begin{aligned}\mu_t =&\frac{1}{2}\frac{\frac{2\sqrt{\alpha_t}}{\beta_t}  x_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}}  x_0}{\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}}=\beta_t\frac{\frac{\sqrt{\alpha_t}}{\beta_t}  x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}}  x_0}{\alpha_t + \frac{\beta_t}{1 - \bar{\alpha}_{t-1}}}\\=&\beta_t\frac{\frac{\sqrt{\alpha_t}}{\beta_t}  x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}}  x_0}{ \frac{\alpha_t-\bar{\alpha_t}+\beta_t}{1 - \bar{\alpha}_{t-1}}}=\beta_t\frac{\frac{\sqrt{\alpha_t}}{\beta_t}  x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}}  x_0}{ \frac{1-\bar{\alpha_t}}{1 - \bar{\alpha}_{t-1}}}\\=& \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha_t}}x_t + \frac{\beta_t\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha_t}}x_0.\\\\\sigma_t =& 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) = 1/(\frac{\alpha_t - \bar{\alpha}_t + \beta_t}{\beta_t(1 - \bar{\alpha}_{t-1})})= \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t}\beta_t\end{aligned}</script><p>出人意料的整齐的形式，可以理解为 $x_t$ 和 $x_0$ 的某种插值。或者说，<strong>在已知 $x_0$ 的情况下，逆向过程是已知的</strong>。然后将 $x_0$ 写作 $x_t$ 的表达式，代入可得</p><script type="math/tex; mode=display">\begin{aligned}\mu_t &=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha_t}}x_t + \frac{\beta_t\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha_t}}x_0.\\&= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \sqrt{1 - \bar{\alpha}_t}\epsilon) \\&=\frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon \right)\end{aligned}</script><p>我们将逆向过程解释为高斯分布，并且通过网络预测均值和方差，因此目标就是通过神经网络 $\mu<em>\theta$ ，使输入结果接近 $\mu_t$ 。而根据上面的推导，$\mu_t$ 中有一大部分是网络的输入 $x_t$ ，因此我们可以再次重参数化，使用一个噪声预测模块 $\epsilon</em>{\theta}$ 来达到这一效果。</p><script type="math/tex; mode=display">\begin{aligned}\mu_\theta(x_t, t) &= \frac{1}{\sqrt{\alpha_t}} \Big( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \Big).\end{aligned}</script><p>换言之，网络在每一级都会直接预测第一次采样的噪声，只不过在前面加上了权重，使得其仍然表达的是从 $x<em>t$ 到 $x</em>{t-1}$ 的过程。</p><p>理论上我们还需要预测标准差，然后使用高斯分布的 KL 散度公式计算 $L<em>{t-1}$ 中的每一项。但实际上 DDPM 并没有使用神经网络去预测方差，而是假定 $p</em>\theta(x<em>{t-1}|x_t)$ 和 $q(x</em>{t-1}|x_0,x_t)$ 具有相同的方差，也就是上面求解的 $\sigma_t$ 。因此我们的损失函数可以写作</p><script type="math/tex; mode=display">\begin{aligned}L_t &= \mathbb{E}_{x_0, \boldsymbol{\epsilon}} \Big[\frac{1}{2 \sigma_t^2} \|\tilde{\mu}_t(x_t, x_0) - \mu_\theta(x_t, t) \|^2 \Big] \\&= \mathbb{E}_{x_0, \boldsymbol{\epsilon}} \Big[\frac{1}{2  \sigma_t^2} \left\|\color{blue}{\frac{1}{\sqrt{\alpha_t}} \Big( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon \Big)} - \color{green}{\frac{1}{\sqrt{\alpha_t}} \Big( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \Big)} \right\|^2 \Big] \\&= \mathbb{E}_{x_0, \epsilon} \Big[\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \sigma_t^2} \|\epsilon - \epsilon_\theta(x_t, t)\|^2 \Big] \\&= \mathbb{E}_{x_0, \boldsymbol{\epsilon}} \Big[\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \sigma_t^2} \|\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon_t, t)\|^2 \Big] \end{aligned}</script><p>这里主要是消除了两个均值的公共项，留下了噪声部分。而 DDPM 也发现，忽略这个方差能够取得更好的效果，也就得到简化后的损失函数</p><script type="math/tex; mode=display">\begin{aligned}L^\text{simple}&= \mathbb{E}_{t \sim [1, T], x_0, \epsilon} \Big[\|\epsilon - \epsilon_\theta(x_t, t)\|^2 \Big] \\&= \mathbb{E}_{t \sim [1, T], x_0, \epsilon} \Big[\|\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon, t)\|^2 \Big]\end{aligned}</script><p>简化之前的 $\sigma_t$ 等同于给不同样本不同的权重，简化后则忽略了它们。原论文的解释是，忽略这些权重能够让网络更专注于噪声更多的部分，也就是 $t$ 较大的部分。</p><h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p>有了上述推导，我们已经可以训练一个标准的 DDPM 了。但对于生成模型，还需要有一个采样生成的过程。这里将论文中的算法贴出来。有了上面的推导，它们已经很容易被理解了。</p><p><img src="/2024/05/05/DDPM/image-20240505171239531.png" alt="训练和采样步骤" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>在 Sampling 的步骤中，注意到 $x_{t-1}$ 的表达式后面还多出来一项随机项。这一项的作用就是引入随机性，因为网络只预测了均值，而非高斯分布。加入这项噪声后，相当于手动给了一个方差，而这个方差在训练中被忽略。</p>]]></content>
    
    
    
    <tags>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
      <tag>生成式模型</tag>
      
      <tag>Diffusion Model</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PU-GCN 阅读笔记</title>
    <link href="/2024/03/15/PU-GCN/"/>
    <url>/2024/03/15/PU-GCN/</url>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1912.03264">PU-GCN: Point Cloud Upsampling using Graph Convolutional Networks</a></p><p>代码：<a href="https://github.com/guochengqian/PU-GCN">PU-GCN: Point Cloud Upsampling using Graph Convolutional Networks (github.com)</a></p><span id="more"></span><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="上采样方法"><a href="#上采样方法" class="headerlink" title="上采样方法"></a>上采样方法</h2><p>在此之前，PU-Net 使用并联的两层 MLP 扩展特征，MPU 对拼接了一维张量的特征向量使用共享 MLP 回归残差坐标，AR-GCN 直接将特征重塑成坐标的维数然后展开。PU-GCN 受图像超分辨率中 <a href="https://arxiv.org/abs/1609.05158">PixelShuffle</a> 的启发，提出 NodeShuffle 来有效地对点云进行上采样。</p><p>PixelShuffle 是插值、转置卷积之外的一种流行的上采样方式。对于尺寸为 $C\times H\times W$ 的图像，通过可学习参数将特征重塑为 $C r^2\times H\times W$ ，然后按照顺序排布，得到 $C\times Hr \times Wr$ ，即实现了上采样。下图给出了一个 $3$ 倍上采样的示意图，可以看到最后的高分辨率图中每个九宫格都是一样的顺序排布，也即所谓的 “周期性” 洗牌。</p><p><img src="/2024/03/15/PU-GCN/image-20240107163814613.png" alt="image-20240107163814613" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><p>我们很容易就可以建立下标之间的对应关系：</p><script type="math/tex; mode=display">\mathcal{PS}(I)_{x,y,c} = I_{\lfloor x/r \rfloor, \lfloor y/r \rfloor, C\cdot \text{mod}(x,r)+c}</script><p>而对于点云来说，这一操作更加简单。NodeShuffle 操作可以分为两个步骤。 </p><ol><li>通道扩展：使用 1 层 GCN 使用可学习参数 $\mathcal{W}<em>{l+1}$ 和 $b</em>{l+1}$ 将节点特征 $\mathcal{V}_l$ 扩展为 $N × rC$ 的尺寸。 </li><li>周期性改组：重新排列通道扩展的输出以形成 $rN × C$ 。</li></ol><p>与多分支 MLP 或基于重复的上采样相比，NodeShuffle 利用图卷积而不是 CNN。尽管 GCN 是特征提取的常见模块，但 PU-GCN 第一次将其用于点云上采样。论文认为上采样的关键是对来自点邻域的空间信息进行编码，并从潜在空间中学习新点。</p><p><img src="/2024/03/15/PU-GCN/image-20240107153751104.png" alt="image-20240107153751104" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>NodeShuffle 和 AR-GCN 中的反池化块在思路上几乎是一样的，区别在于 NodeShuffle 返回了特征，而 AR-GCN 中返回坐标残差，并用插值得到对应点特征。而且 NodeShuffle 返回的特征实际上仍然是一个图，可以进行更多的处理。</p><p>NodeShuffle 的设计方式使其更通用，能够植入到任意的上采样框架中。看来细微的设计差异也能带来很大的不同啊。</p><h2 id="多尺度特征"><a href="#多尺度特征" class="headerlink" title="多尺度特征"></a>多尺度特征</h2><p>为了对点云的多尺度性质进行编码，论文提出了一种新的 Inception DenseGCN 特征提取器，它将 DeepGCNs 中的密集连接 GCN 模块(DenseGCN) 有效地集成到 GoogLeNet 中的 Inception 模块中。</p><p><img src="/2024/03/15/PU-GCN/inception.png" alt="image-20240107153751104" style="zoom:60%;display: block; margin-left: auto; margin-right: auto;"></p><p>GoogLeNet 中的 Inception 模块的主要思想是通过多个并行的不同大小的卷积核以及池化层来处理图像，并将特征连接。事实证明，残差连接和密集连接对于提高点云处理性能非常有用。在这里，论文更多采用密集连接而非残差连接，因为前者利用了先前层的特征以及不同的 Inception 路径。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>主要的思路和方法就是以上这些，论文原文讲得非常详细。总得来说，PU-GCN 很好地在上采样过程中结合了 GAN 的思路，因此对于未见过的数据集有更强的泛化能力，能够生成细节更丰富的结果。并且通过回归坐标残差来提升收敛速度和稳定性，通过渐进式上采样取得更优的效果。</p>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
      <tag>点云上采样</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>抽象代数笔记（更新中）</title>
    <link href="/2023/12/14/%E6%8A%BD%E8%B1%A1%E4%BB%A3%E6%95%B0/"/>
    <url>/2023/12/14/%E6%8A%BD%E8%B1%A1%E4%BB%A3%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>抽象代数笔记，仅供个人参考。</p><span id="more"></span><div>  <iframe src="/pdfjs/web/viewer.html?file=/pdf/抽象代数.pdf" width="100%" height="1000px" frameborder="0"></iframe></div> ]]></content>
    
    
    
    <tags>
      
      <tag>数学笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>和弦理论笔记（更新中）</title>
    <link href="/2023/12/14/%E5%92%8C%E5%BC%A6%E7%90%86%E8%AE%BA/"/>
    <url>/2023/12/14/%E5%92%8C%E5%BC%A6%E7%90%86%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[<p>和弦理论笔记，教程出处：<a href="https://music-theory.aizcutei.com/">自由派音乐理论 </a> 。</p><span id="more"></span><div>  <iframe src="/pdfjs/web/viewer.html?file=/pdf/和弦理论.pdf" width="100%" height="1000px" frameborder="0"></iframe></div> ]]></content>
    
    
    
    <tags>
      
      <tag>音乐笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>激光雷达点云上采样调研</title>
    <link href="/2023/11/28/LiDAR%20SR%20Methods/"/>
    <url>/2023/11/28/LiDAR%20SR%20Methods/</url>
    
    <content type="html"><![CDATA[<p>激光雷达点云上采样相关论文调研。</p><span id="more"></span><h1 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>点云超分辨率关注点云的密度以及几何信息。对于给定的点云 $P$ ，我们希望得到更加密集的点云 $Q$ ，能够描述 $P$ 所在的底层形状。</p><p>对于激光雷达点云，这个问题要特殊一些。常规的点云上采样容易受到点云数据不规则特性的困扰，但激光雷达点云具有规则的分布，这受益于激光雷达的环状扫描方式。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231128154333947.png" alt="image-20231128154333947" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>鉴于激光雷达的扫描方式，一个自然的想法是将点云投影为球面坐标，即：</p><script type="math/tex; mode=display">\begin{cases}\begin{aligned}\varphi &= \arctan\left(z\big/\sqrt{x^2+y^2} \right) \\\theta &= \arctan(y/x)\\d  &=\sqrt{x^2+y^2+z^2}\end{aligned}\end{cases}</script><p>此时在 $\varphi-\theta$ 平面上，点的分布是规则的，这有利于后续的栅格化和上采样。使用这种投影的上采样方法通常总结为基于格网的方法。</p><p>需要注意的是，有的激光雷达点云在垂直方向上并不均匀分布，例如 <a href="https://hesaiweb2019.blob.core.chinacloudapi.cn/uploads/Pandar64_产品手册_640-zh-230510.pdf">Pandar64</a> 将 $3/4$ 的线束集中在了 $(-6°,+2°)$ ，而垂直视场角为 $(-25°,+15°)$ ，但这样的激光雷达目前还不多见。</p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>对于点云 $P$ ，可将其记作一系列扫描线的集合，即 $P={L_i \, |i=1,2,\dots,N_P}$ ，其中</p><script type="math/tex; mode=display">L_i=\left\{(x,y,z)\in P \, \middle|\arctan\left(z\big/\sqrt{x^2+y^2}\right)=\varphi_i \right\},</script><p>表示第 $i$ 条扫描线，我们希望预测点云 $Q={L_i \, |i=1,2,\dots,N_Q}$ ，满足 $N_Q&gt;N_P$ ，且保有 $P$ 的几何特征和扫描线结构。同时我们希望点云 $Q$ 在同样的下游算法上表现出优于 $P$ 的性能。</p><h1 id="研究现状"><a href="#研究现状" class="headerlink" title="研究现状"></a>研究现状</h1><h2 id="CNN-based-synthesis-of-realistic-high-resolution-LiDAR-data"><a href="#CNN-based-synthesis-of-realistic-high-resolution-LiDAR-data" class="headerlink" title="CNN-based synthesis of realistic high-resolution LiDAR data"></a><a href="https://arxiv.org/abs/1907.00787">CNN-based synthesis of realistic high-resolution LiDAR data</a></h2><h3 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h3><p>下图展示了网络的总体框架。对于低分辨率图像，其特征提取步骤通过一系列残差块执行，上采样则通过转置卷积（文中称分数跨步卷积）实现。在第一层和最后一层使用了 $9\times 9$ 的卷积，中间残差块中都是 $3\times 3$ 。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031175129278.png" alt="image-20231031175129278" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="修正的逐点损失函数"><a href="#修正的逐点损失函数" class="headerlink" title="修正的逐点损失函数"></a>修正的逐点损失函数</h3><p>论文考虑到图像中大量存在的缺失点，将 $\mathcal{L}_1、\mathcal{L}_2$ 损失修正为只对比非缺失点，记作集合 $V\subset I$ ，即：</p><script type="math/tex; mode=display">\mathcal{L}_d^\alpha = \sum_{(i,j)\in V}\left| d_{ij}-\hat{d}_{ij} \right|^{\alpha},\alpha=1,2</script><h3 id="感知损失"><a href="#感知损失" class="headerlink" title="感知损失"></a>感知损失</h3><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031190341496.png" alt="image-20231031190341496" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p><p>逐点损失鼓励图像输出较为平滑的结果，因为它表示了平均误差。同时逐点损失只能在像素层面比较，无法获取高频信息。因此有许多方法使用感知模块来表征损失，使生成的图像更真实。论文采用了一个预训练好的特征提取器 $\phi$ ，将预测图和实际图作为输入，并计算每一层的损失：</p><script type="math/tex; mode=display">\mathcal{L}_{f}=\sum_{c}\sum_{(i,j)\in I}\left| \phi_c(d)_{ij}-\phi_c(\hat{d})_{ij} \right|</script><p>其中 $\phi_c$ 对应了前 $c$ 层特征提取器。</p><h3 id="语义一致性损失"><a href="#语义一致性损失" class="headerlink" title="语义一致性损失"></a>语义一致性损失</h3><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031194443752.png" alt="image-20231031194443752" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p><p>语义一致性损失则利用了语义分割网络，以交叉熵方式比较两次扫描。对每个点预测一个语义类别概率，并和真值（one-hot 编码）进行比较，得到交叉熵损失 $\mathcal{L}_{ce}$ 。但仅有交叉熵损失无法约束点云的几何结构，因此通过可训练的权重参数将两个损失整合在一起：</p><script type="math/tex; mode=display">\mathcal{L}_{sc}=\frac{1}{2\sigma_r^2}\mathcal{L}_{d}^{1}+\frac{1}{\sigma_c^2}\mathcal{L}_{ce}+\log\sigma_r+\log\sigma_c</script><p>这一结果来自 <a href="https://arxiv.org/abs/1705.07115">Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</a> ，它通过对数似然推导了语义损失和回归损失的整合，但论文这里似乎把正则项抄错了（丢了两个平方）。</p><h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><p>MAE, MSE, mIoU 以及问卷投票。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/CNN-based-result.png" alt="CNN-based-result" style="zoom:30%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>论文只实现了两倍上采样，从实验结果来看，使用逐点损失的 MAE 和 MSE 最高，使用感知损失的 mIoU 最高，使用语义的效果不好。但这些结论几乎没什么帮助。</p><h2 id="Simulation-based-Lidar-Super-resolution-for-Ground-Vehicles"><a href="#Simulation-based-Lidar-Super-resolution-for-Ground-Vehicles" class="headerlink" title="Simulation-based Lidar Super-resolution for Ground Vehicles"></a><a href="https://arxiv.org/abs/2004.05242">Simulation-based Lidar Super-resolution for Ground Vehicles</a></h2><p>代码：<a href="https://github.com/RobustFieldAutonomyLab/lidar_super_resolution">lidar-super-resolution</a> </p><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>第一篇开源的工作，也是该任务下被引最多的。其思路很简单：带有转置卷积的 U-Net 用于重建深度，蒙特卡洛 Dropout 用于克服噪声值。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031204141231.png" alt="image-20231031204141231" style="zoom:27%;display: block; margin-left: auto; margin-right: auto;"></p><p>MC-Dropout 的想法是：在测试阶段也应用 Dropout 进行多次预测，从而获取多个不同的值。相当于将多个子网络的预测进行集成。对于多次预测变化较大的点，输出较低的置信度，并取平均值作为最终预测值。<a href="https://arxiv.org/abs/1506.02142">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a> 论证了 MC-Dropout 可以被看作高斯过程中的近似贝叶斯推理，表达为下式：</p><script type="math/tex; mode=display">p(y^*|\mathbf{x}^*,\mathcal{D})\propto \int p(y^*|\theta^*)p(\mathbf{x}^*,\mathcal{D}|\theta^*)\mathrm{d}\theta^*\\\Downarrow\\p(y^*|\mathbf{x}^*)=\frac{1}{T}\sum_{t=1}^{T}p(y^*|\mathbf{x}^*,\theta^*_t)</script><p>MC-Dropout 在直觉上接近机器学习中的 Bagging，但它只需要一个模型。论文实验了有无 MC-Dropout 的两种效果，认为它对减少噪声有很大帮助。</p><p><center class="half">       <img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101133538701.png" alt="image-20231031204141231" style="zoom:50%;">      <img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101140717153.png" alt="image-20231101140717153" style="zoom:50%;"></center></p><h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>通过生成预测点和 ground truth 的占用地图，绘制 ROC 曲线以及 AUC 的值。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231128173836966.png" alt="image-20231128173836966" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p><h2 id="T-UNet-A-Novel-TC-Based-Point-Cloud-Super-Resolution-Model-for-Mechanical-LiDAR"><a href="#T-UNet-A-Novel-TC-Based-Point-Cloud-Super-Resolution-Model-for-Mechanical-LiDAR" class="headerlink" title="T-UNet: A Novel TC-Based Point Cloud Super-Resolution Model for Mechanical LiDAR"></a><a href="https://link.springer.com/chapter/10.1007/978-3-030-92635-9_40">T-UNet: A Novel TC-Based Point Cloud Super-Resolution Model for Mechanical LiDAR</a></h2><p>代码：<a href="https://github.com/donkeyofking/lidar-sr">donkeyofking/lidar-sr</a> 。其主要思路是利用点云帧序列，而非单帧点云。</p><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><ul><li>首先将 $16$ 帧序列点云分别通过转置卷积进行上采样。将相邻两个特征图拼接，并通过（膨胀）卷积提取特征。论文用膨胀卷积取代了池化层，以减少信息的丢失。</li><li>重复上述步骤，直至得到一个特征图。然后通过一系列的转置卷积上采样，并和之前的特征图连接，这里和 U-Net 的结构相同。</li><li>采用 SSIM 作为损失函数。</li></ul><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101154818026.png" alt="image-20231101154818026" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="评价指标-1"><a href="#评价指标-1" class="headerlink" title="评价指标"></a>评价指标</h3><p>峰值信噪比 (PNSR), MSE, 结构相似性指数 (SSIM)。</p><h2 id="Channel-Attention-based-Network-for-LiDAR-Super-resolution"><a href="#Channel-Attention-based-Network-for-LiDAR-Super-resolution" class="headerlink" title="Channel Attention based Network for LiDAR Super-resolution"></a><a href="https://ieeexplore.ieee.org/document/9727846">Channel Attention based Network for LiDAR Super-resolution</a></h2><p>无代码。网络架构由一个 U-Net 和一个基于通道注意力的重建块组成。</p><h3 id="基于通道注意力的重建块"><a href="#基于通道注意力的重建块" class="headerlink" title="基于通道注意力的重建块"></a>基于通道注意力的重建块</h3><p>从图中看到，首先是两个转置卷积上采样四倍，然后就是不断复用卷积层和通道注意力模块，并使用残差连接。最后用两个卷积层回归深度值，并和 U-Net 提取的信息逐点相加。论文希望 U-Net 能够捕获边缘信息，使重建更准确（但是并没有对提取边缘这一点做监督或者约束，比较奇怪，可能是玄学吧）。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101160136946.png" alt="image-20231101160136946" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>通道注意力的结构就是最基本的自注意力机制，它关注不同通道之间的相关性（原文却说“每个通道上相邻像素之间的相关性”，可能是笔误）。首先将图像特征 $C\times V \times H$ 展平成 $C\times VH$ 的特征，和 $VH \times C$ 的矩阵执行点积，通过 SoftMax 得到 $C\times C$ 的注意力矩阵，然后和原来的特征矩阵相乘，得到新的特征图。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101160511380.png" alt="image-20231101160511380" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="环形填充"><a href="#环形填充" class="headerlink" title="环形填充"></a>环形填充</h3><p>球面投影需要一个角度来分割投影图，然后展平，因此在分割处提取不到真实的局部特征。论文的方法很简单，就是把图像往两边 padding，补充回丢掉的局部信息。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101163539525.png" alt="image-20231101163539525" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="评估指标-1"><a href="#评估指标-1" class="headerlink" title="评估指标"></a>评估指标</h3><p>只采用了一个 MAE 。</p><h2 id="LiDAR-Super-Resolution-Based-on-Segmentation-and-Geometric-Analysis"><a href="#LiDAR-Super-Resolution-Based-on-Segmentation-and-Geometric-Analysis" class="headerlink" title="LiDAR Super-Resolution Based on Segmentation and Geometric Analysis"></a><a href="https://ieeexplore.ieee.org/document/9875347">LiDAR Super-Resolution Based on Segmentation and Geometric Analysis</a></h2><p>无代码。这是一个步骤较多的无监督方法，并且基于点而非格网，但采用的是球面投影，因此同样保留扫描线结构。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101164701852.png" alt="image-20231101164701852" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="地面点分割"><a href="#地面点分割" class="headerlink" title="地面点分割"></a>地面点分割</h3><p>这一步骤在 $xyz$ 坐标上进行，更准确的说，在每一列扫描线上进行。</p><p>对于输入点 $P<em>l$ ，目标是分割得到地面点 $P_g$ 和非地面点 $P</em>{ng}$ 。考虑一列扫描点，点分布如下图所示。</p><ul><li>首先找到 $z$ 值最小的点，向两边顺序搜索，得到相邻点的向量 $V_l$ ；同时从最低点出发，连接所有点，得到向量 $V_r$ ；</li><li>求向量点积 $V_l \cdot V_r$ ，并通过点积的绝对值选取种子点（论文这里讲得不太清楚，应该就是求向量夹角）。最后通过一个 $z$ 值的低通滤波得到地面种子点；</li><li>基于种子点，利用最小二乘拟合一条直线，将距离直线一定阈值内的点纳入地面点，其余点纳入非地面点。对一圈的点执行上述操作，实现分割。</li></ul><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101170403255.png" alt="image-20231101170403255" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="坐标重组"><a href="#坐标重组" class="headerlink" title="坐标重组"></a>坐标重组</h3><p>坐标重组就是球面投影。但论文这里没有采用栅格化为图像的方式，而是保留三维坐标 $(h,v,d)$ ，避免了任何信息损失。其中 $h,v$ 分别表示水平角和垂直角，$d$ 表示距离。</p><h3 id="超分辨率"><a href="#超分辨率" class="headerlink" title="超分辨率"></a>超分辨率</h3><p>针对地面点和非地面点，采用两种上采样思路。</p><h4 id="地面点上采样"><a href="#地面点上采样" class="headerlink" title="地面点上采样"></a>地面点上采样</h4><p>将地面点视作平面，若上下两个像素都是地面点，则考虑三角形角平分线的性质。这里的推导很简单，设前后两个点的球面坐标分别为：</p><script type="math/tex; mode=display">\begin{cases}p_A = [I_i\cdot H_{\textrm{res}},a,v_1]\\p_B = [I_i\cdot H_{\textrm{res}},b,v_5]\end{cases}</script><p>则 $v_3=(v_1+v_5)/2$ ，只需求 $OD$ 的长度，结果如下：</p><script type="math/tex; mode=display">d = \frac{2ab}{a+b}\cos\frac{\alpha}{2}</script><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101170807215.png" alt="image-20231101170807215" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>地面点还有一个优化，大致是对空缺点进行了讨论，然后用局部的平滑细化点。</p><h4 id="非地面点上采样"><a href="#非地面点上采样" class="headerlink" title="非地面点上采样"></a>非地面点上采样</h4><p>从俯视图上，观察到非地面点呈现簇的分布，即同一物体的点之间相距较进。简单聚类后对每个物体进行上采样，将点分为物体内的点和物体间的点。对于物体间的点，由于缺乏先验知识，无法归类，为了提升远处物体的点数量，论文直接将其归到更远的物体上。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101172953666.png" alt="image-20231101172953666" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="评价指标-2"><a href="#评价指标-2" class="headerlink" title="评价指标"></a>评价指标</h3><p>Hasdorff 距离和 CD 。</p><h2 id="Fast-Point-Clouds-Upsampling-with-Uncertainty-Quantification-for-Autonomous-Vehicles"><a href="#Fast-Point-Clouds-Upsampling-with-Uncertainty-Quantification-for-Autonomous-Vehicles" class="headerlink" title="Fast Point Clouds Upsampling with Uncertainty Quantification for Autonomous Vehicles"></a><a href="https://ieeexplore.ieee.org/document/9811914">Fast Point Clouds Upsampling with Uncertainty Quantification for Autonomous Vehicles</a></h2><p>无代码。基本思路是用神经过程（NP）取代了 MC-Dropout，去实现更快速的不确定性量化。MC-Dropout 需要多次前向推理，会比较占用资源。从它的输出结果来看，不确定性较大的点依然是集中在边缘区域。</p><h3 id="使用-Conv-NPs-的上采样"><a href="#使用-Conv-NPs-的上采样" class="headerlink" title="使用 Conv-NPs 的上采样"></a>使用 Conv-NPs 的上采样</h3><p>对于低分辨率图像，论文用空白的掩码 $M_c$ 替代了转置卷积，直接增加图像的行数。与之对应的有 $M_t$ ，表示已知的部分。</p><script type="math/tex; mode=display">M_c(i,j)=\begin{cases}\begin{aligned}1&, \text{if} \ \ (r_{up}|i) \\0&, \text{otherwise}\end{aligned}\end{cases}</script><p>后续的方法分为四个模块。首先通过特征提取器，分别从掩码和扩大后的图像中提取特征图，并连接在一起。</p><script type="math/tex; mode=display">\begin{cases}e=\zeta(M_c)\in \mathbb{R}^{U_{\mathcal{H}}\times V_{\mathcal{H}}\times K}\\e'=\zeta(\mathcal{I_P})\in \mathbb{R}^{U_{\mathcal{H}}\times V_{\mathcal{H}}\times K}\\\end{cases}\Rightarrow\epsilon=e \oplus e'</script><p>通过通过卷积层聚合邻域特征：</p><script type="math/tex; mode=display">e_C = \gamma(\epsilon)\in \mathbb{R}^{U_{\mathcal{H}}\times V_{\mathcal{H}}\times 2}</script><p>再由掩码 $M_t$ 和特征 $e_C$ 预测一组高斯分布：</p><script type="math/tex; mode=display">v=(\mu, \sigma)=\Phi(M_t,e_C)</script><p>得到了均值图像和方差图像，从而滤除不确定性较大的点。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>由于输出了不确定性，实际上估计的是一个高斯分布。因此有<strong>条件负对数似然</strong>损失：</p><script type="math/tex; mode=display">Loss = -\mathbb{E}_{\mathcal{D}}\left[ \frac{1}{U_{\mathcal{H}}\times V_{\mathcal{H}}}\sum_{i,j}\log p_{i,j}(r_{i,j}^{g}|v_{i,j})\right]</script><p>其中 $r_{i,j}^{g}$ 表示像素点 $(i,j)$ 上的真实距离。</p><h3 id="评价指标-3"><a href="#评价指标-3" class="headerlink" title="评价指标"></a>评价指标</h3><p>仅适用了 MAE 。</p><h2 id="Implicit-LiDAR-Network-LiDAR-Super-Resolution-via-Interpolation-Weight-Prediction"><a href="#Implicit-LiDAR-Network-LiDAR-Super-Resolution-via-Interpolation-Weight-Prediction" class="headerlink" title="Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction"></a><a href="https://arxiv.org/abs/2203.06413">Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction</a></h2><p>代码：<a href="https://github.com/PinocchioYS/iln">PinocchioYS/iln</a> 。整体思路比较简单，对于任意一条查询射线，对其四个邻域点的特征进行注意力，求得权重，然后对距离加权。ILN 是第一个实现任意分辨率的，并且无需不确定性量化。</p><h3 id="LIIF"><a href="#LIIF" class="headerlink" title="LIIF"></a>LIIF</h3><p>LIIF 是这篇文章的灵感来源，发表在 CVPR2021 。对于二维特征图 $M \in \mathbb{R}^{H\times W\times D}$ ，定义一个对于所有图像相同的解码器 $f_\theta$ ，其作用为：</p><script type="math/tex; mode=display">s=f_\theta(z,x)</script><p>其中 $z$ 是一个向量，$x\in \mathcal{X}$ 是一个二维坐标，$s$ 为预测信号（通常为 RGB 值）。因此每一个 $z$ 对应了一个函数，即：</p><script type="math/tex; mode=display">z\mapsto f_\theta(z,\cdot):\mathcal{X}\rightarrow\mathcal{S},</script><p>假设特征向量在二维空间均匀分布，为每一个特征分配一个二维坐标。对于连续图像 $I(i)$ ，坐标 $x_q$ 处的 RGB 值定义为：</p><script type="math/tex; mode=display">I(x_q)=f_\theta(z^*, x_q-v^*),</script><p>其中 $z^{*}$ 是距离 $x_q$ 最近的一个特征向量，$v$ 是对应的坐标。</p><p>简而言之，对于任何一个需要预测的位置，找到离它最近的那个已知点，将该点的特征以及距离送入一个网络，输出预测值。仅此而已。这就好比点云上采样时，从一个点出发生成一系列点。</p><p>但这样做还不够，因为一个特征过于单调。论文使用了一个叫“特征展开”的步骤，将 $M$ 中每个位置的 $3\times 3$ 邻域串联起来，得到新的特征图：</p><script type="math/tex; mode=display">M_{jk}=\text{Concat}(\{M_{j+l,k+m}\}_{l,m \in \{-1,0,1\}}),</script><p>此外，由于两个像素连线中点处，会发生“跳变”的情况，因为 $z^*$ 发生了变化。为保证预测的连续性，将预测图像改写为：</p><script type="math/tex; mode=display">I(x_q)=\sum_{t\in \{00,01,10,11\}}\frac{S_t}{S}\cdot f_\theta(z^*_t, x_q-v^*_t),</script><p>也就是将最近的四个像素的预测值取加权平均。权重系数和 $x_q$ 到 $v^*_t$ 构成的矩形面积 $S_t$ 成正比。</p><p>除此之外还不够，由于 $f_\theta$ 预测了一个离散点的值，而我们实际上想要生成一个像素的值。这类似于 NeRF 与 Mip-NeRF 的区别，论文将像素的范围考虑在内，即：</p><script type="math/tex; mode=display">s=f_{cell}(z,[x,c])</script><p>其中 $c=[c_h,c_w]$ ，表示查询像素的大小。</p><h3 id="ILN"><a href="#ILN" class="headerlink" title="ILN"></a>ILN</h3><p>LIIF 通过周边信息直接预测了值，而 ILN 尝试预测权重，以在距离图像上取得比较稳定的效果。在 LIIF 中，权重是可以直接计算的。记权重函数为 $h$ ，值函数为 $g$ ，则 LIIF 可以表示为：</p><script type="math/tex; mode=display">\hat{r}=\sum_{t}^{4}g(\cdot)h(\cdot |\theta)=\sum_{t}^{4}\frac{S_t}{S}\cdot h(z_t|\theta)</script><p>为了直接利用周边点的距离值，ILN 直接预测权重：</p><script type="math/tex; mode=display">\hat{r}=\sum_{t}^{4}g(\cdot |\theta)h(\cdot )=\sum_{t}^{4} g(z_t|\theta)\cdot r_t</script><p>其主要思路很简单：首先对输入图像做特征提取，得到特征图；然后对于每个查询射线 $q$ ，找到最近的四个像素，将每个像素的相对距离 $\Delta q_t$ 编码后和特征 $z_t$ 组合在一起，得到 $z_t’$ 向量；之后通过一组自注意力块和线性层，直接获得四个权重值。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102145918672.png" alt="image-20231102145918672" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="评价指标-4"><a href="#评价指标-4" class="headerlink" title="评价指标"></a>评价指标</h3><p>MAE、IoU、Precision、Recall 以及 F1。</p><h2 id="HALS-A-Height-Aware-Lidar-Super-Resolution-Framework-for-Autonomous-Driving"><a href="#HALS-A-Height-Aware-Lidar-Super-Resolution-Framework-for-Autonomous-Driving" class="headerlink" title="HALS: A Height-Aware Lidar Super-Resolution Framework for Autonomous Driving"></a><a href="https://arxiv.org/abs/2202.03901">HALS: A Height-Aware Lidar Super-Resolution Framework for Autonomous Driving</a></h2><p>无代码。但这一篇写得很详细，有比较多的分析和对过往方法的总结。</p><h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h3><p>作者认为距离图像的上下部分具有不同的高度分布规律，即上部分距离较远，方差较大，下部分距离较进，方差较小。这意味着上部区域具有更广泛的距离值分布，因此具有更高的空间频率。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102152124742.png" alt="image-20231102152124742" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>因此论文在距离图的不同高度使用不同的策略。远处物体被压缩，且通常出现在上方，因此关注小区域；近处物体较大，且通常出现在下方，因此关注较大的区域。所以论文问用两个感受野提取的特征进行上采样，并预测两个感受野的掩码，从而进行加权融合。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102152552051.png" alt="image-20231102152552051" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>DRB 是膨胀残差块，在 <a href="https://arxiv.org/abs/2009.00206">RangeRCNN: Towards Fast and Accurate 3D Object Detection with Range Image Representation</a> 中提出，是专为激光雷达投影后图像设计的。</p><blockquote><p>不同距离的物体的尺度表现出显着的差异。为了更好地适应不同的尺度并获得更灵活的感受野，我们设计了膨胀残差块（DRB），它将膨胀卷积插入到正常残差块中。</p></blockquote><p>应用三个具有不同扩张率 ${1,2,3}$ 的 $3\times3$ 卷积来提取具有不同感受野的特征。三个扩张卷积的输出被连接起来，然后是一个 1 × 1 卷积，以融合具有不同感受野的特征。残差连接用于添加融合特征和输入特征。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102161906330.png" alt="image-20231102161906330" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>但是作者这里没有说上采样层的结构。最终预测一个 $C+1$ 维的特征图，最后一维作为掩码。两个掩码进行 SoftMax 得到权重。</p><h3 id="评价指标-5"><a href="#评价指标-5" class="headerlink" title="评价指标"></a>评价指标</h3><p>EMD、CD、MAE、RMSE、IoU、Precision、Recall、F1。</p><h2 id="SGSR-Net-Structure-Semantics-Guided-LiDAR-Super-Resolution-Network-for-Indoor-LiDAR-SLAM"><a href="#SGSR-Net-Structure-Semantics-Guided-LiDAR-Super-Resolution-Network-for-Indoor-LiDAR-SLAM" class="headerlink" title="SGSR-Net: Structure Semantics Guided LiDAR Super-Resolution Network for Indoor LiDAR SLAM"></a><a href="https://ieeexplore.ieee.org/document/10164213">SGSR-Net: Structure Semantics Guided LiDAR Super-Resolution Network for Indoor LiDAR SLAM</a></h2><h3 id="CASE-模块"><a href="#CASE-模块" class="headerlink" title="CASE 模块"></a>CASE 模块</h3><p>为了缓解物体边界周围的边缘膨胀和混合，采用了 squeeze and excitation 方法和注意力机制结合。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102172250213.png" alt="image-20231102172250213" style="zoom:70%;display: block; margin-left: auto; margin-right: auto;"></p><p>具体来说，对于输入的特征图 $(C\times H \times W)$ 做平均池化，得到压缩的特征 $(C\times 1\times W)$ ，再通过卷积将特征压缩到 $C/r’$ ，随后对特征图做批量归一化，并输入 sigmoid 得到注意力权重 $(C/r’ \times 1\times W)$ ，将其和原始特征矩阵相乘（没看懂咋乘的）。整体结构依然是 U-Net 。将 CASE 模块放在最前面，以避免在 Dropout 中丢失必要的信息。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103094427059.png" alt="image-20231103094427059" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="SGR-模块"><a href="#SGR-模块" class="headerlink" title="SGR 模块"></a>SGR 模块</h3><p>这部分主要是针对室内点云的特性，做一些简单的分割以引入语义信息。</p><p>首先统计单帧点云的 $z$ 值直方图，找出频率最高的两个，作为地面和天花板的高度 $h<em>{floor},h</em>{ceiling}$ 。为了提升相邻帧检测的一致性，取前后 $N$ 帧的中值滤波结果。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103110455119.png" alt="image-20231103110455119" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>估计 $h<em>{floor},h</em>{ceiling}$ 的主要原因是，在 MC-Dropout 估计不确定度时，天花板和地面的点距离传感器较远，容易得到较低的置信度，但对于室内场景这些点至关重要。因此对于不同的高度采用不同的系数 $\lambda(h)$ ，再和方差相乘得到置信度。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103113108059.png" alt="image-20231103113108059" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="评价指标-6"><a href="#评价指标-6" class="headerlink" title="评价指标"></a>评价指标</h3><p>RMSE、MAR、z RMSE（垂直方向上的误差），以及应用到 SLAM 算法中的评估结果（Mean、RMSE、SSE、STD、最大漂移和相对误差）。</p><h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h3><p>MC-Dropout 或其它删除不确定点的操作有利于 SLAM 的结果更稳定。</p><h1 id="TULIP-Transformer-for-Upsampling-of-LiDAR-Point-Clouds"><a href="#TULIP-Transformer-for-Upsampling-of-LiDAR-Point-Clouds" class="headerlink" title="TULIP: Transformer for Upsampling of LiDAR Point Clouds"></a><a href="https://arxiv.org/pdf/2312.06733.pdf">TULIP: Transformer for Upsampling of LiDAR Point Clouds</a></h1><p>暂时没有开源。其中的实验和结论值得学习。</p><h2 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h2><p>网络建立在 Swin-Unet 基础上，其中主要使用了 Swin Transformer 块。</p><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231213141040063.png" alt="image-20231213141040063" style="zoom:50%;"></p><h3 id="SWIN-Transformer"><a href="#SWIN-Transformer" class="headerlink" title="SWIN-Transformer"></a>SWIN-Transformer</h3><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>目前主要的问题包括：</p><ol><li>现有方法将高分辨率点云下采样，然后进行监督训练，但这意味着无法准确地上采样到更高的分辨率。而使用虚拟数据的方法很难泛化到复杂的真实数据；</li><li>由于训练数据中大量存在平面特征，往往将物体表面也拟合成平面；</li><li>对于生成的噪声没有合适的约束，容易在非表面区域生成不合理的点。</li></ol><p><img src="/2023/11/28/LiDAR%20SR%20Methods/25c774a139b7d3b25450e00c352cc6d.png" alt="25c774a139b7d3b25450e00c352cc6d" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
      <tag>点云上采样</tag>
      
      <tag>激光雷达</tag>
      
      <tag>研究现状调研</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>个人简历</title>
    <link href="/2023/09/27/%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86/"/>
    <url>/2023/09/27/%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><div>  <iframe src="/pdfjs/web/viewer.html?file=/pdf/简历-张从朗.pdf" width="100%" height="1000px" frameborder="0"></iframe></div> ]]></content>
    
    
    
    <tags>
      
      <tag>个人简历</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PU-GAN 论文阅读笔记</title>
    <link href="/2023/09/17/PU-GAN/"/>
    <url>/2023/09/17/PU-GAN/</url>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/abs/1907.10844">PU-GAN: a Point Cloud Upsampling Adversarial Network</a>。这篇比 AR-GCN 发表时间略早，思路也都是结合 GAN 。</p><span id="more"></span><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>生成器包含了三个组件，下面一一介绍。</p><p><img src="/2023/09/17/PU-GAN/image-20230917122834453.png" alt="image-20230917122834453" style="zoom:100%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="逐点特征提取单元（Per-point-feature-extraction-unit）"><a href="#逐点特征提取单元（Per-point-feature-extraction-unit）" class="headerlink" title="逐点特征提取单元（Per-point feature extraction unit）"></a>逐点特征提取单元（Per-point feature extraction unit）</h3><p>PU-GAN 采用了 MPU 中的特征提取方法，这在 <a href="https://zcliangyue.github.io/2023/06/10/Patch-based Progressive 3D Point Set Upsampling/">MPU 论文阅读笔记</a> 中有详细说明。简言之，它使用了层内密集连接来复用显式信息，同时借鉴 DGCNN 在特征空间上定义邻域，无需下采样就可以得到每个点的特征。</p><h3 id="特征扩展组件（Feature-Expansion-Component）"><a href="#特征扩展组件（Feature-Expansion-Component）" class="headerlink" title="特征扩展组件（Feature Expansion Component）"></a>特征扩展组件（Feature Expansion Component）</h3><p>论文提出了一个自上而下的扩展单元，称为 Up-down-up Expansion Unit 。简单来说，它首先将点特征$\mathbf{F}<em>1$上采样为 $\mathbf{F}</em>{up}’$ ，然后下采样为 $\mathbf{F}<em>2$ ，并计算上采样前和下采样后的特征差异，记作 $\Delta$ 。然后再将 $\Delta$ 上采样为 $\Delta</em>{up}$ ，并和 $\mathbf{F}<em>{up}’$ 相加，得到最终的上采样特征 $\mathbf{F}</em>{up}$ 。</p><p><img src="/2023/09/17/PU-GAN/image-20230917130718887.png" alt="image-20230917130718887" style="zoom:60%;display: block; margin-left: auto; margin-right: auto;"></p><h4 id="特征上采样"><a href="#特征上采样" class="headerlink" title="特征上采样"></a>特征上采样</h4><p><img src="/2023/09/17/PU-GAN/image-20230917130805805.png" alt="image-20230917130805805" style="zoom:60%;display: block; margin-left: auto; margin-right: auto;"></p><p>上采样组件 Up-feature operator 为了避免 PU-Net 中生成点太接近的问题，将特征复制后，对于每一个特征及其副本，在二维格网上采样向量并拼接到后面，使得每一个副本都不一样。和 MPU 不同，PU-GAN 对 FoldingNet 借鉴得更彻底。</p><p><img src="/2023/09/17/PU-GAN/image-20230917125408837.png" alt="image-20230917125408837" style="zoom:50%;float:right;padding-left:10pt">接着引入了自注意力机制，具体如左图所示。首先将输入特征通过两个单独的密集连接层，分别得到 $\mathbf{G}$ 和 $\mathbf{H}$ ，从而得到注意力权重 $\mathbf{W}$ ：</p><script type="math/tex; mode=display">\mathbf{W}=f_{\text{softmax}}(\mathbf{G}^T\mathbf{H})</script><p>然后通过 $\mathbf{K}$ 得到权重矩阵 $\mathbf{W}^T\mathbf{K}$ 。最后将权重矩阵和输入矩阵求和，得到输出矩阵。在这里自注意力单元不改变输入特征的尺寸。</p><h4 id="特征下采样"><a href="#特征下采样" class="headerlink" title="特征下采样"></a>特征下采样</h4><p><img src="/2023/09/17/PU-GAN/image-20230917130847566.png" alt="image-20230917130847566" style="zoom:60%;display: block; margin-left: auto; margin-right: auto;"></p><p>下采样单元的思路则非常简单，直接将 $rN\times C’$ 的特征 reshape 为 $N\times rC’$ ，然后通过一组共享的 MLPs 将特征变回原来的尺寸 $N\times C’$ 。</p><h3 id="点集重建组件"><a href="#点集重建组件" class="headerlink" title="点集重建组件"></a>点集重建组件</h3><p>为了增强生成点的均匀性，PU-GAN 首先通过一组 MLPs 生成一组点坐标，然后通过最远点采样得到 $rN$ 个点。因此在上采样阶段，需要上采样到更高的倍数，论文中使用了 $(r+2)N$ 。</p><h2 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h2><p>​      接着看一下判别器的组成。</p><p><img src="/2023/09/17/PU-GAN/image-20230917131251715.png" alt="image-20230917131251715" style="zoom:100%;display: block; margin-left: auto; margin-right: auto;"></p><p>对于输入的高分辨率点坐标 $rN\times 3$ ，首先通过共享 MLPs 和池化层得到全局特征 $1\times C_d$ ，并复制 $rN$ 份，和点特征 $rN\times C_d$ 拼接。通过注意力机制单元增强特征，然后再通过一组共享的 MLPs 和池化层得到全局特征，最后以一组全连接层回归置信度。若置信度接近 1，则判别器将其预测为真实数据，反之为生成数据。</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>为端到端训练网络，论文设计了复合的损失函数。</p><h3 id="对抗损失"><a href="#对抗损失" class="headerlink" title="对抗损失"></a>对抗损失</h3><p>和 AR-GCN 一样，PU-GAN 采用 LSGAN 的最小二乘损失作为对抗损失，定义如下：</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_{\text{gan}}(G)&=\frac{1}{2}(D(\mathcal{Q})-1)^2\\\text{and }\  \mathcal{L}_{\text{gan}}(D)&=\frac{1}{2}\left[D(Q)^2+(D(\hat{Q})-1)^2\right]\end{aligned}</script><h3 id="均匀损失（Uniform-Loss）"><a href="#均匀损失（Uniform-Loss）" class="headerlink" title="均匀损失（Uniform Loss）"></a>均匀损失（Uniform Loss）</h3><p>单独使用对抗网络难以使网络收敛，也很难生成均匀的点集。因此需要一个统一的损失来评估生成的 $\mathcal{Q}$ ，从而提高生成器的生成能力。PU-Net 使用 NUC 指标来评估点集表面的均匀性，主要思路是在物体表面放置大小相同的圆盘并统计圆盘内的点数变化差异。但这样做忽略了圆盘内点的局部混乱。</p><p>论文的方法如下。首先对 patch 进行最远点采样，得到 $M$ 个种子点，并使用球查询半径 $r_d$ 获取一系列局部点子集，记作 $S_j,\ j=1,2,\dots,M$ 。这里的 $r_d$ 取较小的值，使得 $S_j$ 中的点大致位于一个小局部圆盘上，面积为 $\pi r_d^2$ 。另一方面，通过测地线距离形成 patch 并标准化到单位球体当中，此时面积为 $\sim\pi 1^2$ 。因此 $S_j$ 中点的百分比应为 $p=(\pi r_d^2)/(\pi1^2)= r_d^2$ 。需要注意，此时的 patch 是标准化的，因此 $r_d&lt;1$ 。得到 $\hat{S_j}$ 中的期望点数为 $\hat{n}=rN\times p$ 。PU-GAN 遵循卡方模型来度量 $|S_j|$ 的偏差：</p><script type="math/tex; mode=display">U_{\text{imbalance}}(S_j)=\frac{(|S_j|-\hat{n})^2}{\hat{n}}</script><p>为了计算局部的点混乱，对于 $S<em>j$ 中的每个点，找到其最近邻点的距离，记第 $k$ 个最近点的距离为 $d</em>{j,k}$ 。如果点是均匀分布的，那么假设 $S<em>j$ 完全平坦且点成六边形分布，则预期的点到邻近点距离 $\hat{d}$ 应为 $\sqrt{\frac{2\pi r_d^2}{|S_j|\sqrt{3}}}$ 。这个计算是比较粗糙的，它假设了点数等于三角形数，那么三角形面积为 $\frac{\sqrt{3}}{2}\hat{d}^2=\frac{\pi r_d^2}{|S_j|}$ ，即可推得。同样地，遵循卡方模型来度量 $d</em>{j,k}$ 的偏差：</p><script type="math/tex; mode=display">U_{\text{clutter}}(S_j)=\sum_{k=1}^{|S_j|}\frac{(d_{j,k}-\hat{d})^2}{\hat{d}}</script><p>根据上述定义可知，$U<em>{\text{imbalance}}$ 描述了非局部的分布均匀性，而 $U</em>{\text{clutter}}$ 描述了局部的分布均匀性，这是对 NUC 指标的改良。最终计算均匀损失为：</p><script type="math/tex; mode=display">\mathcal{L}_{\text{uni}}= \sum_{j=1}^M U_{\text{imbalance}}(S_j)\cdot U_{\text{clutter}}(S_j)</script><h3 id="重建损失（Reconstruction-Loss）"><a href="#重建损失（Reconstruction-Loss）" class="headerlink" title="重建损失（Reconstruction Loss）"></a>重建损失（Reconstruction Loss）</h3><p>当然不能忘了上采样原本的目的：让生成的点位于表面上。PU-GAN 使用了 EMD 距离来衡量生成点云和实际点云的距离，记作 $\mathcal{L}_{\text{rec}}$ 。</p><h3 id="联合损失"><a href="#联合损失" class="headerlink" title="联合损失"></a>联合损失</h3><p>最终定义生成器和鉴别器的训练损失分别为：</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_G=&\lambda_{\text{gan}}\mathcal{L}_{\text{gan}}(G)+\lambda_{\text{rec}}\mathcal{L}_{\text{rec}}+\lambda_{\text{uni}}\mathcal{L}_{\text{uni}}\\\text{and }\ \mathcal{L}_D=&\mathcal{L}_{\text{gan}}(D)\end{aligned}</script><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>PU-GAN 最早将生成网络应用于点云上采样，在上采样以及判别器模块中结合了注意力机制加强特征融合。同时为了追求均匀分布的点，设计了能够兼顾局部和非局部点均匀性的损失函数。独特的 up-down-up 特征扩展单元被称为具有所谓的“自我校正”功能，我的理解是在上采样时扩展了特征维度，但一次扩展不一定准确，所以相当于算两遍特征。不过我不是很懂这个结构怎么被设计出来的，可能还是境界不够。</p>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
      <tag>点云上采样</tag>
      
      <tag>GAN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AR-GCN 阅读笔记</title>
    <link href="/2023/09/16/AR-GCN/"/>
    <url>/2023/09/16/AR-GCN/</url>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/pdf/1908.02111.pdf">Point Cloud Super Resolution with Adversarial Residual Graph Networks</a></p><span id="more"></span><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="AR-GCN-方法概述"><a href="#AR-GCN-方法概述" class="headerlink" title="AR-GCN 方法概述"></a>AR-GCN 方法概述</h2><p>AR-GCN 由两个网络组成，生成器 $G$ 和鉴别器 $D$ 。其中 $G$ 通过逐步上采样输入的 LR 来生成 HR 点云，而 $D$ 负责辨别 HR 点云是真还是假。</p><p><img src="/2023/09/16/AR-GCN/image-20230721134533712.png" alt="image-20230721134533712" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p><p>论文提出了一个联合损失函数：</p><script type="math/tex; mode=display">L(x,y)=\lambda L_{cd}(G(x),y)+L_G(G(x))</script><p>其中 $\lambda$ 控制损失函数 $L<em>{cd}$ 和 $L_G$ 的权重比。$L</em>{cd}$ 度量了 $y$ 和 $\hat{y}$ 之间的距离，类似于图像超分辨率中的 $L_2$ 损失：</p><script type="math/tex; mode=display">L_{cd}(\hat{y},y)=\sum_{p\in y}min_{q\in\hat{y}}\|p-q\|_2^2</script><p>$L<em>{cd}$ 是 CD 距离的变体。原始倒角距离由两部分组成：$L</em>{cd}$ 和 $\hat{L}<em>{cd}$ ，两者形式上对称。但 $\hat{L}</em>{cd}$ 会促使预测点云 $\hat{y}$ 与输入相同，导致点云出现重复点（后续可以实验证明一下）。因此论文删去了 $\hat{L}_{cd}$ 。</p><p>$L_G$ 损失则借鉴了 LSGAN（最小二乘生成对抗网络），被称作图对抗损失。LSGAN 主要工作是将 GAN 中的交叉熵损失函数替换为了最小二乘损失函数，克服了原始 GAN 生成结果不稳定、图像质量差的问题。具体有关 GAN 网络的原理及改进，在我另一篇笔记中有详细说明。以此有生成器和鉴别器的训练指标：</p><script type="math/tex; mode=display">\begin{aligned}L_G(\hat{y})&=\left\|1-D(\hat{y}) \right\|^2_2\\L_D(\hat{y},y)&=\frac{1}{2}\|D(\hat{y}) \|^2_2+\frac{1}{2}\|1-D(y) \|^2_2\end{aligned}</script><p>简单来说，AR-GCN 使用了生成对抗网络，生成器和鉴别器的损失函数借鉴了 LSGAN 的定义方法；此外，问题的本质仍然是上采样问题，因此加入点云间的相似性度量，指导生成器的训练。论文通过设计新的联合损失函数，将 GAN 和点云上采样结合了起来。</p><h2 id="残差图卷积生成器"><a href="#残差图卷积生成器" class="headerlink" title="残差图卷积生成器"></a>残差图卷积生成器</h2><p>首先来看生成器的组成。生成器的目标是将点云上采样，包含了残差图卷积块、反池化块以及特征网络。</p><h3 id="残差图卷积块"><a href="#残差图卷积块" class="headerlink" title="残差图卷积块"></a>残差图卷积块</h3><p><img src="/2023/09/16/AR-GCN/image-20230916205731283.png" alt="image-20230916205731283" style="zoom:60%;display: block; margin-left: auto; margin-right: auto;"></p><p>作者认为 PointNet++ 对中心点邻近点一视同仁，而图卷积的性能更加优异。观察上图，对于输入的特征  $f<em>{in}$ 和输入点云 $x</em>{in}$ ，通过 $x_{in}$ 在每次卷积时查询近邻点 $N(p)$ ，则每一层卷积的运算为：</p><script type="math/tex; mode=display">f_{i+1}^p = w_0 f_l^p + w_1\sum_{q\in N(p)}f_l^q,\forall p\in v</script><p>其中 $w<em>0,w_1$ 是可学习的参数，$x</em>{in}$ 和 $x_{out}$ 没有区别。同时注意到块中引入了残差连接来提升性能。思路和 DGCNN 很类似，但 DGCNN 更关注边特征，而这里以点特征为主体。同时 DGCNN 的图是动态更新的，也是一点不同。</p><h3 id="反池化块"><a href="#反池化块" class="headerlink" title="反池化块"></a>反池化块</h3><p>反池化的目的是增加点的数目。它首先通过残差图卷积块中的 G-Conv 层，将特征转换为 $\hat{n}\times 6$ 的张量，然后重塑为 $\hat{n}\times2\times3$ ，记作 $\delta x$ ，然后将原始点坐标复制一份，加到坐标残差上。反池化块的宗旨是预测输入点和输出点之间的残差，比直接预测点坐标更快，这在 EC-Net 中就有阐述。</p><p>反池化块仅仅重塑了坐标，但破坏了特征。因此论文依然利用残差图卷积块所得到的特征，进行插值得到新点云 $x_{out}$ 中每点的特征：</p><script type="math/tex; mode=display">f_{out}^p = \frac{1}{k}\sum_{q\in N[x_{in}](p)}f_{in}^q,\forall p\in x_{out}</script><p>可以看到，此处对最近邻搜索 $N(p)$ 标注了搜索集合为 $x<em>{in}$ ，但计算的点坐标是来自 $x</em>{out}$ 的。个人觉得，如果把预测的残差和原始特征放进一个图卷积来预测新的特征，或许会更好一些，这里相当于直接用了平均池化层。</p><h3 id="特征网络"><a href="#特征网络" class="headerlink" title="特征网络"></a>特征网络</h3><p>在进入残差图卷积块之前，需要提取点特征。论文采用了简单的 PointNet 结构，对每个点获取最近邻点，得到张量 $k\times 3$ ，然后通过一系列逐点卷积加上一个最大池化层，转换为 $1\times c$ 的特征 $f^p$ 。</p><h3 id="渐进式上采样"><a href="#渐进式上采样" class="headerlink" title="渐进式上采样"></a>渐进式上采样</h3><p>另外，论文采用了两次 $2\times$ 的上采样，并在实验中发现这样做的精度更好。</p><h2 id="图判别器"><a href="#图判别器" class="headerlink" title="图判别器"></a>图判别器</h2><p>图判别器的结构依然基于残差图卷积块和特征网络，事实上，从第一张图可以看出，判别器和生成器唯一的区别就是用池化层替代了反池化层，最终输出一个标量预测。池化层的运算方法很简单，首先将点进行最远点采样，然后计算剩余点的特征为周围近邻点特征的池化：</p><script type="math/tex; mode=display">f_{out}^p =\max_{q\in N[x_{in}](p)}f_{in}^q,\forall p\in x_{out}</script><p>特别的是，论文没有采用逐步下采样至单个标量的方式，因为这样做会导致伪像（我的理解是一些细微的噪声很难被整体鉴别器察觉，导致生成的数据上有伪影）。因此在这里鉴别器的输出包含不止 1 个点，并对每个点的局部 patch 进行鉴别，通过交叉熵来计算最终的总损失值。这里实际上是借鉴了另一篇文章：<a href="https://arxiv.org/abs/1612.07828">Learning from Simulated and Unsupervised Images through Adversarial Training</a> ，下图很直观地说明了这种方法。</p><p><img src="/2023/09/16/AR-GCN/image-20230916213653638.png" alt="image-20230916213653638" style="zoom:100%;display: block; margin-left: auto; margin-right: auto;"></p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>主要的思路和方法就是以上这些，论文原文讲得非常详细。总得来说，AR-GCN 很好地在上采样过程中结合了 GAN 的思路，因此对于未见过的数据集有更强的泛化能力，能够生成细节更丰富的结果。并且通过回归坐标残差来提升收敛速度和稳定性，通过渐进式上采样取得更优的效果。</p>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
      <tag>点云上采样</tag>
      
      <tag>GAN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MPU 论文阅读笔记</title>
    <link href="/2023/06/10/Patch-based%20Progressive%203D%20Point%20Set%20Upsampling/"/>
    <url>/2023/06/10/Patch-based%20Progressive%203D%20Point%20Set%20Upsampling/</url>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/pdf/1811.11286v3.pdf">Patch-based Progressive 3D Point Set Upsampling</a></p><h1 id="一、摘要及引言"><a href="#一、摘要及引言" class="headerlink" title="一、摘要及引言"></a>一、摘要及引言</h1><p>点云通常是稀疏、嘈杂且不完整的，这意味着上采样技术非常重要，但将图像中的超分辨率方法迁移到点云中并不容易。PU-Net 通过多尺度学习及特征扩展的方式来扩大点集，但无论输入的几何结构是大规模的还是细粒度的，PU-Net 都将使用同样的尺度来处理，以致于其重建结果往往缺乏细粒度的几何结构。</p><p>论文提出了一种 patch-based 渐进式上采样网络，将一个 $16\times$ 上采样网络分成四个 $2\times$ 网络，其中每个子网络侧重于不同级别的细节。</p><p>所有子网络都是完全基于 patch 的，并且输入 patch 的大小相对于当前的细节级别是自适应的。论文提出了一系列架构改进，包括用于逐点特征提取的新型密集连接、用于特征扩展的编码分配，以及用于层间特征传播的双边特征插值。这些都会在后面详细介绍。</p><span id="more"></span><p><img src="/2023/06/10/Patch-based%20Progressive%203D%20Point%20Set%20Upsampling/image-20230531170652387.png" alt="image-20230531170652387" style="zoom:60%;display: block; margin-left: auto; margin-right: auto;"></p><h1 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h1><p>主要介绍了基于优化和基于深度学习的方法。论文指出了 PU-Net 对高分辨率输入效果较好，但缺乏细节；EC-Net 在锐利特征上有所加强，但边缘标记的工作量很大。论文还特别提到了深度学习中的多尺度 skip connection 方法，如 CNN 里的 U-Net 、ResNet 等。针对点云上采样问题，论文在不同组件中采用了不同的 skip connection 策略。</p><h1 id="三、方法"><a href="#三、方法" class="headerlink" title="三、方法"></a>三、方法</h1><h2 id="多步上采样网络（Multi-step-Upsampling-Network）"><a href="#多步上采样网络（Multi-step-Upsampling-Network）" class="headerlink" title="多步上采样网络（Multi-step Upsampling Network）"></a>多步上采样网络（Multi-step Upsampling Network）</h2><h3 id="多步监督（Multi-step-Supervision）"><a href="#多步监督（Multi-step-Supervision）" class="headerlink" title="多步监督（Multi-step Supervision）"></a>多步监督（Multi-step Supervision）</h3><p>Multi-step supervision 是神经图像超分辨率（neural image super-resolution）中的常见做法。简言之，对于上采样任务， Multi-step supervision 通常先将输入图像重建到一个中间分辨率，然后利用已知的高分辨率图像进行监督学习；之后再重建到更高的分辨率，再次进行学习。</p><p><img src="/2023/06/10/Patch-based%20Progressive%203D%20Point%20Set%20Upsampling/1685689112348.png" alt="1685689112348" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><p>这种做法的好处在于它允许模型在各个阶段学习和纠正错误，而不仅仅是在最终阶段。其次，它允许模型学习在<strong>不同分辨率之间</strong>的显式映射，这可能有助于使上采样结果更准确。</p><h3 id="多步-patch-based-感受野（Multi-step-patch-based-receptive-field）"><a href="#多步-patch-based-感受野（Multi-step-patch-based-receptive-field）" class="headerlink" title="多步 patch-based 感受野（Multi-step patch-based receptive field）"></a>多步 patch-based 感受野（Multi-step patch-based receptive field）</h3><p>理想情况下，点集上采样网络应针对各种细节尺度自适应地跨越感受野，以从多个尺度学习几何信息。然而不同于图像，点集没有规则结构，每个点的邻域都需要通过 $k$ 近邻的方式去查找，计算代价非常大，这使得多步上采样难以应用在点云中。因此有必要优化网络架构，使其可扩展到高分辨率点集。</p><p>论文应对这一问题的关键想法是：patch 大小应适应当前步骤的感受野范围。感受野的范围实际上由 $k$ 的大小决定，若 $k$ 固定，则随着点集不断被上采样，感受野会变小。因此论文提出的网络在上采样的同时，缩小了 patch 的空间跨度，减少了计算量。</p><p>由于需要对每个点做 KNN ，设总点数为 $N$ ，patch 大小为 $p_{num}$ ，其计算复杂度可以大约估算：</p><script type="math/tex; mode=display">O=p_{num}^2\times \frac{N}{p_{num} }= N\times p_{num}</script><p>因此随着 patch 大小缩减，计算复杂度也会降低。</p><h3 id="多步端到端训练（Multi-step-end-to-end-training）"><a href="#多步端到端训练（Multi-step-end-to-end-training）" class="headerlink" title="多步端到端训练（Multi-step end-to-end training）"></a>多步端到端训练（Multi-step end-to-end training）</h3><p>网络通过 $L$ 步将点集上采样 $2^L$ 倍，包括子网络单元 ${U<em>1,U_2,\dots,U_L}$ 。论文通过<strong>逐步激活</strong>每个单元的方式来训练这一系列上采样单元。具体地，除了第一层网络，每一层网络的训练都包含两步：对于层次 $\hat{L}$ ，首先固定前面 $U_1$ 到 $U</em>{\hat{L}-1}$ 每一层的参数，只对 $U_{\hat{L}}$ 层训练；然后释放固定单元，对所有单元同时训练。</p><p>这种渐进式的训练方法是为了避免当前层产生过大的梯度（gradient turbulence），导致前面的单元参数被破坏。 </p><h2 id="上采样网络单元"><a href="#上采样网络单元" class="headerlink" title="上采样网络单元"></a>上采样网络单元</h2><p>分别用 $T,P,Q$ 表示基准模型、预测 patch 和 参考 patch ，$\hat{L},\ell$ 表示目标的细节级别和一个中间级别。简单来说，上采样网络单元 $U<em>{\ell}$ 首先接收来自于点集 $P</em>{\ell-1}$  的 patch ，然后提取深度特征并扩展特征数量，将特征通道数压缩到 $d$ 维坐标 $P_{\ell}$ 。下面做详细说明。</p><h3 id="通过层内密集连接提取特征"><a href="#通过层内密集连接提取特征" class="headerlink" title="通过层内密集连接提取特征"></a>通过层内密集连接提取特征</h3><p>在 PointNet++ 之后，大多数网络都采用对输入点集进行分层下采样的方式来提取多尺度信息，并采用 skip-connections 来连接多级特征。然而由于在下采样过程中采用了泊松盘采样或者最远点采样，导致点的位置发生变化，因此在特征连接的时候，需要进行点与点之间的对应搜索，导致计算代价增加。</p><p>收到 DGCNN 的启发，论文在<strong>特征空间</strong>中定义了局部邻域，因此网络<strong>无需点集子采样</strong>即可获得大范围、非局部的信息，也就不需要在特征组合时进行对应搜索。</p><p>如下图所示，论文的特征提取单元由一系列<strong>密集块</strong>（dense block）组成。在每个 dense block 中，首先将输入转换为固定维数 $(C’)$ 的特征，然后使用基于特征的 KNN 对特征进行分组，得到分组特征 $(N\times K\times C’)$ 。进而通过 MLP ，将特征重组为 $G’$ 维。实际上，在每个 dense block <strong>内部</strong>，MLP 的输出维度都是固定的 $(G’)$ ，并且每经过一次特征处理，就会将上一步的特征拼接在后面，因此每一次处理都使得特征维数增加 $G’$ 。最后通过最大池化得到一个顺序不变的点特征。而在 dense blocks <strong>之间</strong>，每个块产生的点特征会作为后面所有的 dense blocks 的输入（因为 dense block 的输出也会和上一个 block 的输出连接。相当于内部外部嵌套地进行 skip connections ）。</p><p>这种 skip-connection 的方式能够<strong>复用显式信息</strong>，从而提高重建精度。同时相比于 PU-Net 在每一次下采样后用 PointNet 层聚合特征的方式，论文的特征提取方法能够<strong>显著减小模型参数量</strong>。</p><p><img src="/2023/06/10/Patch-based%20Progressive%203D%20Point%20Set%20Upsampling/image-20230602201310600.png" alt="image-20230602201310600" style="zoom:120%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="通过编码分配扩展特征"><a href="#通过编码分配扩展特征" class="headerlink" title="通过编码分配扩展特征"></a>通过编码分配扩展特征</h3><p>特征扩展单元的目标是将提取得到的特征 $(N\times C)$ 扩展为一组上采样的点坐标 $(2N\times d)$ 。PU-Net 的策略是复制每个点的特征，然后通过<strong>独立</strong>的 MLP 去处理所有的复制特征。但这会造成点的集中分布，PU-Net 通过添加了排斥损失来缓解这一问题。</p><p>论文借鉴了 <a href="https://arxiv.org/pdf/1712.07262.pdf">FoldingNet</a> 和 <a href="https://arxiv.org/pdf/1802.05384.pdf">AtlasNet</a> 。简单浏览了一下 FoldingNet ，大致思路是：首先从三维模型中提取了全局特征，然后复制一定数量，连接到一个<strong>二维网格点</strong>后面，将其重建为三维点，再次将复制后的全局特征连接到三维点后，重建成最终的具有预设数量的三维点。</p><p>论文的方法则更为简单，它将 $N$ 个 $-1$ 和 $N$ 个 $1$ 组成的一维张量拼接在复制了两份的特征向量后面（code assignment），再利用一系列<strong>共享</strong>的 MLP 将其压缩为 $2N\times d$ 的残差。将残差和原始坐标求和即得到新的上采样坐标，这与 EC-Net 的做法是一样的。区别于 PU-Net 和 EC-Net 在特征扩展部分所采用的策略，共享的 MLP 意味着参数量不会随着上采样率增大而增大（突然有个想法，如果后面接的特征不是 $1$ 和 $-1$ ，而是在 $4\pi$ 空间上均匀采样的 $2N$ 个方位角呢，会不会发散得更合理）。</p><p><img src="/2023/06/10/Patch-based%20Progressive%203D%20Point%20Set%20Upsampling/image-20230610101835846.png" alt="image-20230610101835846" style="zoom:120%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="通过双边特征插值实现层间-skip-connection"><a href="#通过双边特征插值实现层间-skip-connection" class="headerlink" title="通过双边特征插值实现层间 skip connection"></a>通过双边特征插值实现层间 skip connection</h3><p>上述两个组件已经实现了特征的嵌入和特征的扩展，这两者合在一起构成一个上采样单元。为了融合不同感受野提取的特征，论文在多个上采样单元之间使用了 skip connection 。由于点数增长，在连接之前需要进行特征插值。对于级别 $\ell$ ，$p_i$ 表示第 $i$ 个点坐标，$f_i$ 表示通过特征提取组件得到的该点特征。$\mathcal{N}_i’$ 表示第 $p_i$ 在级别 $\ell’$ 中的空间 KNN 近邻点集，则插值特征 $\widetilde{f}_i$ 表示为：</p><script type="math/tex; mode=display">\widetilde{f}_i = \frac{\sum_{i'\in \mathcal{N}_i'}\theta(p_i,p_{i'})\psi(f_i,f_{i'})f_{i'}}{\sum_{i'\in \mathcal{N}_i'}\theta(p_i,p_{i'})\psi(f_i,f_{i'})}</script><p>显然 $\theta$ 和 $\psi$ 是两个权重函数。其中 $\theta(p_1,p_2)=e^{-\left(\frac{|p_1-p_2|}{r}\right)^2},\psi(f_1,f_2)=e^{-\left(\frac{|f_1-f_2|}{h}\right)^2}$ ，$r$ 和 $h$ 是到附近点的（特征）距离平均值。这也就是所谓的双边插值（bilateral interpolation），即同时考虑空间相似度和特征相似度的插值方式。</p><p>实现层间连接的方式可以是对<strong>先前所有</strong>层的 $\widetilde{f}_i$ 进行插值和连接，即密集连接，这和特征提取单元是一样的。但是这样做意味着第 $\ell$ 层会有 $\ell C$ 个特征，导致扩展性差、优化困难。因此论文采用了<strong>残差跳跃连接</strong>，每个级别只需要和上一个级别的特征相连，这在下图中展现得很清楚。</p><p><img src="/2023/06/10/Patch-based%20Progressive%203D%20Point%20Set%20Upsampling/1686379552309.png" alt="1686379552309" style="zoom:120%;display: block; margin-left: auto; margin-right: auto;"></p><h2 id="实施细节"><a href="#实施细节" class="headerlink" title="实施细节"></a>实施细节</h2><h3 id="迭代提取-patch"><a href="#迭代提取-patch" class="headerlink" title="迭代提取 patch"></a>迭代提取 patch</h3><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p> $P<em>{\hat{L}},Q</em>{\hat{L}}$ 分别表示预测和参考 patch ，$T<em>{\hat{L}}$ 则表示该分辨率下的整体参考点云。在渐进式上采样过程中，则会有一系列预测和参考 patch ，记作 $P</em>{\ell},Q_{\ell}$ ，其中 $\ell=1\dots\hat{L}-1$ 。</p><p>具体来说，$\ell$ 层的输入是通过对 $P<em>{\ell-1}$ 中的随机点 $p</em>{\ell-1}’$ 执行 KNN 搜索得到的，其中 $k=N$ ，为 patch 的大小。而 $\widetilde{Q}<em>{\ell}$ 应与 $P</em>{\ell}$ 的空间范围相匹配，同时具有更高的分辨率，因此 $Q<em>{\ell}$ 可以通过在 $Q</em>{\ell-1}$ 中执行 KNN 得到，并且查询点仍为 $p_{\ell-1}’$ 。此时 $k=2^{\hat{L}-\ell+1}N$ (这里符号表示和原文不同，因为 * 有转义字符的含义，网页里似乎优先级高于公式)。</p><p>关于这个结论，可以先考虑第 $1$ 层：我们希望将第一层的 $N$ 个点上采样为 $2^{\hat{L}}$ 个点，因此在参考点云中，需要采样 $2^{\hat{L}-0}=2^{\hat{L}}$ 个点；而点云被上采样 $\ell-1$ 次之后，到达了 $\ell$ 层，此时需要在参考点云中采样的点数变为 $2^{\hat{L}-(\ell-1)}=2^{\hat{L}-\ell+1}$ 。如下图所示，需要注意的是 <strong>$Q_{\ell}$ 的分辨率是不随 $\ell$ 变化的</strong>，仅仅是空间范围变化而已，换言之，$\left|P<em>{\ell}\right|/\left|Q</em>{\ell}\right|$ 等于 $P<em>{\ell}$ 和基准点云的分辨率之比，随着上采样次数增加，$P</em>{\ell}$ 的分辨率增大，patch 点数不变的情况下， $Q_{\ell}$ 的点数随之减少。</p><p><img src="/2023/06/10/Patch-based%20Progressive%203D%20Point%20Set%20Upsampling/image-20230610193120100.png" alt="image-20230610193120100" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><h4 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h4><p>推理阶段和训练主要有两个不同：</p><ol><li>对于每个级别，提取 $H$ 个<strong>有重叠</strong>的输入 patches 以确保<strong>覆盖整个点集</strong>。patch 的中心点通过最远点采样获得；</li><li>由于有重叠，上采样后的点数实际上大于 $2\left|P<em>{\ell-1} \right|$ ，因此对 $P</em>{\ell}$ 进行最远点采样，使其点数为上一层的两倍。这同样有助于上采样结果均匀分布。</li></ol><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>考虑到计算速度，论文采用了欧氏距离进行 patch 提取，但这可能导致 $P<em>{\ell}$ 和 $Q</em>{\ell}$ 的边缘产生错位问题，也就是空间范围不一致。为了降低这些不匹配点带来的噪声，论文提出了改进的 Chamfer 距离：</p><script type="math/tex; mode=display">\mathcal{L}(P,Q)=\frac{1}{\left|P\right|}\sum_{p\in P}\xi(\underset{q\in Q}{\min}\left\|p-q \right\|^2)+\frac{1}{\left|Q\right|}\sum_{q\in Q}\xi(\underset{p\in P}{\min}\left\|p-q \right\|^2),\\\xi=\left\{\begin{aligned}&d,\ \ d\leq\delta\\&0,\ \ \text{otherwise} \end{aligned} \right.</script><p>相比于之前在 PU-Net 里所介绍的 CD 距离，其实就差了一个 $\xi$ 函数。其中 $\delta$ 设置为平均最近邻距离的倍数，以便动态调整到不同尺度的 patch （至于为什么是倍数，可能因为尺度较大时这个条件可以被适当放宽？）。</p><h1 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h1><p>论文所做的主要工作包括：</p><ul><li>提出了新的特征提取和特征扩展单元，其中特征提取部分在特征空间上定义了邻域，无需下采样，避免了特征连接需要点对应搜索的问题，并通过密集连接复用信息；特征扩展部分采用了附加变量的方式，使用共享的 MLP ，起到控制参数量、促使点均匀分布的作用；</li><li>在不同层之间利用双边插值进行残差连接，同时考虑特征距离和空间距离；</li><li>随着不断上采样、感受野缩小的同时，缩小了 patch 的空间跨度，即自适应 patch 。这使得网络可以端到端地训练；</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
      <tag>点云上采样</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DGCNN 论文阅读笔记</title>
    <link href="/2023/06/08/DGCNN/"/>
    <url>/2023/06/08/DGCNN/</url>
    
    <content type="html"><![CDATA[<blockquote><p>近来饱受专业实习折磨，学习方面，有所懈怠</p></blockquote><p>论文：<a href="https://arxiv.org/pdf/1801.07829.pdf">Dynamic Graph CNN for Learning on Point Clouds</a></p><h1 id="一、摘要及引言"><a href="#一、摘要及引言" class="headerlink" title="一、摘要及引言"></a>一、摘要及引言</h1><p>在 PointNet、PointNet++ 中，都没有考虑到点云的拓扑结构，即相邻点之间的邻接关系。如果设计一个能够恢复<strong>拓扑结构</strong>的模型，应当可以增强网络的表示能力。基于这一想法，论文设计了网络模块 EdgeConv 来提取局部邻域信息和潜在的长距离语义特征。</p><span id="more"></span><p>PointNet 通过在局部邻域内独立地处理点，确保了顺序不变性，然而这种<strong>独立性</strong>一定程度上忽略了点之间的几何关系，因而难以捕获局部特征。而 EdgeConv 并不从点的嵌入中生成点特征，而是生成了描述点与其邻域内点之间关系的<strong>边特征</strong>，并且对邻域内点的排序具有不变性。同时 EdgeConv 易于嵌入到现有网络中。论文将其集成到 PointNet 中，得到了很好的性能。</p><h1 id="二、方法"><a href="#二、方法" class="headerlink" title="二、方法"></a>二、方法</h1><h2 id="图卷积神经网络（Graphic-Convolutional-Neural-Networks，GCN）"><a href="#图卷积神经网络（Graphic-Convolutional-Neural-Networks，GCN）" class="headerlink" title="图卷积神经网络（Graphic Convolutional Neural Networks，GCN）"></a>图卷积神经网络（Graphic Convolutional Neural Networks，GCN）</h2><p>由于文章借鉴了图卷积神经网络，因此简单了解了一下图卷积的原理。与 CNN 相比，GCN 主要应用于<strong>图数据</strong>。也就是节点和边组成的图形。当然图像也是一种特殊的图形，它具有规整的结构。而在特征嵌入方面，两者都是局部连接，并且卷积核权重处处共享。因此 GCN 与 CNN 思想上是基本一致的，只不过应用场景不同。相比之下，GCN 所处理的数据结构会更复杂。</p><p><img src="/2023/06/08/DGCNN/605d901a470d47739b7ee58670f91c82.jpg" style="zoom:60%;display: block; margin-left: auto; margin-right: auto;"></p><h2 id="边卷积（Edge-Convolution）"><a href="#边卷积（Edge-Convolution）" class="headerlink" title="边卷积（Edge Convolution）"></a>边卷积（Edge Convolution）</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>利用点云能够生成的最简单的图，大概是体素连通性分割里的体素邻接图。但论文所使用的方法有所区别于 GCN，因为它会在每一层根据新的特征序列，重新计算节点的邻接关系。不同于使用空间距离构建的图，这样做意味着图会<strong>动态更新</strong>，即每个点的 $k$ 近邻点会在不同层之间发生变化。这使得<strong>非局部</strong>（non-local）信息能够得到扩散。下面阐述 EdgeConv 具体架构。</p><p>将数量为 $n$ 的 $F$ 维点云记作 $\mathbf{X}=\left{\mathbf{x}_1, \ldots, \mathbf{x}_n\right} \subseteq \mathbb{R}^F$ ，令 $F=3$ ，则每个点包含三维坐标 $\mathbf{x}=(x_i,y_i,z_i)$ ，也可以包含颜色、法线等附加特征。因此 $F$ 更一般的含义是点特征。</p><p>引入一个有向图 $\mathcal{G}=(\mathcal{V}, \mathcal{E})$ 来表示局部点云结构，其中 $\mathcal{V}={1, \ldots, n}$ , $ \mathcal{E} \subseteq \mathcal{V} \times \mathcal{V}$ ，分别表示节点和边，最简单的 $\mathcal{G}$ 是 $k$ 近邻图。图中包含了自环（self-loop），即每个节点也会指向自己。论文定义了以 $\mathbf{x}_i,\mathbf{x}_j$ 为端点的边缘的特征：</p><script type="math/tex; mode=display">\boldsymbol{e}_{i j}=h_{\Theta}\left(\mathbf{x}_i, \mathbf{x}_j\right)</script><p>其中 $h_{\boldsymbol{\Theta}}: \mathbb{R}^F \times \mathbb{R}^F \rightarrow \mathbb{R}^{F^{\prime}}$ 是一个非线性函数，$\Theta$ 为一组可学习优化的参数。</p><p> 最后，将边缘特征定义为由顶点出发的所有边特征的聚合，聚合方式为对称函数（如求和或者池化），论文里记作一个<del>令人费解的</del>正方形：</p><script type="math/tex; mode=display">\mathbf{x}_i^{\prime}=\underset{j:(i, j) \in \mathcal{E}}{\square} h_{\Theta}\left(\mathbf{x}_i, \mathbf{x}_j\right)</script><p>类比于图像卷积， $\mathbf{x}_i$ 为中心像点，${\mathbf{x}_j:(i,j)\in\mathcal{E}}$ 为其邻域内像点。总之，给定一个 $F$ 维的点云，EdgeConv 将其转换为点数不变的 $F’$ 维点云。</p><p><img src="/2023/06/08/DGCNN/image-20230608223623247.png" alt="image-20230608223623247" style="zoom:70%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="函数的选择"><a href="#函数的选择" class="headerlink" title="函数的选择"></a>函数的选择</h3><p>在 EdgeConv 中主要涉及到两个函数的选取：$h$ 和 $\square$ 。若 $\mathbf{x}_1,\dots,\mathbf{x}_n$ 是规则网格上的图像像素，而图 $\mathcal{G}$ 中表示了每个像素周围固定大小的块的连通性，同时选取边缘函数为 $\Theta_m\cdot\mathbf{x}_j$ ，聚合操作为求和函数，就得到了标准的卷积操作：</p><script type="math/tex; mode=display">x_{i m}^{\prime}=\sum_{j:(i, j) \in \mathcal{E}} \boldsymbol{\theta}_m \cdot \mathbf{x}_j,</script><p>这个表示的细节就不深究了，个人感觉和一般说的 CNN 不太一样，因为这里似乎对所有邻域内的点都共享了权重。</p><p>后面论文列举了很多函数的选取，都比较常规，这里不再赘述。论文所采用的函数如下所示:</p><script type="math/tex; mode=display">\left\{\begin{aligned} &e'_{ijm}=\operatorname{ReLU}(\theta_m\cdot(\mathbf{x}_j-\mathbf{x}_i)+\boldsymbol{\phi}_m\cdot\mathbf{x}_i),\\&x'_{im} =\max\limits_{j:(i,j)\in\mathcal{E}}e'_{ijm},\end{aligned}\right.</script><p>不同于 PointNet 中共享的 MLP ，这种特征提取方式考虑了边特征。论文中说可以用共享 MLP 实现，但我还没想明白如何做到的。</p><h2 id="动态图更新（Dynamic-Graph-Update）"><a href="#动态图更新（Dynamic-Graph-Update）" class="headerlink" title="动态图更新（Dynamic Graph Update）"></a>动态图更新（Dynamic Graph Update）</h2><p>论文再次强调了在特征空间中定义图形的优势，即使得感受野和点云直径一样大，并且是稀疏的。用人话说就是不局限在周边点，还会将点云中其它具有相似特征的点纳入到感受野中。在具体实现中，计算了特征空间中的成对距离矩阵，从而为每个点提取最近的 $k$ 个点。</p><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><p>主要包括<strong>置换不变性</strong>和<strong>平移不变性</strong>。置换不变性就不必多说了，平移不变性则来自于 $h$ 函数。若对点云进行平移操作 $T$ ，则特征值变为：</p><script type="math/tex; mode=display">\begin{aligned}e'_{ijm} &=\operatorname{ReLU}(\theta_m\cdot(\mathbf{x}_j+T-(\mathbf{x}_i+T))+\boldsymbol{\phi}_m\cdot(\mathbf{x}_i+T))\\&=\operatorname{ReLU}(\theta_m\cdot(\mathbf{x}_j-\mathbf{x}_i)+\boldsymbol{\phi}_m\cdot(\mathbf{x}_i+T))\end{aligned}</script><p>当 $\boldsymbol{\phi}_m=0$ 时，算子对平移是完全不变的。然而这会导致模型的简化，patches 的位置信息被忽略。以 $\mathbf{x}_j-\mathbf{x}_i$ 和 $\mathbf{x}_i$ 作为输入，既能保留全局形状信息，也能考虑到局部几何关系。</p><h1 id="三、模型架构"><a href="#三、模型架构" class="headerlink" title="三、模型架构"></a>三、模型架构</h1><p><img src="/2023/06/08/DGCNN/image-20230608215922553.png" alt="image-20230608215922553" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><h2 id="变换块（Point-cloud-transform-block）"><a href="#变换块（Point-cloud-transform-block）" class="headerlink" title="变换块（Point cloud transform block）"></a>变换块（Point cloud transform block）</h2><p><img src="/2023/06/08/DGCNN/image-20230608223703797.png" alt="image-20230608223703797" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><p>在架构的最开始，对点云应用一个 $3\times 3$ 的矩阵变换以将其对齐。这和 PointNet 中的 T-Net 想法类似。为了学习到变换矩阵参数，构建了 $k$ 近邻图，并提取了每个点与其相邻点的坐标差张量。</p><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>输入为变换后 $n$ 个点的坐标，在 EdgeConv 中为每个点计算大小为 $k$ 的边特征集合，通过 MLP 扩展并聚合每个集合中的特征。不同于 PointNet++ 里的下采样，EdgeConv 并不改变点的大小和顺序，因此在多级特征组合的时候更为便利。</p><p>四个 EdgeConv 层使用了三个共享的全连接层 $(64,64,128,256)$ ，并根据每个 EdgeConv 输出的特征重新计算图，将其应用于下一层。将这几层的输出连接后得到 $512$ 维的特征，通过一个 MLP 和池化操作将其扩展到 $1024$ 维，并进行池化操作，最终通过一系列 MLP 得到点云全局特征。</p><p>对于超参数 $k$ 的选取，采用了留出验证的方式来评估不同 $k$ 对模型性能的影响。</p><h2 id="分割"><a href="#分割" class="headerlink" title="分割"></a>分割</h2><p>分割不同于分类的点无非在于需要同时用到每个点的全局信息和局部信息。论文采用了非常类似于 PointNet 的方法，将多层 EdgeConv 得到的全局特征（和分类部分类似）与 MLP 处理后的分类张量（categorical vector） 相连接，得到 $1088$ 维的特征，并与前面每一层 EdgeConv 的输出相连接。最后通过一些列 MLP 将特征压缩到需要的维数。</p><p>有待确认的是，架构图中的 categorical vector 具体来自于哪一层，论文中似乎没有具体说明。</p><h1 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h1><p>关于 DGCNN ，主要需要关注的有以下几点：</p><ul><li>考虑了点云的拓扑结构（个人觉得 PointNet++ 实际上也包含了简单的拓扑关系，但 DGCNN 的动态图使得其可能学到的更多），关注了<strong>边特征</strong>；</li><li>EdgeConv 通过 MLP 提取边特征，通过池化来确保邻域内的置换不变性；</li><li>图的构建基于<strong>特征空间</strong>，在每一层对图进行更新，即所谓的<strong>动态图</strong>。这种方式让感受野变得更大、更稀疏；</li><li>EdgeConv 很容易嵌入到其它网络中；</li><li>整体架构类似于 PointNet ，也就是用 EdgeConv 替换了 PointNet 中的共享 MLP 层；</li></ul><p>与 PointNet 及 PointNet++ 的对比：</p><ul><li>PointNet 是 DGCNN 的一个特例，即当 $k=1$ 时，边集为空集，边缘函数 $h$ 为 $h<em>{\Theta}(\mathbf{x}_i,\mathbf{x}_j)=h</em>{\Theta}(\mathbf{x}_i)$ 。换言之， PointNet 是不考虑边特征、不考虑拓扑关系的 DGCNN ；</li><li>PointNet++ 的主要组件是 SA 层，分为下采样和 PointNet 层，每一次输出后点数减少；EdgeConv 也考虑了点的邻域，但不改变点数，因此在特征组合时无需上采样。当然 PointNet++ 也可以取消采样层从而保持点数不变，但这不是分层的本意；</li><li>PointNet++ 利用 PointNet 层来聚合局部信息， PointNet 能够对邻域内每个点特征进行编码然后池化；EdgeConv 则对边特征进行编码，而非每个点单独的特征；</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>EC-Net 论文阅读笔记</title>
    <link href="/2023/05/31/EC-Net/"/>
    <url>/2023/05/31/EC-Net/</url>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/pdf/1807.06010.pdf">EC-Net: an Edge-aware Point set Consolidation Network</a></p><h1 id="一、摘要及引言"><a href="#一、摘要及引言" class="headerlink" title="一、摘要及引言"></a>一、摘要及引言</h1><p>点云整合（point cloud consolidation）是将点云“按摩”到表面上的过程，去噪、补全、重采样等等都属于其一部分。目前数据驱动方法展现出了很好的性能，但它们忽略了 3D 对象的锐利特征。该论文提出了第一个用于边缘感知整合网络 EC-Net ，其在 PointNet 的启发下，通过将坐标转换为深层特征并进行特征扩展产生更多点。同时论文提出了一种仅适用于点云的 patch 提取方案，以便提取 patch 并在训练和测试阶段共同使用。</p><span id="more"></span><p>此外，为了使得网络具有<strong>边缘感知</strong>能力，论文将边缘和网格三角形信息同 patch 相关联，通过回归<strong>点到边缘的距离</strong>以及点坐标来训练网络。更重要的是，论文通过一种新颖的 edge-ware 联合损失函数，可以有效地比较输出点和基准 3D 网格。该损失函数鼓励输出点靠近底层表面和边缘，并更均匀地分布在表面上。</p><h1 id="二、方法"><a href="#二、方法" class="headerlink" title="二、方法"></a>二、方法</h1><h2 id="训练数据准备"><a href="#训练数据准备" class="headerlink" title="训练数据准备"></a>训练数据准备</h2><p>论文从 ShapeNet 和其它在线存储库收集 3D 网格 ，包括简单的 3D 形状、机械零件和椅子等日常用品。并且采用了手动绘制折线的方式来标记网格上的锐利边缘，用于学习点到边缘的距离，如下图所示。</p><p><img src="/2023/05/31/EC-Net/9914334e1a334b6aa2fb96ea8b3c64f7.png" alt="网格边缘标记" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="虚拟扫描"><a href="#虚拟扫描" class="headerlink" title="虚拟扫描"></a>虚拟扫描</h3><p>为了从 3D 网格获取点云，论文采用了虚拟扫描的方式，具体来说。首先将网格归一化到 $\left[-1,+1\right]^3$ 单位距离空间里，并在物体周围水平均匀的布置 30 个虚拟相机（视角为 50°），相机距离物体中心两个单位距离，同时随机地扰动相机位置（向上或向下）。之后，通过渲染出网格对象的深度图并为深度值和像素位置添加量化噪声，最后反向投影每个像素得到点云。</p><p>这种方式模拟了真实场景里的扫描仪，比一般的下采样方法更加贴合实际。其特点是存在线状的点分布（下图左），离相机越近的平面采样点越密集（下图右），同时具有随机误差。</p><p><img src="/2023/05/31/EC-Net/2a1c179521514327bbf9b1b4f61402ab.png" alt="虚拟扫描" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="局部区域提取"><a href="#局部区域提取" class="headerlink" title="局部区域提取"></a>局部区域提取</h3><p>提取 patch 的依据是测地线距离，因为采用欧氏距离可能导致相邻点位于薄表面的两侧。具体的提取步骤如下：</p><ul><li><img src="/2023/05/31/EC-Net/f19afa3e9ca74fdc978749eeb712767f.png" alt="在这里插入图片描述" style="zoom:90%;float:right;padding-left:30pt">首先将每个点视为节点创建邻接图，图中每个点与其 $k$ 近邻点（$k=10$）相连，如右图所示。边权重设置为两点之间的欧氏距离；</li><li>随机选择 $m=100$ 个点作为 patch 的中心点。对于每个选定的点，通过 Dijkstra 算法找到 $2048$ 个在<strong>邻接图上</strong>最近的点；</li><li>在 $2048$ 个点里随机选取 $\hat{N}=1024$ 个点，从而引入随机性；</li><li>将点坐标归一化到单位球内，坐标重心为原点；</li><li>对于训练所用的 patch ，论文还找到了其附近相关联的网格三角形以及标记的边缘线作为基准信息。</li></ul><h2 id="边缘感知的点集整合网络"><a href="#边缘感知的点集整合网络" class="headerlink" title="边缘感知的点集整合网络"></a>边缘感知的点集整合网络</h2><h3 id="特征嵌入及扩展"><a href="#特征嵌入及扩展" class="headerlink" title="特征嵌入及扩展"></a>特征嵌入及扩展</h3><p>该组件首先使用 PointNet++ 将每个点周围的局部信息映射到 $D$ 维特征向量中（论文实验取 $D=256$ ）。考虑到 patch 边缘点的局部信息不准确，论文只保留了 $N = \frac{\hat{N}}{2}$ 个最接近 patch 中心的点对应的特征向量，因此特征嵌入组件的输入为 $N\times 3$ 的张量。</p><p>下图为特征嵌入部分的详细结构，其中在四个级别分别采用了 $0.1、0.2、0.4、0.6$ 的分组半径来提取局部特征，这四个层次对应的点样本数分别为 $N,\frac{N}{2},\frac{N}{4},\frac{N}{8}$ 。这里虽然写的是 conv 层，但其实就是 PointNet++ 中的 SA 层。其特征组合方式参考了 PU-Net 。</p><p><img src="/2023/05/31/EC-Net/537dcf63ed6d4f3f9c8a8729657f540c.png" alt="在这里插入图片描述" style="zoom:70%;display: block; margin-left: auto; margin-right: auto;"></p><p>特征扩展部分和 PU-Net 一致，只不过在 PU-Net 中的 $1\times1$ 卷积，在这里也统一写成了卷积层。特征扩展部分的输出为 $rN\times128$ 的张量。</p><p><img src="/2023/05/31/EC-Net/image-20230526201933967.png" alt="image-20230526201933967" style="zoom:70%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="边缘距离回归"><a href="#边缘距离回归" class="headerlink" title="边缘距离回归"></a>边缘距离回归</h3><p>这一组件将回归每个点到边缘的距离，从而进行边缘点识别。回归距离是点到最近的标记边缘的距离。具体来说，首先通过 MLP 从扩展特征中提取距离特征 $f_{dist}$ ，然后再通过另一个 MLP 回归点到边缘的距离（但是既然点是无序的，训练样本中的点到边缘距离如何排列？或者随机排列？）。</p><p><img src="/2023/05/31/EC-Net/image-20230526202725949.png" alt="image-20230526202725949" style="zoom:70%;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="坐标回归"><a href="#坐标回归" class="headerlink" title="坐标回归"></a>坐标回归</h3><p>基于边缘距离回归组件中的 $f_{dist}$ 特征，利用两个 MLP 回归点坐标。在这里论文采用了只回归<strong>残差坐标</strong>的方式，也就是上采样点相对当前点的偏移值，这样预测值会比较小，有利于网络学习。另外，论文提到除了最后用于回归的 MLP 层，其余所有卷积和 MLP 层后面都接的是 RELU 激活函数。</p><h3 id="边缘点识别"><a href="#边缘点识别" class="headerlink" title="边缘点识别"></a>边缘点识别</h3><p>记 $d<em>i$ 为输出点 $x_i$ 到边缘的距离，则边缘点集为 $\mathcal{S}</em>{\Delta<em>d}={x_i }</em>{d_i&lt;\Delta_d}$ 。该组件在训练和测试阶段都会执行。</p><h2 id="边缘感知的联合损失函数"><a href="#边缘感知的联合损失函数" class="headerlink" title="边缘感知的联合损失函数"></a>边缘感知的联合损失函数</h2><p><img src="/2023/05/31/EC-Net/d39191aed6af41fab68697431bc668b7.png" alt="EC-Net架构图" style="zoom:70%;display: block; margin-left: auto; margin-right: auto;"></p><p>损失函数的设计主要基于以下目标：1）靠近底层物体表面；2）靠近标记边缘；3）均匀分布</p><h3 id="表面损失（Surface-Loss）"><a href="#表面损失（Surface-Loss）" class="headerlink" title="表面损失（Surface Loss）"></a>表面损失（Surface Loss）</h3><p>表面损失定义为从每个输出点 $x_i$ 到与 patch 关联的所有网格三角形 $T$ 的最短距离：</p><script type="math/tex; mode=display">d_T(x_i,T)=\min_{t\in T}d_t(x_i,t),</script><p>为了计算 $d_t$ ，需要考虑其中情况，因为三角形 $t$ 上离 $x_i$ 最近的点可能位于三角形的顶点、边缘或面内。计算所有输出点的 $d_T$ ，相加得到表面损失：</p><script type="math/tex; mode=display">L_{surf}=\frac{1}{\widetilde{N}}\sum_{1\leq i \leq \widetilde{N}}d_T^2(x_i,T),</script><p>其中 $\widetilde{N}=rN$ ，为每个 patch 包含的点数。</p><h3 id="边缘损失（Edge-Loss）"><a href="#边缘损失（Edge-Loss）" class="headerlink" title="边缘损失（Edge Loss）"></a>边缘损失（Edge Loss）</h3><p>边缘损失鼓励输出点位于靠近边缘的位置。将与 patch 相关的一组带注释的边缘段记作 $E$ ，定义边缘损失为从每个边缘点（边缘检测得到）到所有 patch 中的边缘段的最短距离的最小值：</p><script type="math/tex; mode=display">d_E(x_i,E)=\min_{e\in E}d_e(x_i,e)，</script><p>其中 $d_e(xi,e)$ 是边缘点 $x_i$ 到边段 $e\in E$ 上任意点的最短距离。将所有边缘点的 $dE$ 求和，得到边缘损失：</p><script type="math/tex; mode=display">L_{edge}=\frac{\sum_{x_i\in \mathcal{S}_{\Delta_d}}d^2_E(x_i,E)}{\left|\mathcal{S}_{\Delta_d} \right|},</script><p>总的思路和表面损失一样，只是表面损失针对所有点，边缘损失只针对边缘点。</p><h3 id="排斥损失（Repulsion-Loss）"><a href="#排斥损失（Repulsion-Loss）" class="headerlink" title="排斥损失（Repulsion Loss）"></a>排斥损失（Repulsion Loss）</h3><p>排斥损失鼓励输出点更均匀分布。对于输出点 $x_i,i=1,\dots,\widetilde{N}$ ，排斥损失定义为：</p><script type="math/tex; mode=display">L_{repl}=\frac{1}{\widetilde{N}\cdot K}\sum_{1\leq i\leq \widetilde{N}}\ \sum_{i'\in \mathcal{K}(i)}\eta(\left\|x_{i'}-x_i \right\|),</script><p>其中 $\mathcal{K}(i)$ 是 $x_i$ 的 $K$ 最近邻域的索引集合（论文设 $K=4$ ），而 $\eta(r)=\max(0,h^2-r^2)$ 是惩罚函数，两点越近则惩罚项越大。当距离大于 $h$ 时，则不起作用。</p><h3 id="边缘距离回归损失（Edge-Distance-Regression-Loss）"><a href="#边缘距离回归损失（Edge-Distance-Regression-Loss）" class="headerlink" title="边缘距离回归损失（Edge Distance Regression Loss）"></a>边缘距离回归损失（Edge Distance Regression Loss）</h3><p>边缘距离回归损失引导网络回归 $rN$ 个输出点到边缘的距离 $d$ 。由于并不是每个点都靠近标记的边缘，因此回归损失应在一定距离截断，以免损失过大：</p><script type="math/tex; mode=display">L_{regr} = \frac{1}{\widetilde{N}}\sum_{1\leq i \leq \widetilde{N}}\left[\mathcal{T}_b(d_E(x_i,E))-\mathcal{T}_b(d_i) \right]^2</script><h3 id="端到端训练"><a href="#端到端训练" class="headerlink" title="端到端训练"></a>端到端训练</h3><p>联合损失函数定义为：</p><script type="math/tex; mode=display">\mathcal{L}=L_{surf}+L_{repl}+\alpha L_{edge}+\beta L_{regr}</script><h2 id="实施细节"><a href="#实施细节" class="headerlink" title="实施细节"></a>实施细节</h2><h3 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h3><p>在训练之前，将每个输入补丁归一化到 $[-1, 1]^3$。然后通过一系列运算符在网络中即时对每个 patch 做数据增强：1）随机旋转；2）在所有维度上随机平移 $-0.2$ 到 $0.2$ ；3）随机缩放 $0.8$ 到 $1.2$ ；4）添加高斯噪声，参数 $\sigma$ 设置为补丁边界框大小的 $0.5\%$；随机调整补丁中点的顺序。</p><h3 id="网络推理"><a href="#网络推理" class="headerlink" title="网络推理"></a>网络推理</h3><p>这里主要阐述如何通过训练好的网络以 patch-wise （在图像分割中指介于像素和图像级别的区域）方式处理点云。</p><p>首先在测试点云中提取点集作为质心，以便使用 2.1 中的过程提取点块。为了使 patch 更均匀地分布在点云上（点云总点数为 $N<em>{pt}$ ，patch 点数为 $N$ ），使用最远点采样法，在测试点云中随机找到 $M = \beta \frac{N</em>{pt}}{N} $ 个点，这意味着平均每个点被采样了 $\beta$ 次，也就是平均每个点出现在 $\beta$ 个不同的 patch 中。</p><p>提取补丁后，将它们输入网络并应用网络生成 3D 坐标和点到边缘的距离，同时进行边缘点识别。与训练阶段的边缘点识别不同，这里设置了一个较小的阈值 $d =0.05$ 。在训练中则使用较大的 $d$ ，这是因为训练是一个优化过程，网络需要通过更多的点来学习识别边缘点。</p><h3 id="表面重建"><a href="#表面重建" class="headerlink" title="表面重建"></a>表面重建</h3><p>首先为网络的输出点构建一个 $k$ 近邻图。对于边缘点过滤，通过 RANSAC 拟合线段实现；对于表面点过滤，通过<strong>边缘停止</strong>的方式在 $k$ 近邻图中找到一小组附近的点，然后使用 PCA 拟合平面来实现。其中边缘停止指的是在到达边缘点时停止广度优先搜索（breath-first growth），这避免了越过边缘将无关点纳入。</p><p>重复多次以上步骤，最后通过纳入一些间隙中的原始点来填充边缘点和表面点之间的微小间隔，并通过投掷飞镖法（dart throwing）来添加新点。Dart throwing 是一种随机采样方法，在已有点的基础上，若新点离已有点太近（飞到镖盘内），则重新选取，直至点数达到要求。</p><p>为了进一步重建表面，论文采用了 EAR 中的方法对点云进行下采样并计算法线，使用球旋转（ball pivoting）或筛选泊松表面重建（screened Poisson surface reconstruction）来重建表面，并使用双边法线滤波（bilateral normal filtering）清洗生成的网格。这里提到的几个概念似乎属于三维重建，暂且将其相关论文放在这里，以后如果想起来学一下：</p><ol><li>EAR：Edge-aware point set resampling</li><li>ball pivoting：The ballpivoting algorithm for surface reconstruction</li><li>screened Poisson surface reconstruction：Screened poisson surface reconstruction.</li><li>bilateral normal filtering：Bilateral normal filtering for mesh denoising</li></ol><h1 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h1><p>EC-Net 主要内容可以概括如下：</p><ul><li>为了使网络具有边缘感知能力，通过手动标注的方式在网格上标记边缘；</li><li>沿用了 PU-Net 中的特征嵌入和特征扩展模块</li><li>网络同时输出点到边缘距离、边缘点、上采样点，并分别设计了边缘距离损失、边缘损失、排斥损失以及表面损失，得到联合损失函数，用于端到端训练；</li><li>采用回归残差坐标的方式来得到上采样点坐标</li></ul><p>EC-Net 主要存在以下不足：</p><ul><li>和 PU-Net 一样不具备补全能力；</li><li>对于严重欠采样的微小结构，网络难以重建其锐利边缘；</li><li>patch 点数固定，导致随着点云密度变化，其大小发生显著改变，难以适应不同规模的结构</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
      <tag>点云上采样</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PU-Net 论文阅读笔记</title>
    <link href="/2023/05/23/PU-Net/"/>
    <url>/2023/05/23/PU-Net/</url>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/pdf/1801.06761.pdf">PU-Net: Point Cloud Upsampling Network</a></p><h1 id="一、摘要"><a href="#一、摘要" class="headerlink" title="一、摘要"></a>一、摘要</h1><p>由于数据的稀疏性和不规则性，使用深度网络学习和分析 3D 点云具有挑战性。论文提出了一种数据驱动的点云上采样技术，即 PU-Net ，其关键思想是学习每个点的<strong>多级特征</strong>，并通过多层卷积单元<strong>扩展特征</strong>，然后将这些特征重建为上采样点集。网络应用于 patch-level，通过联合损失函数驱使上采样点以均匀的方式分布在隐式表面上。最后论文通过一系列实验展现网络的效果，并阐述了其局限性。</p><span id="more"></span><h1 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h1><p>论文中将点云上采样的方法主要分为两类：<strong>基于优化</strong>（optimization-based）的方法和<strong>基于深度学习</strong>（deep-learning-based）的方法。</p><h2 id="基于优化的方法"><a href="#基于优化的方法" class="headerlink" title="基于优化的方法"></a>基于优化的方法</h2><h3 id="移动最小二乘法（Moving-Least-Squares-MLS）"><a href="#移动最小二乘法（Moving-Least-Squares-MLS）" class="headerlink" title="移动最小二乘法（Moving Least Squares, MLS）"></a>移动最小二乘法（Moving Least Squares, MLS）</h3><p>参考论文：Computing and Rendering Point Set Surfaces</p><p>通过已有点的<strong>局部</strong>信息估计平滑表面，并将其<strong>投影</strong>到表面上，可以实现点云的平滑，同时因为描述了表面结构，可以实现上采样和下采样。假设从表面 $S$ 上获取到点 $p_i \in \mathbb{R}^3,i\in {1,2,\dots,N }$ ，目标是将 $S$ 附近的点 $r$ 投影到近似表达 $p_i$ 的二维表面 $S_P$ 上。</p><p><img src="/2023/05/23/PU-Net/1bf0783fb26a47a8900a482c8de667b0.png" alt="在这里插入图片描述" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p><p>首先找到 $r$ 的局部参考域（Local Reference Domain） $H$ ，$H$ 是一个平面，可以通过其单位法向量 $n$ 以及原点到平面的距离 $D$ 共同定义，即 $H = {x|\left&lt; n,x \right&gt; - D = 0,x\in\mathbb{R}^3  }$ 。参考域 $H$ 通过<strong>最小化加权距离平方和</strong>得到：</p><script type="math/tex; mode=display">\sum_{i=1}^{N}(\left< n,p_i \right>-D)^2\theta\left(\| p_i - q \|\right)</script><p>其中 $\theta$ 是一个平滑的单调递减函数，在整个空间上都是正的，如 $\theta(d)=e^{\frac{d^2}{h^2}}$ 。考虑到点到平面距离同样可以转换到 $q$ 点上：$(\left&lt; n,p_i \right&gt;-D)^2 = (\left&lt; n,p_i-q \right&gt;)^2$ ，将 $q$ 点坐标写作 $r+tn$ ，则式子改写为：</p><script type="math/tex; mode=display">\sum_{i=1}^{N}(\left< n,p_i-r-tn \right>)^2\theta\left(\| p_i - r-tn \|\right)</script><p>函数的因变量为 $t$ 和 $n$ ，可以通过非线性最小二乘的方式求得。</p><p>然后计算局部图（Local Map），即通过多项式近似来拟合曲面。如上图所示，令 $f_i$ 为 $p_i$ 到 $H$ 的距离，即 $f_i= n \cdot (p_i-q)$ 。设多项式函数为 $g$ ，则其系数通过最小化下式得到：</p><script type="math/tex; mode=display">\sum_{i=1}^{N}(g(x_i.y_i)-f_i)^2\theta(\| p_i - q \|)</script><p>这里 $(x_i,y_i)$ 是 $p_i$ 点投影到 $H$ 平面的坐标， $q$ 为原点。总而言之，从 $H$ 的视角来看，其它点分布在其上下，利用多项式拟合了一个凹凸不平的曲面 $S_P$ 来接近所有点，其中离原点 $q$ 越远的点权重越低。</p><p>最后进行投影操作。$r$ 点的投影即为为原 $g,\mathrm{g}$ 点处的多项式值，即：</p><script type="math/tex; mode=display">\mathscr{P}(r)=q + g(0,0)n = r+(t+g(0,0))n</script><p>该算法涉及到两次最小二乘，其中第一次的相对复杂一些，可能需要一些假设或技巧来求解，这里不展开。</p><h3 id="局部最佳投影（Local-Optimal-Projection-LOP）"><a href="#局部最佳投影（Local-Optimal-Projection-LOP）" class="headerlink" title="局部最佳投影（Local Optimal Projection, LOP）"></a>局部最佳投影（Local Optimal Projection, LOP）</h3><p>参考论文：Parameterization-free Projection for Geometry Reconstruction</p><p>MLS 方法假设局部平面可以很好地近似局部几何形状，并不能适用于复杂形状。因此设计一个新的不使用局部方向信息（参考平面或法线）的算子来解决这一问题，也就是 LOP 算子。</p><p>问题仍然是一个投影问题：给定数据点集 $P = {p<em>j}</em>{j\in J}\subset \mathbb{R}^3$ ，将任意点集 $X^{(0)}={x^{(0)}<em>i}</em>{i\in I}\subset \mathbb{R}^3$ 投影到 $P$ 上，投影点集为 $Q = {q<em>i}</em>{i\in I}$ 。</p><p>为了使投影后点逼近 $P$ 的几何形状，且考虑到距离越远的点作用越弱，定义代价函数 $E_1$ 表达式为：</p><script type="math/tex; mode=display">E_1(X,P,Q)=\sum_{i\in I}\sum_{j\in J}\|x_i-p_j\|\theta(\|q_i-p_j\|)</script><p>同时为了避免投影后点太靠近彼此，定义代价函数 $E_2$ 表达式为：</p><script type="math/tex; mode=display">E_2(X,Q)=\sum_{i'\in I}\lambda_{i'}\sum_{i\in I \setminus \{i'\}}\eta(\|x_{i'}-q_i \|)\theta(\|q_{i'}-q_i \|)</script><p>其中 $\eta(r)$ 同样是一个递减函数，对彼此接近的 $q<em>{i}$ 进行惩罚，使得投影后分布均匀。通常为 $\eta(r)=1/3r^3$ 。 ${\lambda_i}</em>{i\in I}$ 是一个平衡项，用 $\Lambda$ 表示。若 $\Lambda$ 较大，则以形状不近似的代价去追求分布均匀；若 $\Lambda$ 较小，则以分布不均的代价去追求形状近似。论文在后续对参数的选取做了比较复杂的证明，但实在是看不懂。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>MLS 和 LOP 是较为常用的基于优化的方法，但它们假设物体表面为光滑流形，对边缘的还原较差。也有基于边缘感知的方法，但依赖于好的参数；总的来说，基于优化的方法都不是数据驱动的，严重依赖先验知识。</p><h2 id="基于深度学习的方法"><a href="#基于深度学习的方法" class="headerlink" title="基于深度学习的方法"></a>基于深度学习的方法</h2><p>论文：此前没有专注于点云上采样的神经网络。</p><h1 id="三、网络架构"><a href="#三、网络架构" class="headerlink" title="三、网络架构"></a>三、网络架构</h1><h2 id="局部区域生成（Patch-Extraction）"><a href="#局部区域生成（Patch-Extraction）" class="headerlink" title="局部区域生成（Patch Extraction）"></a>局部区域生成（Patch Extraction）</h2><p>考虑到上采样需要利用物体的局部几何信息，论文采用了 patch-based 的方式，也就是从物体点云中收集各种形状的局部区域来训练网络。</p><p>具体来说，首先从物体表面随机选取 $M$ 个点，并从每个选择的点开始，沿着表面生长出一个 patch 。并规定在每个 patch 内，任意两点之间的测地线距离小于一定的阈值 $d$ 。随后，论文使用<a href="# 泊松盘采样">泊松盘采样</a>（Poisson-disk Sampling），从每个 patch 上随机生成 $\hat{N}$ 个点作为该 patch 上参考基准（ground truth）点。同时为了利用到局部和全局信息，论文通过改变 $d$ 的大小来提取不同比例和密度的 patch 。</p><h3 id="泊松盘采样"><a href="#泊松盘采样" class="headerlink" title="泊松盘采样"></a>泊松盘采样</h3><p>泊松盘采样的目的是从原始点中采样一部分点，使得任意两点间距离都不会太近。泊松盘采样可以用于随机生成一组分布均匀的点，也可以从已有的点中进行采样。下面主要介绍后者的方法。</p><ol><li>初始化参考点列表：在每个 patch 上初始化一个参考点列表，这个列表最开始为空；</li><li>选择第一个参考点：在每个 patch 上随机选择一个点作为第一个参考点，并将其添加到参考点列表中；</li><li>生成新参考点：在距离第一个参考点一定距离范围内，随机生成一个新的参考点，并将其添加到参考点列表中。这个距离范围通常由两个参数决定，一个是最小距离 $r$ ，表示新生成的点与已有参考点之间的最小距离；另一个是采样次数 $k$ ，表示在一个点附近最多采样 $k$ 个点。</li><li>验证新参考点：为了避免新参考点太接近已有的参考点，需要对新生成的参考点进行验证。如果新参考点与其他参考点之间的距离都大于等于 $r$ ，则接受新参考点，并继续进行步骤 3 。否则，舍弃新参考点，重新生成一个新的参考点，并重复步骤 4 ，直到找到符合条件的新参考点。</li><li>重复步骤 3 和 4 ，直到达到预设的参考点数量或者无法再添加新的参考点为止。</li></ol><p>泊松盘采样算法是一个计算密集型的过程，因此需要采用高效的算法来实现。通常，可以使用基于网格的算法（例如网格边长为 $r$ ，则非相邻的网格内两点距离一定大于 $r$ ）或基于随机抽样的算法来实现泊松盘采样。</p><h2 id="点特征嵌入（Point-Feature-Embedding）"><a href="#点特征嵌入（Point-Feature-Embedding）" class="headerlink" title="点特征嵌入（Point Feature Embedding）"></a>点特征嵌入（Point Feature Embedding）</h2><p>为了从 patch 中学习局部和全局几何上下文，考虑以下两种特征学习策略，它们的优点相互补充。</p><h3 id="分层特征学习"><a href="#分层特征学习" class="headerlink" title="分层特征学习"></a>分层特征学习</h3><p>论文采用了 <a href="https://zcliangyue.github.io/2023/05/23/PointNet++/">PointNet++ </a>中提出的层级特征学习机制作为网络的最前端，从而在不同尺度上提取点云的局部和全局特征。同时因为点云上采样需要涉及到更多的局部上下文，特地在每个级别中使用了相对较小的分组半径（grouping radius）。关于分层特征学习以及 PointNet++ 相关内容，参考笔记 <a href="https://zcliangyue.github.io/2023/05/21/pointnet/">PointNet </a>和<a href="https://zcliangyue.github.io/2023/05/23/PointNet++/">PointNet++ </a> 。</p><h3 id="多级特征聚合"><a href="#多级特征聚合" class="headerlink" title="多级特征聚合"></a>多级特征聚合</h3><p>网络中较低层对应较小尺度的局部特征，较高层对应较大尺度的局部特征。在 pointnet++ 中采用了 skip link 来联合多级特征，但论文在实验中发现“这种自上而下的传播”方法不适合上采样问题（但似乎没有给出具体原因）。因此论文给出的方法是直接组合来自不同级别的特征，并让网络学习每个级别的重要性。</p><p>如下图的 Point Feature Embedding 部分，补丁的输入为大小 $(N,3)$ 的坐标矩阵，在分层特征提取的过程中不断被下采样，同时特征被提取为不同的尺寸。为了融合不同特征，将每一层的特征上采样（反距离加权插值）为行数为 $N$ 的特征矩阵，并利用 $1\times 1$ 卷积将特征长度减少为 $C$ ，最后直接拼接起来得到嵌入点特征 $f$ 。</p><p><img src="/2023/05/23/PU-Net/44e5a25cd1d046ec942a972b828d05ad.png" alt="PU-Net网络结构" style="zoom:60%;padding:30pt;display: block; margin-left: auto; margin-right: auto;"></p><h2 id="特征扩展（Feature-Expansion）"><a href="#特征扩展（Feature-Expansion）" class="headerlink" title="特征扩展（Feature Expansion）"></a>特征扩展（Feature Expansion）</h2><p>在点特征嵌入组件之后，论文扩展了特征空间中的特征数量，从而扩大了点的数量，达到上采样的目的。假设 $f$ 的维度为 $N\times \widetilde{C}$ ，$N$为输入点数， $\widetilde{C}$ 为嵌入特征的特征维度。特征扩展操作将输出维度为 $rN \times \widetilde{C}_2$ 的特征 $f’$，其中 $r$ 是上采样率，$\widetilde{C}_2$ 是新的特征维度。本质上，这类似于图像相关任务中的特征上采样，在图像中可以通过反卷积（也称为转置卷积）或插值来完成。然而，由于点的不规则性和无序性，将这些操作应用于点云并非易事。因此，论文提出了一种基于<strong>亚像素卷积层</strong>的有效特征扩展操作。该操作可以表示为：</p><script type="math/tex; mode=display">f'=\mathcal{RS}(\ [\ \mathcal{C}^2_1(\mathcal{C}^1_1(f)),\dots,\mathcal{C}^2_r(\mathcal{C}^1_r(f))\ ]\ )</script><p>其中 $\mathcal{C}<em>{i}^1$ 和 $\mathcal{C}</em>{i}^2$ 是两个独立的 $1\times1$ 卷积，$\mathcal{RS}$ 是一个 reshape 操作，将大小为 $N\times r\widetilde{C}_2$ 的张量转换成大小为 $rN\times\widetilde{C}_2$ 的张量（以此实现点数的放大）。</p><p>论文提到，嵌入特征 $f$ 已经聚合了来自邻域点的相关信息，因此在特征扩展时无需明确考虑空间信息。同时为了让扩张的特征相关性降低（避免生成的点距离太近），因此在 $\mathcal{C}<em>{i}^1$ 的基础上添加了 $\mathcal{C}</em>{i}^2$ 。这种特征扩展可以通过对 $r$ 个特征集应用分离卷积实现（如上图所示），也可以通过计算效率更高的分组卷积来实现。</p><p>关于分组卷积的概念，参考了飞浆的<a href="https://paddlepedia.readthedocs.io/en/latest/tutorials/CNN/convolution_operator/Group_Convolution.html">文档</a> 。简单来说，普通卷积有 $C_2$ 个，尺寸为 $h_1\times w_1\times C_1$ ，将大小为 $H_1\times W_1\times C_1$ 的输入张量转换为大小为 $H_2\times W_2\times C_2$ 的输出张量。分组卷积则将原始输入张量分割为 $g$ 个大小为 $H_1\times W_1\times \frac{C_1}{g}$ 的张量，对应地，将卷积核尺寸变为 $h_1\times w_1\times \frac{C_1}{g}$ ，卷积个数变为 $\frac{C_2}{g}$ ，使得输出尺寸为 $H_2\times W_2\times \frac{C_2}{g}$ 。最后将 $g$ 个输出拼接即可。如下图所示：</p><p><img src="/2023/05/23/PU-Net/37f39a858cd24513bdfccb33c9cdbf24.png" alt="在这里插入图片描述" style="zoom:100%;padding:30pt;display: block; margin-left: auto; margin-right: auto;"></p><p>普通卷积的参数量为 $h_1\times w_1 \times C_1\times C_2$ ，而分组卷积的参数量缩减为：</p><script type="math/tex; mode=display">h_1\times w_1\times \frac{C_1}{g} \times \frac{C_2}{g}\times g=h_1\times w_1 \times C_1\times C_2\times\frac{1}{g}</script><p>针对特征扩展问题，则将 $\widetilde{C}$ 视作通道数目，将其进行分组从而实现加速。</p><h2 id="坐标重建（Coordinate-Reconstruction）"><a href="#坐标重建（Coordinate-Reconstruction）" class="headerlink" title="坐标重建（Coordinate Reconstruction）"></a>坐标重建（Coordinate Reconstruction）</h2><p>得到 $rN\times\widetilde{C}_2$ 的张量后，将其重建为坐标值。论文采用了一系列全连接层来对每个点的特征回归 3D 坐标，最终输出 $rN\times3$ 的上采样坐标。</p><h1 id="四、端到端训练"><a href="#四、端到端训练" class="headerlink" title="四、端到端训练"></a>四、端到端训练</h1><h2 id="训练数据生成"><a href="#训练数据生成" class="headerlink" title="训练数据生成"></a>训练数据生成</h2><p>对于一个稀疏的输入点云，实际上有许多可行的输出点分布。因此论文采用了在每个训练时期以 $r$ 的下采样率从 ground truth 点集中随机采样的方法，生成一些列输入点集，从而为给定的稀疏输入点分布模拟出来许多可行的输出点分布（不应该是输入点分布么？）。同时该方法可以进一步扩大训练数据集。</p><h2 id="联合损失函数"><a href="#联合损失函数" class="headerlink" title="联合损失函数"></a>联合损失函数</h2><p>为了鼓励生成的点以更均匀的方式分布在底层对象表面上，论文提出了结合重建损失（Reconstruction Loss）和排斥损失（Repulsion Loss）的联合损失函数。</p><h3 id="重建损失函数"><a href="#重建损失函数" class="headerlink" title="重建损失函数"></a>重建损失函数</h3><p>对于两组点云之间的距离度量方法，主要有 CD（Chamfer Distance）和 EMD（Earth Mover’s Distance），下面分别做详细介绍，主要参考 <a href="https://arxiv.org/pdf/1612.00603.pdf">A Point Set Generation Network for 3D Object Reconstruction from a Single Image</a> 这篇文章。</p><h4 id="EMD"><a href="#EMD" class="headerlink" title="EMD"></a>EMD</h4><p>EMD 也称作“推土机距离”，通过定义“工作量”——即将一个分布搬运到和令一个分布相同所需的搬运量和搬运距离乘积总合——来衡量两组分布之间的相似性。数据的分布经常用直方图来表示，而对于点云，这个定义会简洁一些，目标是找到预测点云 $S<em>P\subseteq \mathbb{R}^3$ 和参考基准点 $S</em>{gt}\subseteq \mathbb{R}^3$ 之间的一个双向映射 $\phi$（既是单射又是满射，也就是一一对应的映射），使每个点与其映射的点之间的距离总和最小，也就是“搬运”的工作量最小即可：</p><script type="math/tex; mode=display">L_{rec} = d_{EMD}(S_p,S_{gt})=\underset{\phi:S_p\rightarrow S_{gt}}{\min}\sum_{x_i\in S_p}\|x_i-\phi(x_i) \|_2</script><p>虽然概念上简单，但是 EMD 是一个优化问题，运算量比较大，可以通过给每个点分配固定的时间量并在一定错误率内终止来加快运行速度。     </p><h4 id="CD"><a href="#CD" class="headerlink" title="CD"></a>CD</h4><p>CD 也称作“倒角距离”，定义为最近距离的平方和：</p><script type="math/tex; mode=display">d_{CD}(S_1,S_2)=\sum_{x\in S_1}\underset{y\in S_2}{\min}\|x-y\|^2_2+\sum_{y\in S_2}\underset{x\in S_1}{\min}\|y-x\|^2_2</script><p>“由于三角不等式不成立，严格意义上 $d_{CD}$ 并非距离函数”。关于文章中提到的这点，反例很容易举出。在网上博客大多会找到这样的版本：</p><script type="math/tex; mode=display">d_{CD}(S_1,S_2)=\frac{1}{\|S_1\|}\sum_{x\in S_1}\underset{y\in S_2}{\min}\|x-y\|^2_2+\frac{1}{\|S_2\|}\sum_{y\in S_2}\underset{x\in S_1}{\min}\|y-x\|^2_2</script><p>这个式子进一步考虑了两个点云数量不同的情况。</p><p>除了上述两种度量方式，还有此前在 PCL 笔记里记过的 Hausdorff 距离（点到点集的最小距离的最大值），但显然不太适用于这里。</p><h4 id="方法对比"><a href="#方法对比" class="headerlink" title="方法对比"></a>方法对比</h4><p>文章中用两种损失函数来计算一系列“平均形状”，从而对两者进行对比分析，如下图所示。</p><p><img src="/2023/05/23/PU-Net/7071501be5e84b49bb187fdad7ce74cb.png" alt="在这里插入图片描述" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p><p>平均形状的具体计算方法没有详细说明，只提到用随机梯度下降法来最小化距离函数。从结果来看，平均形状的点数应该是固定好的，并且有一个合适的初始位置。</p><p>观察图中的平均形状，论文给出了以下结论：</p><ol><li>在第一种和第二种情况下，只有一个连续变化的<strong>隐藏变量</strong>，即 (a) 中的圆半径和 (b) 中的弧段位置。EMD 粗略地捕获了对应于隐藏变量的平均值的形状。相比之下，CD 会产生一种模糊形状，其几何结构呈飞溅形状；</li><li>在后两种情况下，存在分类隐藏变量：正方形位于 (c) 的哪个角以及在条形 (d) 旁边是否有圆。CD 将少量的点分布在主体之外的正确位置；而 EMD 则严重扭曲了主体之外的点。</li></ol><p>总的来说，EMD 对主体形状的拟合能力更强，而 CD 对总体形状的保持能力更强。论文中采用了 EMD 。</p><h3 id="排斥损失（Repulsion-Loss）"><a href="#排斥损失（Repulsion-Loss）" class="headerlink" title="排斥损失（Repulsion Loss）"></a>排斥损失（Repulsion Loss）</h3><p>为了生成更加均匀分布的点，论文设计了排斥损失，表达式为：</p><script type="math/tex; mode=display">L_{rep}=\sum_{i=1}^{\hat{N}}\sum_{i'\in K(i)}\eta(\|x_{i'}-x_{i} \|)w(\|x_{i'}-x_{i} \|)</script><p>其中 $\hat{N}=rN$ ，是输出点的数量；$K(i)$ 是点 $x_i$ 的 $k$ 近邻点的索引集合；$\eta$ 称为排斥项，是一个递减函数，用于在两个点距离太近时对其惩罚；$w(r)=e^{-r^2/h^2}$ ，用于使惩罚项随距离快速衰减。这个表达式以及函数形式的选择参考了<a href="#局部最佳投影（Local Optimal Projection, LOP）">局部最佳投影（LOP）</a> 。</p><h3 id="联合函数"><a href="#联合函数" class="headerlink" title="联合函数"></a>联合函数</h3><p>最终得到联合损失函数如下式，其中 $\theta$ 表示网络中的参数，$\alpha$ 用于平衡重建损失和排斥损失，而 $\beta$ 表示权重的 $L_2$ 正则化项的乘数，用于降低模型参数值以防止过拟合。</p><script type="math/tex; mode=display">L(\theta)=L_{rec}+\alpha L_{rep}+\beta\|\theta\|^2</script><h1 id="五、实验"><a href="#五、实验" class="headerlink" title="五、实验"></a>五、实验</h1><p>现在还没跑过实验，先看看论文里咋做的。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>由于点云上采样没有公共基准，我们从 Visionair 存储库中收集了 $60$ 个不同模型的数据集，范围从光滑的非刚性物体（例如 Bunny）到陡峭的刚性物体（例如 Chair）。其中，我们随机抽取 $40$ 个进行训练，其余的用于 testing 。我们为每个训练对象裁剪 $100$ 个补丁，总共使用 $M = 4000$ 个补丁来训练网络。对于测试对象，我们使用蒙特卡洛随机采样方法在每个对象上采样 $5000$ 个点作为输入。为了进一步证明我们网络的泛化能力，我们直接在 SHREC15 数据集上测试我们训练有素的网络，该数据集包含来自 $50$ 个类别的 1200 个形状。具体来说，我们从每个类别中随机选择一个模型进行测试，考虑到每个类别包含 $24$ 个不同姿势的相似对象。至于 ModelNet40 和 ShapeNet ，我们发现由于网格质量低（例如，孔洞、自相交等），很难从这些对象中提取补丁。因此，我们使用它们进行测试；结果见补充材料。</p><h2 id="实施细节"><a href="#实施细节" class="headerlink" title="实施细节"></a>实施细节</h2><p>每个补丁的默认点数 $\hat{N}$ 为 $4096$，上采样率 $r$ 为 $4$。因此，每个输入补丁有 $1024$ 个点。为了避免过度拟合，我们通过随机旋转、移动和缩放数据来扩充数据。我们在点特征嵌入组件的四个级别中分别使用分组半径 $0.05、0.1、0.2$ 和 $0.3$ ，恢复特征的维数 $C$ 为 $64$。排斥损失中的参数 $k$ 和 $h$ 分别设置为 $5$ 和 $0.03$ 。平衡权重 $α$ 和 $β$ 分别设置为 $0.01$ 和 $10^{−5}$ 。实现基于 TensorFlow。为了优化，我们使用 Adam 算法训练网络 $120$ 个 epoch，mini-batch size 为 $28$ ，学习率为 $0.001$ 。训练在 NVIDIA TITAN Xp GPU 上花费了大约 $4.5$ 小时。</p><h2 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h2><p>为了定量评估输出点集的质量，我们制定了两个指标来衡量输出点与地面真值网格之间的偏差，以及输出点的分布均匀性。</p><p>对于表面偏差，我们为每个预测点 $x_i$ 在网格上找到最近的点 $x_i$ ，并计算它们之间的距离。然后我们计算所有点的均值和标准差作为我们的指标之一。</p><p>对于均匀性指标，我们在物体表面随机放置 $D$ 个大小相等的圆盘（在我们的实验中 $D = 9000$）并计算圆盘内点数的标准差。我们进一步归一化每个对象的密度，然后计算测试数据集中所有对象的点集的整体均匀性。因此，我们将磁盘面积百分比 $p$ 的归一化均匀系数 (NUC) 定义为：</p><script type="math/tex; mode=display">\begin{aligned}avg &= \frac{1}{K*D}\sum_{k=1}^K\sum_{i=1}^D\frac{n_i^k}{N^k*p},\\NUC &= \sqrt{\frac{1}{K*D}\sum_{k=1}^K\sum_{i=1}^D\left(\frac{n_i^k}{N^k*p}-avg\right)^2},\end{aligned}</script><p>其中 $n_i^k$ 是第 $k$ 个物体在第 $i$ 个圆盘内的点数，$N^k$ 是第 $k$ 个物体上的总点数，$K$ 是测试物体的总数，$p$ 是圆盘面积占总物体表面积的百分比。$n_i^k/(N^k*p)$ 在均匀分布的理想前提下为 $1$ ，$avg$ 表示该值的平均值。$NUC$ 相当于表达了该值的方差。需要注意的是，我们使用测地距离而不是欧几里得距离来形成圆盘（用测地线距离怎么形成大小相等的圆盘？）。</p><h2 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h2><p>尽管 PU-Net 是第一个专门用于上采样的网络，但还是找了 PointNet 和 PointNet++ 以及 PointNet++（MSG）来作对比，具体方法则是用它们的分割模块来做特征嵌入，然后用重建损失函数训练。但是最后给出的对比表格是用于评价均匀性的 NUC 指标？这是不是不太公平哈哈。剩下的对比和实验就不记录了，大致就是在不同的数据集上测试了一下效果。</p><h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><p>PU-Net 主要的内容概括如下：</p><ul><li>在局部区域生成方面，采用了泊松盘采样，提供了均匀性和随机性；</li><li>在特征嵌入方面，参考了 PointNet++ 中的分层学习，并且采取了更直接的组合方式；</li><li>在特征扩展方面，利用 $1\times1$ 卷积对特征上采样，并重组为 $rN\times \widetilde{C}_2$ 的矩阵；最后对该矩阵进行特征重组，直接得到点坐标；</li><li>采用了联合损失函数，包括重建损失（EMD）、排斥损失（参考 LOP 方法）以及参数正则化项；</li><li>通过 NUC 指标评价生成点的均匀性。</li></ul><p>关于网络的局限性，论文提到了两方面：</p><ul><li>网络不是为补全而设计的，因此不能填补大洞和缺失的部分；</li><li>网络无法为严重欠采样的微小结构添加有意义的点。</li></ul><p>同时也指出可以研究更多下采样方法，来生成更多的不规则稀疏数据用于训练。</p>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
      <tag>点云上采样</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PointNet++ 论文阅读笔记</title>
    <link href="/2023/05/23/PointNet++/"/>
    <url>/2023/05/23/PointNet++/</url>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/pdf/1706.02413.pdf">PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</a></p><h1 id="一、摘要及引言"><a href="#一、摘要及引言" class="headerlink" title="一、摘要及引言"></a>一、摘要及引言</h1><p>PointNet 是直接处理点集的开创性工作，其基本思想是学习每个点的空间编码，然后将所有单个点特征聚合为全局点云特征。但 PointNet 只对单个点编码，无法捕获<strong>局部特征</strong>。因此引入了分层神经网络 PointNet++ ，通过以分层方式处理点集的方法来获取不同尺度下的点集特征。</p><span id="more"></span><h1 id="二、问题陈述"><a href="#二、问题陈述" class="headerlink" title="二、问题陈述"></a>二、问题陈述</h1><p>假设 $\mathcal{X} = (M, d)$ 是一个离散度量空间，其度量继承自欧氏空间 $\mathbb{R}^n$，其中 $M \subseteq \mathbb{R}^n$ 是点集，$d$ 是距离度量。此外，环境欧氏空间中 $M$ 的密度可能并非处处一致。我们感兴趣的是学习将 $\mathcal{X}$ 作为输入（连同每个点的附加特征）的集合函数 $f$ 并产生语义兴趣重新分级 $\mathcal{X}$ 的信息。和 PointNet 一样，这样的 $f$ 可以是将标签分配给 $\mathcal{X}$ 的分类函数，也可以是将标签分配给 $M$ 的每个成员的分割函数。</p><h1 id="三、方法"><a href="#三、方法" class="headerlink" title="三、方法"></a>三、方法</h1><h2 id="PointNet-回顾"><a href="#PointNet-回顾" class="headerlink" title="PointNet 回顾"></a>PointNet 回顾</h2><p>对于无序点集 ${x_1,\dots,x_n}$ ，定义集合函数 $f:\mathcal{X}\rightarrow\mathbb{R}$ 将点集映射为向量：</p><script type="math/tex; mode=display">f(x_1,\dots,x_n)=\gamma\left( \underset{i=1,\dots,n}{\max}\{h(x_i)\} \right)</script><p>其中 $\gamma$ 和 $h$ 通常为多层感知器。PointNet 论文中已经证明 $f$ 可以逼近任何一个连续集合函数，且对输入点排列不变。但 PointNet 缺乏捕捉到不同尺度的本地特征的能力。</p><h2 id="分层点集特征学习"><a href="#分层点集特征学习" class="headerlink" title="分层点集特征学习"></a>分层点集特征学习</h2><p>PointNet++ 的层次结构由许多 SA 层（Set Abstraction Levels）组成。SA 层由三个关键层组成：<strong>采样（Sampling）层</strong>、<strong>组合（Grouping）层</strong>和 <strong>PointNet 层</strong>。</p><p>抽象层次的输入矩阵大小为 $N\times(d+C)$ ，表示 $N$ 个具有 $d$ 维坐标和 $C$ 维点特征的点；输出矩阵大小为 $N’\times(d+C’)$ ，表示 $N’$ 个具有 $d$ 维坐标和 $C’$ 维点特征（以总结局部上下文）的<strong>子采样点</strong>。 </p><p><img src="/2023/05/23/PointNet++/1.png" alt="architecture" style="zoom:70%;padding-top:20pt;display: block; margin-left: auto; margin-right: auto;"></p><h3 id="采样层"><a href="#采样层" class="headerlink" title="采样层"></a>采样层</h3><p>给定输入点 ${x<em>1,x_2,\dots,x_n}$ ，利用<strong>迭代最远点采样</strong>（FPS）来选择点的子集 ${x</em>{i<em>1},x</em>{i<em>2},\dots,x</em>{i<em>m}}$ ，使得 $x</em>{i<em>j}$ 是剩余点中距离点集 ${x</em>{i<em>1},\dots,x</em>{i_{j-1}}}$ 最远的点。论文原话虽然凝练但是略微抽象，这里详细阐述一下 FPS 算法的步骤：</p><ol><li>选定第 $i$ 个点为初始点，记作 $x<em>{i_1}$ ，此时候选集为 $x</em>{i_1}$ ；</li><li>定义点 $x_k$ 到点集 $X$ 的距离为 $\min(\left|x_k-x \right|_2)(x\in X)$ ，即到点集中所有点距离的最小值；</li><li>找到剩余点中距离候选集最远的点，纳入到候选集中；</li><li>重复步骤 3，直到点数达到设定值。</li></ol><p>其中距离的定义一般采用欧式距离，也可以采用测地线距离；初始点随机选择，也可以选择距离点云重心的最远点，使得结果没有随机性。FPS 算法和泊松盘采样很类似，但泊松盘采样提供了更多的随机性，并且对点与点之间的距离要求更宽松。另外，FPS 算法不需要任何参数，应该是更方便可靠的。</p><p>采样层得到了 $N’$ 个采样点，这些点将被用来构成局部特征。</p><h3 id="组合层"><a href="#组合层" class="headerlink" title="组合层"></a>组合层</h3><p>组合层的输入为 $N\times(d+C)$ 的点集和 $N’\times d$ 的采样点集合。对于每个采样点，收集其一定半径范围内最近的 $K$ 个点（$K$ 是因采样点而异的），这个操作称为 ball query 。与 KNN 相比，ball query 保证了固定的区域尺度。</p><p>每个采样点会生成一个 $K\times(d+C)$ 的矩阵，因此最后组合得到 $N’\times K\times(d+C)$ 的矩阵。这个矩阵聚合了一系列的局部点集，如果类比到二维图像，则与 CNN 中的感受野类似，只不过 CNN 中只需要简单地滑动卷积核，而点云中稍微麻烦一些。类似地，PointNet++通过多个 SA 层，逐步扩大感受野，从而提取更高层的特征。</p><h3 id="PointNet-层"><a href="#PointNet-层" class="headerlink" title="PointNet 层"></a>PointNet 层</h3><p>该层的输入为 $N’$ 个局部区域，每个 $K\times(d+C)$ 的局部区域将被聚合为一个 $(d+C’)$ 的局部特征向量，组合得到 $N’\times(d+C’)$ 的矩阵。</p><p>具体地，首先将局部区域所有点中心化，即 ：</p><script type="math/tex; mode=display">x_i^{(j)}=x_i^{(j)}-\hat{x}^{(j)},\mathrm{for}\ i=1,2\dots,K\ \mathrm{and}\ j=1,2,\dots,d</script><p>然后将相对坐标和点特征一起使用，从而捕获局部区域特征，并且消除平移对局部特征的影响。中心化也可以类比到卷积运算中的卷积核中心，因为卷积操作同样不关心每个点在图像中的绝对位置。</p><h2 id="非均匀采样密度下的鲁棒特征学习"><a href="#非均匀采样密度下的鲁棒特征学习" class="headerlink" title="非均匀采样密度下的鲁棒特征学习"></a>非均匀采样密度下的鲁棒特征学习</h2><p>如前所述，点集在不同区域的密度不均匀是很常见的。这种不均匀性给点集特征学习带来了重大挑战。在密集数据中学习到的特征可能无法推广到稀疏采样区域。同时，为稀疏点云训练的模型可能无法识别细粒度的局部结构。</p><p>理想情况下，我们希望尽可能捕获密集采样区域中的细节，但这在稀疏区域无法做到，因为局部特征可能会因采样不足而失效。在这种情况下，我们应该在附近寻找更大尺度的特征。为了实现这一目标，我们提出了<strong>密度自适应 PointNet 层</strong>（右图)，当输入采样密度发生变化时，它可以学习组合来自不同尺度区域的特征。我们将具有密度自适应 PointNet 层的分层网络称为 PointNet++。</p><p>对比 <a href="#分层点集特征学习">分层点集特征学习</a> 章节所描述的 SA 层，PointNet++中每个 SA 层将提取多个尺度的局部特征，并根据点密度将它们组合，论文提出了两种类型的密度自适应层：MSG 和 MRG 。</p><h3 id="多尺度组合（Multi-scale-Grouping，MSG）"><a href="#多尺度组合（Multi-scale-Grouping，MSG）" class="headerlink" title="多尺度组合（Multi-scale Grouping，MSG）"></a>多尺度组合（Multi-scale Grouping，MSG）</h3><p><img src="/2023/05/23/PointNet++/3.png" alt="MRG示意图" style="zoom:50%;float:right;padding-left:30pt">如右图所示，在每个采样点上，用 PointNet 提取不同尺度的特征并将其组合形成多尺度特征。同时为了给网络提供不同密度的输入，采用 random input dropout 方法，随机选取 dropout 概率 $\theta\in\left[0,p\right] (p\le 1)$ ，以概率 $\theta$ 丢弃部分输入点，从而提供了稀疏性和不均匀性（随机性)。</p><h3 id="多分辨率组合（Multi-resolution-Grouping，MRG）"><a href="#多分辨率组合（Multi-resolution-Grouping，MRG）" class="headerlink" title="多分辨率组合（Multi-resolution Grouping，MRG）"></a>多分辨率组合（Multi-resolution Grouping，MRG）</h3><p><img src="/2023/05/23/PointNet++/2.png" alt="在这里插入图片描述" style="zoom:45%;float:right;padding: 0 20pt">考虑到 MSG 方法计算代价较大，提出一种替代方法：MRG，如图（右)所示。对于每个局部区域的特征 $L_i$ ，都由两个特征组成：左边特征通过 SA 层得到，右边特征则通过对区域内所有点云利用 PointNet 获取特征（相当于在 SA 层中嵌套了一个 SA 层？）。</p><p>当局部区域密度较低时，第一个向量往往不如第二个可靠，这时可以提高第二个向量的权重。相反地，局部区域密度较高时，第一个向量提供了更精细的细节特征。</p><h2 id="用于点分割的特征传递"><a href="#用于点分割的特征传递" class="headerlink" title="用于点分割的特征传递"></a>用于点分割的特征传递</h2><p>SA 层对原始点集进行了下采样，然而在分割任务重我们希望获得所有原始点的点特征（即输入输出矩阵的行数应相等）。一种办法是在每个 SA 层中将所有点都采样为中心点（即去掉了 Sampling 层），但这样会导致计算代价非常大。因此论文给出了另一种方法：<strong>特征传播（FP）层</strong>（Feature Propagation level）。设 $N<em>l\ ,\ N</em>{l-1}$ 是第 $l$ 个 SA 层输出和输入的点集大小（$N<em>l\le N</em>{l-1}$），FP 层通过在 $N_{l-1}$ 个点的坐标处插入 $N_l$ 个点的特征值 $f$ 来实现上采样。具体的插值方法，论文选择了基于 kNN 的反距离加权平均：</p><script type="math/tex; mode=display">f^{(j)}(x)=\frac{\sum_{i=1}^kw_i(x)f_i^{(j)}}{\sum_{i=1}^kw_i(x)}\ \ \textrm{where}\ w_i(x)=\frac{1}{d(x,x_j)^p},\ j=1,\dots,C</script><p>然后将插值得到的特征和来自 SA 层的 $N_{l-1}$ 个特征连接（skip link）起来，并传递给 unit pointnet 。unit pointnet 论文中没有更多介绍，只说是类似于 $1\times 1$ 卷积核。由此来看，unit pointnet 应该就是没有池化操作的 pointnet ，因此只是重组了每个点的特征向量，并不会改变点的个数。</p><p>重复通过与 SA 层个数相同的 FP 层，即可将输出矩阵行数恢复为 $N$ ，并且特征长度重组为 $k$ ，即类别个数，从而达到分割的目的。</p><h1 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h1><p>针对 pointnet 难以获取局部特征的缺陷，pointnet++ 主要做了以下改进：</p><ul><li>采用多个 SA 层逐步获取多层次的特征信息。其中采样层利用 FPS 算法生成采样点；组合层利用 ball query 算法构成局部区域；pointnet 层提取局部区域特征；</li><li>采用多个 FP 层进行特征上采样，融合高层特征和底层特征，实现分割任务。利用了反距离加权插值来上采样特征值，利用了 unit pointnet 来提取特征；</li><li>提出了 MSG 和 MRG 两种方法来应对非均匀采样问题，主要原理是在 SA 层中为采样点生成多尺度的局部信息，并通过 dropout 方法来提供稀疏性和不均匀性。</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PointNet 论文阅读笔记</title>
    <link href="/2023/05/21/pointnet/"/>
    <url>/2023/05/21/pointnet/</url>
    
    <content type="html"><![CDATA[<p>论文：<a href="https://arxiv.org/pdf/1612.00593.pdf">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</a></p><h1 id="一、摘要"><a href="#一、摘要" class="headerlink" title="一、摘要"></a>一、摘要</h1><p>点云是一类重要的几何数据结构。由于其形式不规则，大多数研究人员将其转换为规则的 3D 体素网格或图像集合来处理。然而这会使数据不必要地庞大。该论文设计了一种<strong>直接作用于点云数据</strong>的新型神经网络 PointNet，它很好地遵从了输入点的<strong>排列不变性</strong>，并为从对象分类、部分分割到场景语义解析等应用场景提供统一的架构。PointNet 虽然简单，但展现出了很好的效果。</p><span id="more"></span><h1 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h1><p>3D 深度学习方面，在此论文之前有很多形式出现：</p><ul><li>Volumetric CNNs：最早将 3D 卷积神经网络应用于体素化点云，但由于数据稀疏性和 3D 卷积的计算成本，受到分辨率的限制；</li><li>Multiview CNNs：多视图 CNN 将 3D 点云或形状渲染成 2D 图像，然后应用 2D CNN 对其进行分类。然而将这种方法扩展到场景理解过其它 3D 任务并非易事；</li><li>Spectral CNNs：这种卷积网络在网格点云的频率域上进行，但仅适用于具有规则结构的网格，难以应用于更加复杂和不规则的形状；</li><li>Feature-based DNNs：通过提取传统形状特征将 3D 数据转换为向量，再利用全连接网络对形状分类，但受到特征本身表达能力的限制；</li></ul><p>这些方法都不能够直接处理无序点集，而是在尝试将点云转换为序列形式，以便用熟悉的卷积网络来操作，但同时面临计算复杂度等问题。</p><h1 id="三、问题陈述"><a href="#三、问题陈述" class="headerlink" title="三、问题陈述"></a>三、问题陈述</h1><p>定义点云为一组 3D 点 ${ P_i|i=1,\dots,n }$ ，其中 $P_i$ 是包含 $(x,y,z)$ 和额外特征通道（如颜色、法线等）的向量，在论文中仅适用 $(x,y,z)$ 坐标。对于分类问题，输入点云可能是单体，也可能是从场景中预先分割得到。PointNet++ 为 $k$ 个候选类别输出 $k$ 个分数；对于分割问题，任务可能是从单体中分割出不同的结构，也可能是从三维场景中分割出不同的物体。若共有 $n$ 个点，$m$ 个类，则输出 $n\times m$ 个分数，表示每个点属于每个类的概率，从而进行分割。</p><h1 id="四、具体方法"><a href="#四、具体方法" class="headerlink" title="四、具体方法"></a>四、具体方法</h1><h2 id="mathbb-R-n-空间中点集的性质"><a href="#mathbb-R-n-空间中点集的性质" class="headerlink" title="$\mathbb{R} ^n$ 空间中点集的性质"></a>$\mathbb{R} ^n$ 空间中点集的性质</h2><p>我们的输入是来自欧几里德空间的点的子集。它具有三个主要属性： </p><ul><li><strong>无序性</strong>。与图像中的像素阵列或体积网格中的体素阵列不同，点云是一组没有特定顺序的点。换句话说，一个使用 N 个 3D 点集的网络需要对 N ! 种输入点排列具有不变性；</li><li><strong>点之间的关联性</strong>。这些点来自具有距离度量的空间。这意味着点不是孤立的，相邻的点形成一个有意义的子集。因此，该模型需要能够从附近的点捕获局部结构，以及局部结构之间的组合相互作用；</li><li><strong>变换下的不变性</strong>。作为一个几何对象，点集的学习表示应该对某些变换是不变的，如旋转和平移。</li></ul><h2 id="PointNet-架构"><a href="#PointNet-架构" class="headerlink" title="PointNet 架构"></a>PointNet 架构</h2><p>网络具有三个关键模块：作为对称函数的最大池化层，用于聚合来自所有点的信息、局部和全局信息组合结构，以及两个对齐输入点和点特征的联合对齐网络。下面的单独段落中将讨论这些设计选择背后的原因。</p><h3 id="无序输入的对称函数"><a href="#无序输入的对称函数" class="headerlink" title="无序输入的对称函数"></a>无序输入的对称函数</h3><p>为了解决无序性问题，论文给出了三种策略：</p><ol><li>引入一种规范的排序方式，但稳定的排序方式难以确定，且易受噪声的影响；</li><li>把点云看作一个序列信号，并通过随机排列的方式训练 RNN 以驱使输出结果相同，但这种方法随着点云数量增长失去可行性；</li><li>利用对称函数聚合来自每个点的信息。所谓聚合信息，即将 $n$ 个向量作为输入而产生一个对输入顺序不变的新向量。例如 $1+2+3 = 2+3 +1$ 。显然这种方法是较为合适的。</li></ol><p>定义函数 $h:\mathbb{R} ^N \rightarrow \mathbb{R} ^K$ ，用于对每个点进行处理；定义对称函数 $g:\underbrace{\mathbb{R} ^K\times\cdots\times\mathbb{R} ^K}_{n}\rightarrow\mathbb{R} $ ，聚合处理结果；则由输入到输出的一般函数 $f:2^{\mathbb{R} ^N}\rightarrow\mathbb{R} $ 定义为：  </p><script type="math/tex; mode=display">f(\{x_1,\dots,x_n\}) \approx g(h(x_1),\dots ,h(x_n))</script><p>在实践中，论文采用多层感知器（MLP）来近似 $h$，利用最大池化函数来近似 $g$ 函数。</p><h3 id="本地和全局信息聚合"><a href="#本地和全局信息聚合" class="headerlink" title="本地和全局信息聚合"></a>本地和全局信息聚合</h3><p><img src="/2023/05/21/pointnet/architecture.jpg" alt="architecture"></p><p>对于分割任务，需要结合本地信息和局部信息。论文采用了简单高效的办法：将学习得到的全局特征和局部特征直接连接在一起，如上图所示。然后再重新提取每个点的特征，从而使得每个点的特征同时包含局部和全局信息。再利用新的组合特征训练几个 MLP ，即可实现每个点的类别判断，也就是分割；若要对单体点云进行识别分类，则直接利用全局特征训练。</p><h3 id="联合对齐网络"><a href="#联合对齐网络" class="headerlink" title="联合对齐网络"></a>联合对齐网络</h3><p>为了使特征具有旋转平移不变性，论文引入了一种迷你网络 T-net 来直接预测仿射变换矩阵，并将该变换直接应用于原始输入。同样地，特征也需要引入旋转不变性，因此对点特征也可以训练一个对齐网络。</p><p>关于 T-net 的结构，其相当于小型的 PointNet，利用最大池化得到全局特征，再利用 MLP 得到 $3\times 3$ 的转换矩阵。由于特征空间维数较大，增大了优化的难度，因此在 softmax 训练损失的基础上，添加了一个正则化项，用来将特征变换矩阵约束为近似<strong>正交矩阵</strong>：</p><script type="math/tex; mode=display">L_{reg}=\| I-AA^T \|^2_F</script><p>其中 $A$ 是由迷你网络预测得到的旋转矩阵。正则项使得优化更稳定，性能更优。</p><h1 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h1><p>为了直接针对点集进行处理，pointnet 的主要思想就是通过池化来解决无序性，通过 MLP 来扩大和缩放特征尺寸。同时为了引入旋转不变性，将点云坐标（或特征）对齐，使用了 T-net 来预测旋转矩阵。</p>]]></content>
    
    
    
    <tags>
      
      <tag>点云</tag>
      
      <tag>神经网络</tag>
      
      <tag>论文阅读笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
