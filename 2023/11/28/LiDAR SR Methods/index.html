<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">




<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

  <meta name="author" content="SGGZCL">





<title>激光雷达点云上采样调研 | ZCL&#39;BLOG</title>



<link rel="icon" href="/favicon.ico">


<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js" type="text/javascript"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"
/>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">


<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/css/search.css">



<script src="/lib/jquery.min.js"></script>


<script src="/lib/iconify-icon.min.js"></script>


<script src="https://cdn.tailwindcss.com?plugins=typography"></script>
<script>
  tailwind.config = {
    darkMode: "class",
  };
</script>

<script>
  (function () {
    const prefersDark =
      window.matchMedia &&
      window.matchMedia("(prefers-color-scheme: dark)").matches;
    const setting = localStorage.getItem("hexo-color-scheme") || "auto";
    if (setting === "dark" || (prefersDark && setting !== "light"))
      document.documentElement.classList.toggle("dark", true);
    let isDark = document.documentElement.classList.contains("dark");
  })();

  $(document).ready(function () {
    // init icon
    const prefersDark =
      window.matchMedia &&
      window.matchMedia("(prefers-color-scheme: dark)").matches;
    const isDark = document.documentElement.classList.contains("dark");
    $("#theme-icon").attr("icon", isDark ? "ic:round-dark-mode" : "ic:round-light-mode");

    function toggleGiscusTheme() {
      const isDark = document.documentElement.classList.contains("dark");
      const giscusFrame = document.querySelector("iframe.giscus-frame");
      if (giscusFrame) {
        giscusFrame.contentWindow.postMessage(
          {
            giscus: {
              setConfig: {
                theme: isDark ? "dark" : "light",
              },
            },
          },
          "https://giscus.app"
        );
      }
    }


    // toggle dark mode
    function toggleDark() {
      let isDark = document.documentElement.classList.contains("dark");
      const setting = localStorage.getItem("hexo-color-scheme") || "auto";
      isDark = !isDark;
      document.documentElement.classList.toggle("dark", isDark);
      $("#theme-icon").attr("icon", isDark ? "ic:round-dark-mode" : "ic:round-light-mode");
      if (prefersDark === isDark) {
        localStorage.setItem("hexo-color-scheme", "auto");
      } else {
        localStorage.setItem("hexo-color-scheme", isDark ? "dark" : "light");
      }
      toggleGiscusTheme();
    }
    $("#toggle-dark").click(toggleDark);

    // listen dark mode change
    window
      .matchMedia("(prefers-color-scheme: dark)")
      .addEventListener("change", (e) => {
        const setting = localStorage.getItem("hexo-color-scheme") || "auto";
        if (setting === "auto") {
          document.documentElement.classList.toggle("dark", e.matches);
          $("#theme-icon").attr(
            "icon",
            e.matches ? "ic:round-dark-mode" : "ic:round-light-mode"
          );
          toggleGiscusTheme();
        }
      });
  });
</script>




<meta name="generator" content="Hexo 6.3.0"></head>
<body 
  class="
    bg-[var(--c-0)]
    text-[var(--c-80)]
  ">
  <!-- The navigation bar -->
<header class="
    flex flex-row items-center
    w-full
    pr-4
    z-10
    border-b-[1px]
    border-b-[var(--c-border)]
    dark:bg-[var(--c-0)]
    dark:border-b-[var(--c-0)]
    gap-2
    h-[var(--h-header)]
    text-[var(--c-80)]
">
  <!-- Left part -->
  <div class="overflow-hidden h-full flex flex-row items-center">
    <!-- Site Title on the top left -->
    <a href="/" class="
            whitespace-nowrap
            text-2xl
            text-[var(--c-theme)]
            hover:text-[var(--c-theme)]
            pl-4
            font-black
            bg-gradient-to-r from-cyan-500
            to-blue-500 bg-clip-text text-transparent
          ">
      ZCL&#39;BLOG
    </a>
  </div>
  <!-- Div for pushing items to both sides -->
  <div class="flex-1"></div>
  <!-- Right part -->
  <div class="flex flex-row items-center z-20 h-full">
    <!-- Page links -->
    <div class="hidden sm:flex flex-row h-full">
      
      
      
      
      
      
      <a href="/./archives" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:inbox-fill" width="22">
        </iconify-icon>
        
        
        <p>Posts</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./publications" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:science-fill" width="22">
        </iconify-icon>
        
        
        <p>Publications</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./about" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:user-info-fill" width="22">
        </iconify-icon>
        
        
        <p>About</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./categories" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:classify-2-fill" width="22">
        </iconify-icon>
        
        
        <p>Categories</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./tags" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:tag-fill" width="22">
        </iconify-icon>
        
        
        <p>Tags</p>
        
      </a>
      
      
      
      
      
      
      <a href="/./index" class="
                        flex flex-row items-center
                        gap-1
                        hover:underline
                        hover:bg-[var(--c-20)]
                        hover:text-[var(--c-theme)]
                        transition-all
                        px-2
                        py-1
                        my-1
                        rounded-lg
                        group
                    ">
        
        <iconify-icon class="group-hover:scale-125 transition-transform" icon="mingcute:home-2-fill" width="22">
        </iconify-icon>
        
        
      </a>
      
    </div>
    <!-- Icons on the right -->
    <div class="flex flex-row items-center">

      <!-- TODO: Add search icon here -->

      <!-- Dark/light toggle icon -->
      <a class="flex group p-1" title="toggle theme" id="toggle-dark">
        <iconify-icon class="transition-transform
                    group-hover:rotate-[45deg]
                    group-hover:scale-125
                    group-hover:text-[var(--c-theme)]" width="24" id="theme-icon">
        </iconify-icon>
      </a>
      <!-- Icon for dropout menu on small screens -->
      <div class="flex p-1 mx-1 sm:hidden">
        <a class="w-5 h-5" aria-hidden="true" id="open-menu">
          <iconify-icon width="24" icon="mingcute:menu-fill" class="transition-transform hover:scale-125 hover:rotate-[5deg]">
          </iconify-icon>
        </a>
        <a class="w-5 h-5 hidden" aria-hidden="true" id="close-menu">
          <iconify-icon width="24" icon="mingcute:close-circle-fill" class="transition-transform hover:scale-125 hover:rotate-[80deg]">
          </iconify-icon>
        </a>
      </div>
    </div>
  </div>
</header>

<!-- Dropdown menu on small screens -->
<div id="menu-panel" class="
        h-0
        overflow-hidden
        sm:hidden
        w-full
        z-10
        rounded
    ">
  <div id="menu-content" class="
        flex
        flex-row
        justify-center
        items-center
        font-bold
        text-xl
        border-b-[1px]
        relative
        z-20
        border-[var(--c-sep)]
        px-2
        py-2
        -translate-y-full
        transition-transform
        duration-200
        ">
    
    
    
    <a href="/./archives" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:inbox-fill" width="22">
      </iconify-icon>
      <p>
        posts
      </p>
    </a>
    
    
    
    
    <a href="/./publications" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:science-fill" width="22">
      </iconify-icon>
      <p>
        publications
      </p>
    </a>
    
    
    
    
    <a href="/./about" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:user-info-fill" width="22">
      </iconify-icon>
      <p>
        about
      </p>
    </a>
    
    
    
    
    <a href="/./categories" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:classify-2-fill" width="22">
      </iconify-icon>
      <p>
        categories
      </p>
    </a>
    
    
    
    
    <a href="/./tags" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:tag-fill" width="22">
      </iconify-icon>
      <p>
        tags
      </p>
    </a>
    
    
    
    
    <a href="/./index" class="
                flex flex-row items-center
                gap-2
                h-12
                hover:underline
                hover:bg-[var(--c-20)]
                px-3
                py-1
                rounded-lg
            ">
      <iconify-icon icon="mingcute:home-2-fill" width="22">
      </iconify-icon>
      <p>
        home
      </p>
    </a>
    
    
  </div>
</div>
  <main>
    <!-- css -->

<link rel="stylesheet" href="/lib/fancybox/fancybox.min.css">

  
<link rel="stylesheet" href="/lib/tocbot/tocbot.min.css">

    <!-- toc -->
    
  <!-- tocbot -->
<nav class="post-toc toc text-sm w-40 relative top-32 right-4 opacity-70 hidden lg:block" style="position: fixed !important;"></nav>


<section class="px-6 max-w-prose mx-auto md:px-0">
  <!-- Post header before content -->
  <header class="py-4">
    <div class="flex flex-col gap-2 pt-4 md:pt-6">
      <!-- Title -->
      <div id="article-title" class="leading-snug">
        <p class="text-3xl font-bold text-[var(--c-100)] mb-4">激光雷达点云上采样调研</p>
      </div>
      <!-- Meta data -->
      <div>
        <section class="
          flex flex-col gap-x-2 gap-y-1 text-sm text-[var(--c-100)]">
          <div class="flex flex-wrap items-center gap-x-2 gap-y-1">
            <!-- Dates -->
            <div class="flex items-center gap-1">
              <iconify-icon width="18" icon="mingcute:add-circle-fill" ></iconify-icon>
              Created: <time class="w-max">2023-11-28</time>
            </div>
            <div class="flex items-center gap-1">
              <iconify-icon width="18" icon="mingcute:refresh-3-fill" ></iconify-icon>
              Edited: <time class="w-max">2023-12-29</time>
            </div>
          </div>
          <div class="flex flex-wrap items-center gap-x-3 gap-y-3">
            <!-- Author -->
            

            <!-- Word count -->
            <span class="flex items-center gap-1">
              <iconify-icon width="18" icon="mingcute:book-2-fill" ></iconify-icon>
              <span>4.9k words, 18 min</span>
            </span>
            <!-- Categories -->
            
          </div>
        </section>
      </div>
      <!-- tags -->
      <div>
        
<div class="flex flex-wrap gap-1">
  
    
      <a href="/tags/%E7%82%B9%E4%BA%91/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        点云
      </a>
    
      <a href="/tags/%E7%82%B9%E4%BA%91%E4%B8%8A%E9%87%87%E6%A0%B7/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        点云上采样
      </a>
    
      <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        神经网络
      </a>
    
      <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        论文阅读笔记
      </a>
    
      <a href="/tags/%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        激光雷达
      </a>
    
      <a href="/tags/%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E8%B0%83%E7%A0%94/" 
        class="
          tag
          text-sm
          rounded-full
          px-[5px]
          border-[1px]
          border-[var(--c-theme)]
          text-[var(--c-theme)]
          bg-[var(--c-0)]
          dark:bg-[var(--c-0)]
          dark:drop-shadow-none
          hover:bg-[var(--c-theme)]
          hover:text-[var(--c-0)]
          dark:hover:text-[var(--c-theme-2)]
        ">
        研究现状调研
      </a>
    
  
</div>
      </div>
    </div>
  </header>
  <!-- content -->
  <article class="post-content prose m-auto dark:prose-invert">
    <p>激光雷达点云上采样相关论文调研。</p>
<span id="more"></span>
<h1 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>点云超分辨率关注点云的密度以及几何信息。对于给定的点云 $P$ ，我们希望得到更加密集的点云 $Q$ ，能够描述 $P$ 所在的底层形状。</p>
<p>对于激光雷达点云，这个问题要特殊一些。常规的点云上采样容易受到点云数据不规则特性的困扰，但激光雷达点云具有规则的分布，这受益于激光雷达的环状扫描方式。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231128154333947.png" alt="image-20231128154333947" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>鉴于激光雷达的扫描方式，一个自然的想法是将点云投影为球面坐标，即：</p>
<script type="math/tex; mode=display">
\begin{cases}
\begin{aligned}
\varphi &= \arctan\left(z\big/\sqrt{x^2+y^2} \right) \\
\theta &= \arctan(y/x)\\
d  &=\sqrt{x^2+y^2+z^2}
\end{aligned}
\end{cases}</script><p>此时在 $\varphi-\theta$ 平面上，点的分布是规则的，这有利于后续的栅格化和上采样。使用这种投影的上采样方法通常总结为基于格网的方法。</p>
<p>需要注意的是，有的激光雷达点云在垂直方向上并不均匀分布，例如 <a target="_blank" rel="noopener" href="https://hesaiweb2019.blob.core.chinacloudapi.cn/uploads/Pandar64_产品手册_640-zh-230510.pdf">Pandar64</a> 将 $3/4$ 的线束集中在了 $(-6°,+2°)$ ，而垂直视场角为 $(-25°,+15°)$ ，但这样的激光雷达目前还不多见。</p>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>对于点云 $P$ ，可将其记作一系列扫描线的集合，即 $P=\{L_i \, |i=1,2,\dots,N_P\}$ ，其中</p>
<script type="math/tex; mode=display">
L_i=\left\{(x,y,z)\in P \, \middle|\arctan\left(z\big/\sqrt{x^2+y^2}\right)=\varphi_i \right\},</script><p>表示第 $i$ 条扫描线，我们希望预测点云 $Q=\{L_i \, |i=1,2,\dots,N_Q\}$ ，满足 $N_Q&gt;N_P$ ，且保有 $P$ 的几何特征和扫描线结构。同时我们希望点云 $Q$ 在同样的下游算法上表现出优于 $P$ 的性能。</p>
<h1 id="研究现状"><a href="#研究现状" class="headerlink" title="研究现状"></a>研究现状</h1><h2 id="CNN-based-synthesis-of-realistic-high-resolution-LiDAR-data"><a href="#CNN-based-synthesis-of-realistic-high-resolution-LiDAR-data" class="headerlink" title="CNN-based synthesis of realistic high-resolution LiDAR data"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1907.00787">CNN-based synthesis of realistic high-resolution LiDAR data</a></h2><h3 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h3><p>下图展示了网络的总体框架。对于低分辨率图像，其特征提取步骤通过一系列残差块执行，上采样则通过转置卷积（文中称分数跨步卷积）实现。在第一层和最后一层使用了 $9\times 9$ 的卷积，中间残差块中都是 $3\times 3$ 。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031175129278.png" alt="image-20231031175129278" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="修正的逐点损失函数"><a href="#修正的逐点损失函数" class="headerlink" title="修正的逐点损失函数"></a>修正的逐点损失函数</h3><p>论文考虑到图像中大量存在的缺失点，将 $\mathcal{L}_1、\mathcal{L}_2$ 损失修正为只对比非缺失点，记作集合 $V\subset I$ ，即：</p>
<script type="math/tex; mode=display">
\mathcal{L}_d^\alpha = \sum_{(i,j)\in V}\left| d_{ij}-\hat{d}_{ij} \right|^{\alpha},\alpha=1,2</script><h3 id="感知损失"><a href="#感知损失" class="headerlink" title="感知损失"></a>感知损失</h3><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031190341496.png" alt="image-20231031190341496" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>逐点损失鼓励图像输出较为平滑的结果，因为它表示了平均误差。同时逐点损失只能在像素层面比较，无法获取高频信息。因此有许多方法使用感知模块来表征损失，使生成的图像更真实。论文采用了一个预训练好的特征提取器 $\phi$ ，将预测图和实际图作为输入，并计算每一层的损失：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{f}=\sum_{c}\sum_{(i,j)\in I}\left| \phi_c(d)_{ij}-\phi_c(\hat{d})_{ij} \right|</script><p>其中 $\phi_c$ 对应了前 $c$ 层特征提取器。</p>
<h3 id="语义一致性损失"><a href="#语义一致性损失" class="headerlink" title="语义一致性损失"></a>语义一致性损失</h3><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031194443752.png" alt="image-20231031194443752" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>语义一致性损失则利用了语义分割网络，以交叉熵方式比较两次扫描。对每个点预测一个语义类别概率，并和真值（one-hot 编码）进行比较，得到交叉熵损失 $\mathcal{L}_{ce}$ 。但仅有交叉熵损失无法约束点云的几何结构，因此通过可训练的权重参数将两个损失整合在一起：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{sc}=\frac{1}{2\sigma_r^2}\mathcal{L}_{d}^{1}+\frac{1}{\sigma_c^2}\mathcal{L}_{ce}+\log\sigma_r+\log\sigma_c</script><p>这一结果来自 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.07115">Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</a> ，它通过对数似然推导了语义损失和回归损失的整合，但论文这里似乎把正则项抄错了（丢了两个平方）。</p>
<h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><p>MAE, MSE, mIoU 以及问卷投票。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/CNN-based-result.png" alt="CNN-based-result" style="zoom:30%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>论文只实现了两倍上采样，从实验结果来看，使用逐点损失的 MAE 和 MSE 最高，使用感知损失的 mIoU 最高，使用语义的效果不好。但这些结论几乎没什么帮助。</p>
<h2 id="Simulation-based-Lidar-Super-resolution-for-Ground-Vehicles"><a href="#Simulation-based-Lidar-Super-resolution-for-Ground-Vehicles" class="headerlink" title="Simulation-based Lidar Super-resolution for Ground Vehicles"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.05242">Simulation-based Lidar Super-resolution for Ground Vehicles</a></h2><p>代码：<a target="_blank" rel="noopener" href="https://github.com/RobustFieldAutonomyLab/lidar_super_resolution">lidar-super-resolution</a> </p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>第一篇开源的工作，也是该任务下被引最多的。其思路很简单：带有转置卷积的 U-Net 用于重建深度，蒙特卡洛 Dropout 用于克服噪声值。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031204141231.png" alt="image-20231031204141231" style="zoom:27%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>MC-Dropout 的想法是：在测试阶段也应用 Dropout 进行多次预测，从而获取多个不同的值。相当于将多个子网络的预测进行集成。对于多次预测变化较大的点，输出较低的置信度，并取平均值作为最终预测值。<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.02142">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</a> 论证了 MC-Dropout 可以被看作高斯过程中的近似贝叶斯推理，表达为下式：</p>
<script type="math/tex; mode=display">
p(y^*|\mathbf{x}^*,\mathcal{D})\propto \int p(y^*|\theta^*)p(\mathbf{x}^*,\mathcal{D}|\theta^*)\mathrm{d}\theta^*
\\
\Downarrow
\\
p(y^*|\mathbf{x}^*)=\frac{1}{T}\sum_{t=1}^{T}p(y^*|\mathbf{x}^*,\theta^*_t)</script><p>MC-Dropout 在直觉上接近机器学习中的 Bagging，但它只需要一个模型。论文实验了有无 MC-Dropout 的两种效果，认为它对减少噪声有很大帮助。</p>
<p><center class="half">    
   <img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101133538701.png" alt="image-20231031204141231" style="zoom:50%;">      <img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101140717153.png" alt="image-20231101140717153" style="zoom:50%;"></center></p>
<h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>通过生成预测点和 ground truth 的占用地图，绘制 ROC 曲线以及 AUC 的值。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231128173836966.png" alt="image-20231128173836966" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>
<h2 id="T-UNet-A-Novel-TC-Based-Point-Cloud-Super-Resolution-Model-for-Mechanical-LiDAR"><a href="#T-UNet-A-Novel-TC-Based-Point-Cloud-Super-Resolution-Model-for-Mechanical-LiDAR" class="headerlink" title="T-UNet: A Novel TC-Based Point Cloud Super-Resolution Model for Mechanical LiDAR"></a><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-030-92635-9_40">T-UNet: A Novel TC-Based Point Cloud Super-Resolution Model for Mechanical LiDAR</a></h2><p>代码：<a target="_blank" rel="noopener" href="https://github.com/donkeyofking/lidar-sr">donkeyofking/lidar-sr</a> 。其主要思路是利用点云帧序列，而非单帧点云。</p>
<h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><ul>
<li>首先将 $16$ 帧序列点云分别通过转置卷积进行上采样。将相邻两个特征图拼接，并通过（膨胀）卷积提取特征。论文用膨胀卷积取代了池化层，以减少信息的丢失。</li>
<li>重复上述步骤，直至得到一个特征图。然后通过一系列的转置卷积上采样，并和之前的特征图连接，这里和 U-Net 的结构相同。</li>
<li>采用 SSIM 作为损失函数。</li>
</ul>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101154818026.png" alt="image-20231101154818026" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评价指标-1"><a href="#评价指标-1" class="headerlink" title="评价指标"></a>评价指标</h3><p>峰值信噪比 (PNSR), MSE, 结构相似性指数 (SSIM)。</p>
<h2 id="Channel-Attention-based-Network-for-LiDAR-Super-resolution"><a href="#Channel-Attention-based-Network-for-LiDAR-Super-resolution" class="headerlink" title="Channel Attention based Network for LiDAR Super-resolution"></a><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9727846">Channel Attention based Network for LiDAR Super-resolution</a></h2><p>无代码。网络架构由一个 U-Net 和一个基于通道注意力的重建块组成。</p>
<h3 id="基于通道注意力的重建块"><a href="#基于通道注意力的重建块" class="headerlink" title="基于通道注意力的重建块"></a>基于通道注意力的重建块</h3><p>从图中看到，首先是两个转置卷积上采样四倍，然后就是不断复用卷积层和通道注意力模块，并使用残差连接。最后用两个卷积层回归深度值，并和 U-Net 提取的信息逐点相加。论文希望 U-Net 能够捕获边缘信息，使重建更准确（但是并没有对提取边缘这一点做监督或者约束，比较奇怪，可能是玄学吧）。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101160136946.png" alt="image-20231101160136946" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>通道注意力的结构就是最基本的自注意力机制，它关注不同通道之间的相关性（原文却说“每个通道上相邻像素之间的相关性”，可能是笔误）。首先将图像特征 $C\times V \times H$ 展平成 $C\times VH$ 的特征，和 $VH \times C$ 的矩阵执行点积，通过 SoftMax 得到 $C\times C$ 的注意力矩阵，然后和原来的特征矩阵相乘，得到新的特征图。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101160511380.png" alt="image-20231101160511380" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="环形填充"><a href="#环形填充" class="headerlink" title="环形填充"></a>环形填充</h3><p>球面投影需要一个角度来分割投影图，然后展平，因此在分割处提取不到真实的局部特征。论文的方法很简单，就是把图像往两边 padding，补充回丢掉的局部信息。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101163539525.png" alt="image-20231101163539525" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评估指标-1"><a href="#评估指标-1" class="headerlink" title="评估指标"></a>评估指标</h3><p>只采用了一个 MAE 。</p>
<h2 id="LiDAR-Super-Resolution-Based-on-Segmentation-and-Geometric-Analysis"><a href="#LiDAR-Super-Resolution-Based-on-Segmentation-and-Geometric-Analysis" class="headerlink" title="LiDAR Super-Resolution Based on Segmentation and Geometric Analysis"></a><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9875347">LiDAR Super-Resolution Based on Segmentation and Geometric Analysis</a></h2><p>无代码。这是一个步骤较多的无监督方法，并且基于点而非格网，但采用的是球面投影，因此同样保留扫描线结构。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101164701852.png" alt="image-20231101164701852" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="地面点分割"><a href="#地面点分割" class="headerlink" title="地面点分割"></a>地面点分割</h3><p>这一步骤在 $xyz$ 坐标上进行，更准确的说，在每一列扫描线上进行。</p>
<p>对于输入点 $P_l$ ，目标是分割得到地面点 $P_g$ 和非地面点 $P_{ng}$ 。考虑一列扫描点，点分布如下图所示。</p>
<ul>
<li>首先找到 $z$ 值最小的点，向两边顺序搜索，得到相邻点的向量 $V_l$ ；同时从最低点出发，连接所有点，得到向量 $V_r$ ；</li>
<li>求向量点积 $V_l \cdot V_r$ ，并通过点积的绝对值选取种子点（论文这里讲得不太清楚，应该就是求向量夹角）。最后通过一个 $z$ 值的低通滤波得到地面种子点；</li>
<li>基于种子点，利用最小二乘拟合一条直线，将距离直线一定阈值内的点纳入地面点，其余点纳入非地面点。对一圈的点执行上述操作，实现分割。</li>
</ul>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101170403255.png" alt="image-20231101170403255" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="坐标重组"><a href="#坐标重组" class="headerlink" title="坐标重组"></a>坐标重组</h3><p>坐标重组就是球面投影。但论文这里没有采用栅格化为图像的方式，而是保留三维坐标 $(h,v,d)$ ，避免了任何信息损失。其中 $h,v$ 分别表示水平角和垂直角，$d$ 表示距离。</p>
<h3 id="超分辨率"><a href="#超分辨率" class="headerlink" title="超分辨率"></a>超分辨率</h3><p>针对地面点和非地面点，采用两种上采样思路。</p>
<h4 id="地面点上采样"><a href="#地面点上采样" class="headerlink" title="地面点上采样"></a>地面点上采样</h4><p>将地面点视作平面，若上下两个像素都是地面点，则考虑三角形角平分线的性质。这里的推导很简单，设前后两个点的球面坐标分别为：</p>
<script type="math/tex; mode=display">
\begin{cases}
p_A = [I_i\cdot H_{\textrm{res}},a,v_1]
\\
p_B = [I_i\cdot H_{\textrm{res}},b,v_5]
\end{cases}</script><p>则 $v_3=(v_1+v_5)/2$ ，只需求 $OD$ 的长度，结果如下：</p>
<script type="math/tex; mode=display">
d = \frac{2ab}{a+b}\cos\frac{\alpha}{2}</script><p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101170807215.png" alt="image-20231101170807215" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>地面点还有一个优化，大致是对空缺点进行了讨论，然后用局部的平滑细化点。</p>
<h4 id="非地面点上采样"><a href="#非地面点上采样" class="headerlink" title="非地面点上采样"></a>非地面点上采样</h4><p>从俯视图上，观察到非地面点呈现簇的分布，即同一物体的点之间相距较进。简单聚类后对每个物体进行上采样，将点分为物体内的点和物体间的点。对于物体间的点，由于缺乏先验知识，无法归类，为了提升远处物体的点数量，论文直接将其归到更远的物体上。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101172953666.png" alt="image-20231101172953666" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评价指标-2"><a href="#评价指标-2" class="headerlink" title="评价指标"></a>评价指标</h3><p>Hasdorff 距离和 CD 。</p>
<h2 id="Fast-Point-Clouds-Upsampling-with-Uncertainty-Quantification-for-Autonomous-Vehicles"><a href="#Fast-Point-Clouds-Upsampling-with-Uncertainty-Quantification-for-Autonomous-Vehicles" class="headerlink" title="Fast Point Clouds Upsampling with Uncertainty Quantification for Autonomous Vehicles"></a><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9811914">Fast Point Clouds Upsampling with Uncertainty Quantification for Autonomous Vehicles</a></h2><p>无代码。基本思路是用神经过程（NP）取代了 MC-Dropout，去实现更快速的不确定性量化。MC-Dropout 需要多次前向推理，会比较占用资源。从它的输出结果来看，不确定性较大的点依然是集中在边缘区域。</p>
<h3 id="使用-Conv-NPs-的上采样"><a href="#使用-Conv-NPs-的上采样" class="headerlink" title="使用 Conv-NPs 的上采样"></a>使用 Conv-NPs 的上采样</h3><p>对于低分辨率图像，论文用空白的掩码 $M_c$ 替代了转置卷积，直接增加图像的行数。与之对应的有 $M_t$ ，表示已知的部分。</p>
<script type="math/tex; mode=display">
M_c(i,j)=\begin{cases}
\begin{aligned}
1&, \text{if} \ \ (r_{up}|i) 
\\
0&, \text{otherwise}
\end{aligned}
\end{cases}</script><p>后续的方法分为四个模块。首先通过特征提取器，分别从掩码和扩大后的图像中提取特征图，并连接在一起。</p>
<script type="math/tex; mode=display">
\begin{cases}
e=\zeta(M_c)\in \mathbb{R}^{U_{\mathcal{H}}\times V_{\mathcal{H}}\times K}
\\
e'=\zeta(\mathcal{I_P})\in \mathbb{R}^{U_{\mathcal{H}}\times V_{\mathcal{H}}\times K}
\\
\end{cases}
\Rightarrow
\epsilon=e \oplus e'</script><p>通过通过卷积层聚合邻域特征：</p>
<script type="math/tex; mode=display">
e_C = \gamma(\epsilon)\in \mathbb{R}^{U_{\mathcal{H}}\times V_{\mathcal{H}}\times 2}</script><p>再由掩码 $M_t$ 和特征 $e_C$ 预测一组高斯分布：</p>
<script type="math/tex; mode=display">
v=(\mu, \sigma)=\Phi(M_t,e_C)</script><p>得到了均值图像和方差图像，从而滤除不确定性较大的点。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>由于输出了不确定性，实际上估计的是一个高斯分布。因此有<strong>条件负对数似然</strong>损失：</p>
<script type="math/tex; mode=display">
Loss = -\mathbb{E}_{\mathcal{D}}\left[ \frac{1}{U_{\mathcal{H}}\times V_{\mathcal{H}}}\sum_{i,j}\log p_{i,j}(r_{i,j}^{g}|v_{i,j})\right]</script><p>其中 $r_{i,j}^{g}$ 表示像素点 $(i,j)$ 上的真实距离。</p>
<h3 id="评价指标-3"><a href="#评价指标-3" class="headerlink" title="评价指标"></a>评价指标</h3><p>仅适用了 MAE 。</p>
<h2 id="Implicit-LiDAR-Network-LiDAR-Super-Resolution-via-Interpolation-Weight-Prediction"><a href="#Implicit-LiDAR-Network-LiDAR-Super-Resolution-via-Interpolation-Weight-Prediction" class="headerlink" title="Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.06413">Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction</a></h2><p>代码：<a target="_blank" rel="noopener" href="https://github.com/PinocchioYS/iln">PinocchioYS/iln</a> 。整体思路比较简单，对于任意一条查询射线，对其四个邻域点的特征进行注意力，求得权重，然后对距离加权。ILN 是第一个实现任意分辨率的，并且无需不确定性量化。</p>
<h3 id="LIIF"><a href="#LIIF" class="headerlink" title="LIIF"></a>LIIF</h3><p>LIIF 是这篇文章的灵感来源，发表在 CVPR2021 。对于二维特征图 $M \in \mathbb{R}^{H\times W\times D}$ ，定义一个对于所有图像相同的解码器 $f_\theta$ ，其作用为：</p>
<script type="math/tex; mode=display">
s=f_\theta(z,x)</script><p>其中 $z$ 是一个向量，$x\in \mathcal{X}$ 是一个二维坐标，$s$ 为预测信号（通常为 RGB 值）。因此每一个 $z$ 对应了一个函数，即：</p>
<script type="math/tex; mode=display">
z\mapsto f_\theta(z,\cdot):\mathcal{X}\rightarrow\mathcal{S},</script><p>假设特征向量在二维空间均匀分布，为每一个特征分配一个二维坐标。对于连续图像 $I(i)$ ，坐标 $x_q$ 处的 RGB 值定义为：</p>
<script type="math/tex; mode=display">
I(x_q)=f_\theta(z^*, x_q-v^*),</script><p>其中 $z^{*}$ 是距离 $x_q$ 最近的一个特征向量，$v$ 是对应的坐标。</p>
<p>简而言之，对于任何一个需要预测的位置，找到离它最近的那个已知点，将该点的特征以及距离送入一个网络，输出预测值。仅此而已。这就好比点云上采样时，从一个点出发生成一系列点。</p>
<p>但这样做还不够，因为一个特征过于单调。论文使用了一个叫“特征展开”的步骤，将 $M$ 中每个位置的 $3\times 3$ 邻域串联起来，得到新的特征图：</p>
<script type="math/tex; mode=display">
M_{jk}=\text{Concat}(\{M_{j+l,k+m}\}_{l,m \in \{-1,0,1\}}),</script><p>此外，由于两个像素连线中点处，会发生“跳变”的情况，因为 $z^*$ 发生了变化。为保证预测的连续性，将预测图像改写为：</p>
<script type="math/tex; mode=display">
I(x_q)=\sum_{t\in \{00,01,10,11\}}\frac{S_t}{S}\cdot f_\theta(z^*_t, x_q-v^*_t),</script><p>也就是将最近的四个像素的预测值取加权平均。权重系数和 $x_q$ 到 $v^*_t$ 构成的矩形面积 $S_t$ 成正比。</p>
<p>除此之外还不够，由于 $f_\theta$ 预测了一个离散点的值，而我们实际上想要生成一个像素的值。这类似于 NeRF 与 Mip-NeRF 的区别，论文将像素的范围考虑在内，即：</p>
<script type="math/tex; mode=display">
s=f_{cell}(z,[x,c])</script><p>其中 $c=[c_h,c_w]$ ，表示查询像素的大小。</p>
<h3 id="ILN"><a href="#ILN" class="headerlink" title="ILN"></a>ILN</h3><p>LIIF 通过周边信息直接预测了值，而 ILN 尝试预测权重，以在距离图像上取得比较稳定的效果。在 LIIF 中，权重是可以直接计算的。记权重函数为 $h$ ，值函数为 $g$ ，则 LIIF 可以表示为：</p>
<script type="math/tex; mode=display">
\hat{r}=\sum_{t}^{4}g(\cdot)h(\cdot |\theta)=\sum_{t}^{4}\frac{S_t}{S}\cdot h(z_t|\theta)</script><p>为了直接利用周边点的距离值，ILN 直接预测权重：</p>
<script type="math/tex; mode=display">
\hat{r}=\sum_{t}^{4}g(\cdot |\theta)h(\cdot )=\sum_{t}^{4} g(z_t|\theta)\cdot r_t</script><p>其主要思路很简单：首先对输入图像做特征提取，得到特征图；然后对于每个查询射线 $q$ ，找到最近的四个像素，将每个像素的相对距离 $\Delta q_t$ 编码后和特征 $z_t$ 组合在一起，得到 $z_t’$ 向量；之后通过一组自注意力块和线性层，直接获得四个权重值。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102145918672.png" alt="image-20231102145918672" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评价指标-4"><a href="#评价指标-4" class="headerlink" title="评价指标"></a>评价指标</h3><p>MAE、IoU、Precision、Recall 以及 F1。</p>
<h2 id="HALS-A-Height-Aware-Lidar-Super-Resolution-Framework-for-Autonomous-Driving"><a href="#HALS-A-Height-Aware-Lidar-Super-Resolution-Framework-for-Autonomous-Driving" class="headerlink" title="HALS: A Height-Aware Lidar Super-Resolution Framework for Autonomous Driving"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2202.03901">HALS: A Height-Aware Lidar Super-Resolution Framework for Autonomous Driving</a></h2><p>无代码。但这一篇写得很详细，有比较多的分析和对过往方法的总结。</p>
<h3 id="方法-2"><a href="#方法-2" class="headerlink" title="方法"></a>方法</h3><p>作者认为距离图像的上下部分具有不同的高度分布规律，即上部分距离较远，方差较大，下部分距离较进，方差较小。这意味着上部区域具有更广泛的距离值分布，因此具有更高的空间频率。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102152124742.png" alt="image-20231102152124742" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>因此论文在距离图的不同高度使用不同的策略。远处物体被压缩，且通常出现在上方，因此关注小区域；近处物体较大，且通常出现在下方，因此关注较大的区域。所以论文问用两个感受野提取的特征进行上采样，并预测两个感受野的掩码，从而进行加权融合。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102152552051.png" alt="image-20231102152552051" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>DRB 是膨胀残差块，在 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2009.00206">RangeRCNN: Towards Fast and Accurate 3D Object Detection with Range Image Representation</a> 中提出，是专为激光雷达投影后图像设计的。</p>
<blockquote>
<p>不同距离的物体的尺度表现出显着的差异。为了更好地适应不同的尺度并获得更灵活的感受野，我们设计了膨胀残差块（DRB），它将膨胀卷积插入到正常残差块中。</p>
</blockquote>
<p>应用三个具有不同扩张率 $\{1,2,3\}$ 的 $3\times3$ 卷积来提取具有不同感受野的特征。三个扩张卷积的输出被连接起来，然后是一个 1 × 1 卷积，以融合具有不同感受野的特征。残差连接用于添加融合特征和输入特征。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102161906330.png" alt="image-20231102161906330" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>但是作者这里没有说上采样层的结构。最终预测一个 $C+1$ 维的特征图，最后一维作为掩码。两个掩码进行 SoftMax 得到权重。</p>
<h3 id="评价指标-5"><a href="#评价指标-5" class="headerlink" title="评价指标"></a>评价指标</h3><p>EMD、CD、MAE、RMSE、IoU、Precision、Recall、F1。</p>
<h2 id="SGSR-Net-Structure-Semantics-Guided-LiDAR-Super-Resolution-Network-for-Indoor-LiDAR-SLAM"><a href="#SGSR-Net-Structure-Semantics-Guided-LiDAR-Super-Resolution-Network-for-Indoor-LiDAR-SLAM" class="headerlink" title="SGSR-Net: Structure Semantics Guided LiDAR Super-Resolution Network for Indoor LiDAR SLAM"></a><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/10164213">SGSR-Net: Structure Semantics Guided LiDAR Super-Resolution Network for Indoor LiDAR SLAM</a></h2><h3 id="CASE-模块"><a href="#CASE-模块" class="headerlink" title="CASE 模块"></a>CASE 模块</h3><p>为了缓解物体边界周围的边缘膨胀和混合，采用了 squeeze and excitation 方法和注意力机制结合。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102172250213.png" alt="image-20231102172250213" style="zoom:70%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>具体来说，对于输入的特征图 $(C\times H \times W)$ 做平均池化，得到压缩的特征 $(C\times 1\times W)$ ，再通过卷积将特征压缩到 $C/r’$ ，随后对特征图做批量归一化，并输入 sigmoid 得到注意力权重 $(C/r’ \times 1\times W)$ ，将其和原始特征矩阵相乘（没看懂咋乘的）。整体结构依然是 U-Net 。将 CASE 模块放在最前面，以避免在 Dropout 中丢失必要的信息。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103094427059.png" alt="image-20231103094427059" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="SGR-模块"><a href="#SGR-模块" class="headerlink" title="SGR 模块"></a>SGR 模块</h3><p>这部分主要是针对室内点云的特性，做一些简单的分割以引入语义信息。</p>
<p>首先统计单帧点云的 $z$ 值直方图，找出频率最高的两个，作为地面和天花板的高度 $h_{floor},h_{ceiling}$ 。为了提升相邻帧检测的一致性，取前后 $N$ 帧的中值滤波结果。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103110455119.png" alt="image-20231103110455119" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>估计 $h_{floor},h_{ceiling}$ 的主要原因是，在 MC-Dropout 估计不确定度时，天花板和地面的点距离传感器较远，容易得到较低的置信度，但对于室内场景这些点至关重要。因此对于不同的高度采用不同的系数 $\lambda(h)$ ，再和方差相乘得到置信度。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103113108059.png" alt="image-20231103113108059" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评价指标-6"><a href="#评价指标-6" class="headerlink" title="评价指标"></a>评价指标</h3><p>RMSE、MAR、z RMSE（垂直方向上的误差），以及应用到 SLAM 算法中的评估结果（Mean、RMSE、SSE、STD、最大漂移和相对误差）。</p>
<h3 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h3><p>MC-Dropout 或其它删除不确定点的操作有利于 SLAM 的结果更稳定。</p>
<h1 id="TULIP-Transformer-for-Upsampling-of-LiDAR-Point-Clouds"><a href="#TULIP-Transformer-for-Upsampling-of-LiDAR-Point-Clouds" class="headerlink" title="TULIP: Transformer for Upsampling of LiDAR Point Clouds"></a><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.06733.pdf">TULIP: Transformer for Upsampling of LiDAR Point Clouds</a></h1><p>暂时没有开源。其中的实验和结论值得学习。</p>
<h2 id="方法-3"><a href="#方法-3" class="headerlink" title="方法"></a>方法</h2><p>网络建立在 Swin-Unet 基础上，其中主要使用了 Swin Transformer 块。</p>
<p><img src="/image-20231213141040063.png" alt="image-20231213141040063" style="zoom:50%;"></p>
<h3 id="SWIN-Transformer"><a href="#SWIN-Transformer" class="headerlink" title="SWIN-Transformer"></a>SWIN-Transformer</h3><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>目前主要的问题包括：</p>
<ol>
<li>现有方法将高分辨率点云下采样，然后进行监督训练，但这意味着无法准确地上采样到更高的分辨率。而使用虚拟数据的方法很难泛化到复杂的真实数据；</li>
<li>由于训练数据中大量存在平面特征，往往将物体表面也拟合成平面；</li>
<li>对于生成的噪声没有合适的约束，容易在非表面区域生成不合理的点。</li>
</ol>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/25c774a139b7d3b25450e00c352cc6d.png" alt="25c774a139b7d3b25450e00c352cc6d" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>

  </article>

  <!-- prev and next -->
  <div class="flex justify-between mt-4 pt-4
    border-t border-[var(--c-sep)] text-sm
    gap-2 text-[var(--c-50)]
  ">
    <div>
      
        <a href="/2023/12/14/%E5%92%8C%E5%BC%A6%E7%90%86%E8%AE%BA/"
          class="
            transition-all
            flex justify-center
            hover:-translate-x-1
            hover:text-[var(--c-80)]
          ">
          <iconify-icon width="20" icon="mingcute:left-fill" data-inline="false">
          </iconify-icon>
          和弦理论笔记（更新中）
        </a>
      
    </div>
    <div>
      
        <a href="/2023/09/17/PU-GAN/"
          class="
            flex 
            justify-center
            hover:translate-x-1 
            transition-transform
            hover:text-[var(--c-100)]
          "
        >
          PU-GAN 论文阅读笔记
          <iconify-icon width="20" icon="mingcute:right-fill" data-inline="false"></iconify-icon>
        </a>
      
    </div>
  </div>

  <!-- comment -->
  <div class="article-comments mt-12">
    

  </div>
</section>
<!-- js inspect -->

<script src="/lib/clipboard.min.js"></script>


<script async src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
  });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>



<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>
  $(document).ready(() => {
    const maraidConfig = {
      theme: "default",
      logLevel: 3,
      flowchart: { curve: "linear" },
      gantt: { axisFormat: "%m/%d/%Y" },
      sequence: { actorMargin: 50 },
    };
    mermaid.initialize(maraidConfig);
  });
</script>



<script src="/lib/fancybox/fancybox.umd.min.js"></script>

<script>
  $(document).ready(() => {
    $('.post-content').each(function(i){
      $(this).find('img').each(function(){
        if ($(this).parent().hasClass('fancybox') || $(this).parent().is('a')) return;
        var alt = this.alt;
        var title = this.title;
        if (alt) $(this).after('<span class="fancybox-alt">' + alt + '</span>');
        if (title) $(this).after('<span class="fancybox-title">' + title + '</span>');
        $(this).wrap('<a class="fancybox-img" href="' + this.src + '" data-fancybox=\"gallery\" data-caption="' + alt + '"></a>')
      });
      $(this).find('.fancybox').each(function(){
        $(this).attr('rel', 'article' + i);
      });
    });

    Fancybox.bind('[data-fancybox="gallery"]', {
        // options
    })
  })
</script>

<!-- tocbot begin -->

<script src="/lib/tocbot/tocbot.min.js"></script>

<script>
  $(document).ready(() => {
      tocbot.init({
        // Where to render the table of contents.
        tocSelector: '.post-toc',
        // Where to grab the headings to build the table of contents.
        contentSelector: '.post-content',
        // Which headings to grab inside of the contentSelector element.
        headingSelector: 'h1, h2, h3',
        // For headings inside relative or absolute positioned containers within content.
        hasInnerContainers: true,
    });
  })
</script>
<!-- tocbot end -->

  </main>
  <footer class="flex flex-col mt-18 mb-12 items-center
  text-[var(--c-50)] text-sm">
  <div class="flex flex-row items-center my-12">
    
    
        
        
            
            
        
        <a class="
            hover:text-[var(--c-theme)]
            hover:bg-[var(--c-20)]
            rounded-lg
            p-2
            my-1
            flex flex-row items-center
            group" title="Github" target="_blank" rel="noopener" href="https://www.github.com/chen-yingfa">
            <iconify-icon width="28" icon="mingcute:github-fill"></iconify-icon>
        </a>
    
        
        
            
            
        
        <a class="
            hover:text-[var(--c-theme)]
            hover:bg-[var(--c-20)]
            rounded-lg
            p-2
            my-1
            flex flex-row items-center
            group" title="ZhiHu" target="_blank" rel="noopener" href="https://www.zhihu.com/people/chen-ying-fa-34">
            <iconify-icon width="28" icon="ri:zhihu-line"></iconify-icon>
        </a>
    
        
        
            
            
        
        <a class="
            hover:text-[var(--c-theme)]
            hover:bg-[var(--c-20)]
            rounded-lg
            p-2
            my-1
            flex flex-row items-center
            group" title="Twitter" target="_blank" rel="noopener" href="https://www.twitter.com/DonnyChan123">
            <iconify-icon width="28" icon="mingcute:social-x-fill"></iconify-icon>
        </a>
    

  </div>
  <!-- busuanzi -->
  <div class="mb-6">
    
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<!-- Busuanzi Analytics -->
<div class="flex flex-col items-center mb-2">
  <div class="flex flex-row items-center">
    <iconify-icon width="16" icon="ic:round-person" width="18"></iconify-icon>
    <span class="mr-1">访客 Visitors: </span>
    <span id="busuanzi_value_site_uv"></span>
  </div>
  <div class="flex flex-row items-center">
    <iconify-icon width="16" icon="carbon:view-filled" width="18"></iconify-icon>
    <span class="mx-1">浏览量 Page Views:</span>
    <span id="busuanzi_value_site_pv"></span>
  </div>
</div>
<!-- End Busuanzi Analytics -->


  </div>
  <!-- copyright -->
  <div class="flex flex-row items-center gap-2">
    <a class="hover:underline"
      target="_blank"
      href="https://creativecommons.org/licenses/by-nc-sa/4.0/"
    >
      CC BY-NC-SA 4.0
    </a>
    <span>© 2022-2024</span>
    <a class="hover:underline"
    href="https://github.com/chen-yingfa" 
    target="_blank" 
    rel="noopener noreferrer">陈英发</a>
  </div>
  <!-- powered by -->
  <div class="flex items-center gap-1">
    <span>Powered by</span>
    <a class="hover:underline" 
    href="https://hexo.io/" target="_blank" rel="noopener noreferrer">Hexo</a>
    <span>&</span>
    <a href="https://github.com/chen-yingfa/hexo-theme-fengye" 
    class="hover:underline"
    target="_blank"
      rel="noopener noreferrer"
      >
      枫叶 Fengye
    </a>
  </div>

</footer>

  <div class="
    back-to-top
    fixed right-6
    z-1024
    -bottom-20
    rounded-lg
    font-bold
    py-1 px-2
    text-[var(--c-80)]
    bg-[var(--c-20)]
    cursor-pointer
    text-center
    drop-shadow-md
  ">
    <span class="flex justify-center items-center text-sm">
      <span id="scrollpercent"><span>0</span> %</span>
      <iconify-icon width="18" icon="mingcute:arrow-to-up-fill" id="go-top"></iconify-icon>
    </span>
  </div>
  
<script src="/js/main.js"></script>


  <div class="fixed top-0 bottom-0 left-0 right-0 pointer-events-none print:hidden" id="maple"></div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
</body>

</html>
