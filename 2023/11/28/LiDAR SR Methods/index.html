

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/whu.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="SGGZCL">
  <meta name="keywords" content="">
  
    <meta name="description" content="激光雷达点云上采样相关论文调研。">
<meta property="og:type" content="article">
<meta property="og:title" content="激光雷达点云上采样调研">
<meta property="og:url" content="http://zcliangyue.github.io/2023/11/28/LiDAR%20SR%20Methods/index.html">
<meta property="og:site_name" content="Zhang Conglang">
<meta property="og:description" content="激光雷达点云上采样相关论文调研。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://zcliangyue.github.io/img/LiUP.png">
<meta property="article:published_time" content="2023-11-28T12:00:00.000Z">
<meta property="article:modified_time" content="2025-07-02T12:58:00.346Z">
<meta property="article:author" content="SGGZCL">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="点云">
<meta property="article:tag" content="论文阅读笔记">
<meta property="article:tag" content="点云上采样">
<meta property="article:tag" content="激光雷达">
<meta property="article:tag" content="研究现状调研">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://zcliangyue.github.io/img/LiUP.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>激光雷达点云上采样调研 - Zhang Conglang</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"zcliangyue.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ZCL&#39;BLOG</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/7.0.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="激光雷达点云上采样调研"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-11-28 20:00" pubdate>
          November 28, 2023 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4.8k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          40 mins
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> views
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">激光雷达点云上采样调研</h1>
            
            
              <div class="markdown-body">
                
                <p>激光雷达点云上采样相关论文调研。</p>
<span id="more"></span>
<h1 id="研究背景">研究背景</h1>
<h2 id="概述">概述</h2>
<p>点云超分辨率关注点云的密度以及几何信息。对于给定的点云 <span class="math inline">\(P\)</span> ，我们希望得到更加密集的点云 <span class="math inline">\(Q\)</span> ，能够描述 <span class="math inline">\(P\)</span> 所在的底层形状。</p>
<p>对于激光雷达点云，这个问题要特殊一些。常规的点云上采样容易受到点云数据不规则特性的困扰，但激光雷达点云具有规则的分布，这受益于激光雷达的环状扫描方式。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231128154333947.png" srcset="/img/loading.gif" lazyload alt="image-20231128154333947" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>鉴于激光雷达的扫描方式，一个自然的想法是将点云投影为球面坐标，即：
<span class="math display">\[
\begin{cases}
\begin{aligned}
\varphi &amp;= \arctan\left(z\big/\sqrt{x^2+y^2} \right) \\
\theta &amp;= \arctan(y/x)\\
d  &amp;=\sqrt{x^2+y^2+z^2}
\end{aligned}
\end{cases}
\]</span> 此时在 <span class="math inline">\(\varphi-\theta\)</span>
平面上，点的分布是规则的，这有利于后续的栅格化和上采样。使用这种投影的上采样方法通常总结为基于格网的方法。</p>
<p>需要注意的是，有的激光雷达点云在垂直方向上并不均匀分布，例如 <a target="_blank" rel="noopener" href="https://hesaiweb2019.blob.core.chinacloudapi.cn/uploads/Pandar64_产品手册_640-zh-230510.pdf">Pandar64</a>
将 <span class="math inline">\(3/4\)</span> 的线束集中在了 <span class="math inline">\((-6°,+2°)\)</span> ，而垂直视场角为 <span class="math inline">\((-25°,+15°)\)</span>
，但这样的激光雷达目前还不多见。</p>
<h2 id="问题描述">问题描述</h2>
<p>对于点云 <span class="math inline">\(P\)</span>
，可将其记作一系列扫描线的集合，即 <span class="math inline">\(P=\{L_i
\, |i=1,2,\dots,N_P\}\)</span> ，其中 <span class="math display">\[
L_i=\left\{(x,y,z)\in P \,
\middle|\arctan\left(z\big/\sqrt{x^2+y^2}\right)=\varphi_i \right\},
\]</span> 表示第 <span class="math inline">\(i\)</span>
条扫描线，我们希望预测点云 <span class="math inline">\(Q=\{L_i \,
|i=1,2,\dots,N_Q\}\)</span> ，满足 <span class="math inline">\(N_Q&gt;N_P\)</span> ，且保有 <span class="math inline">\(P\)</span>
的几何特征和扫描线结构。同时我们希望点云 <span class="math inline">\(Q\)</span> 在同样的下游算法上表现出优于 <span class="math inline">\(P\)</span> 的性能。</p>
<h1 id="研究现状">研究现状</h1>
<h2 id="cnn-based-synthesis-of-realistic-high-resolution-lidar-data"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1907.00787">CNN-based synthesis of realistic
high-resolution LiDAR data</a></h2>
<h3 id="上采样">上采样</h3>
<p>下图展示了网络的总体框架。对于低分辨率图像，其特征提取步骤通过一系列残差块执行，上采样则通过转置卷积（文中称分数跨步卷积）实现。在第一层和最后一层使用了
<span class="math inline">\(9\times 9\)</span> 的卷积，中间残差块中都是
<span class="math inline">\(3\times 3\)</span> 。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031175129278.png" srcset="/img/loading.gif" lazyload alt="image-20231031175129278" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="修正的逐点损失函数">修正的逐点损失函数</h3>
<p>论文考虑到图像中大量存在的缺失点，将 <span class="math inline">\(\mathcal{L}_1、\mathcal{L}_2\)</span>
损失修正为只对比非缺失点，记作集合 <span class="math inline">\(V\subset
I\)</span> ，即： <span class="math display">\[
\mathcal{L}_d^\alpha = \sum_{(i,j)\in V}\left| d_{ij}-\hat{d}_{ij}
\right|^{\alpha},\alpha=1,2
\]</span></p>
<h3 id="感知损失">感知损失</h3>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031190341496.png" srcset="/img/loading.gif" lazyload alt="image-20231031190341496" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>逐点损失鼓励图像输出较为平滑的结果，因为它表示了平均误差。同时逐点损失只能在像素层面比较，无法获取高频信息。因此有许多方法使用感知模块来表征损失，使生成的图像更真实。论文采用了一个预训练好的特征提取器
<span class="math inline">\(\phi\)</span>
，将预测图和实际图作为输入，并计算每一层的损失： <span class="math display">\[
\mathcal{L}_{f}=\sum_{c}\sum_{(i,j)\in I}\left|
\phi_c(d)_{ij}-\phi_c(\hat{d})_{ij} \right|
\]</span> 其中 <span class="math inline">\(\phi_c\)</span> 对应了前
<span class="math inline">\(c\)</span> 层特征提取器。</p>
<h3 id="语义一致性损失">语义一致性损失</h3>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031194443752.png" srcset="/img/loading.gif" lazyload alt="image-20231031194443752" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>语义一致性损失则利用了语义分割网络，以交叉熵方式比较两次扫描。对每个点预测一个语义类别概率，并和真值（one-hot
编码）进行比较，得到交叉熵损失 <span class="math inline">\(\mathcal{L}_{ce}\)</span>
。但仅有交叉熵损失无法约束点云的几何结构，因此通过可训练的权重参数将两个损失整合在一起：
<span class="math display">\[
\mathcal{L}_{sc}=\frac{1}{2\sigma_r^2}\mathcal{L}_{d}^{1}+\frac{1}{\sigma_c^2}\mathcal{L}_{ce}+\log\sigma_r+\log\sigma_c
\]</span> 这一结果来自 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1705.07115">Multi-Task Learning Using
Uncertainty to Weigh Losses for Scene Geometry and Semantics</a>
，它通过对数似然推导了语义损失和回归损失的整合，但论文这里似乎把正则项抄错了（丢了两个平方）。</p>
<h3 id="评估指标">评估指标</h3>
<p>MAE, MSE, mIoU 以及问卷投票。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/CNN-based-result.png" srcset="/img/loading.gif" lazyload alt="CNN-based-result" style="zoom:30%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="结论">结论</h3>
<p>论文只实现了两倍上采样，从实验结果来看，使用逐点损失的 MAE 和 MSE
最高，使用感知损失的 mIoU
最高，使用语义的效果不好。但这些结论几乎没什么帮助。</p>
<h2 id="simulation-based-lidar-super-resolution-for-ground-vehicles"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2004.05242">Simulation-based Lidar
Super-resolution for Ground Vehicles</a></h2>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/RobustFieldAutonomyLab/lidar_super_resolution">lidar-super-resolution</a></p>
<h3 id="方法">方法</h3>
<p>第一篇开源的工作，也是该任务下被引最多的。其思路很简单：带有转置卷积的
U-Net 用于重建深度，蒙特卡洛 Dropout 用于克服噪声值。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231031204141231.png" srcset="/img/loading.gif" lazyload alt="image-20231031204141231" style="zoom:27%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>MC-Dropout 的想法是：在测试阶段也应用 Dropout
进行多次预测，从而获取多个不同的值。相当于将多个子网络的预测进行集成。对于多次预测变化较大的点，输出较低的置信度，并取平均值作为最终预测值。<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.02142">Dropout as a Bayesian
Approximation: Representing Model Uncertainty in Deep Learning</a>
论证了 MC-Dropout 可以被看作高斯过程中的近似贝叶斯推理，表达为下式：
<span class="math display">\[
p(y^*|\mathbf{x}^*,\mathcal{D})\propto \int
p(y^*|\theta^*)p(\mathbf{x}^*,\mathcal{D}|\theta^*)\mathrm{d}\theta^*
\\
\Downarrow
\\
p(y^*|\mathbf{x}^*)=\frac{1}{T}\sum_{t=1}^{T}p(y^*|\mathbf{x}^*,\theta^*_t)
\]</span> MC-Dropout 在直觉上接近机器学习中的
Bagging，但它只需要一个模型。论文实验了有无 MC-Dropout
的两种效果，认为它对减少噪声有很大帮助。</p>
<center class="half">
<img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101133538701.png" srcset="/img/loading.gif" lazyload alt="image-20231031204141231" style="zoom:50%;">
<img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101140717153.png" srcset="/img/loading.gif" lazyload alt="image-20231101140717153" style="zoom:50%;">
</center>
<h3 id="评价指标">评价指标</h3>
<p>通过生成预测点和 ground truth 的占用地图，绘制 ROC 曲线以及 AUC
的值。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231128173836966.png" srcset="/img/loading.gif" lazyload alt="image-20231128173836966" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>
<h2 id="t-unet-a-novel-tc-based-point-cloud-super-resolution-model-for-mechanical-lidar"><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-030-92635-9_40">T-UNet:
A Novel TC-Based Point Cloud Super-Resolution Model for Mechanical
LiDAR</a></h2>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/donkeyofking/lidar-sr">donkeyofking/lidar-sr</a>
。其主要思路是利用点云帧序列，而非单帧点云。</p>
<h3 id="方法-1">方法</h3>
<ul>
<li>首先将 <span class="math inline">\(16\)</span>
帧序列点云分别通过转置卷积进行上采样。将相邻两个特征图拼接，并通过（膨胀）卷积提取特征。论文用膨胀卷积取代了池化层，以减少信息的丢失。</li>
<li>重复上述步骤，直至得到一个特征图。然后通过一系列的转置卷积上采样，并和之前的特征图连接，这里和
U-Net 的结构相同。</li>
<li>采用 SSIM 作为损失函数。</li>
</ul>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101154818026.png" srcset="/img/loading.gif" lazyload alt="image-20231101154818026" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评价指标-1">评价指标</h3>
<p>峰值信噪比 (PNSR), MSE, 结构相似性指数 (SSIM)。</p>
<h2 id="channel-attention-based-network-for-lidar-super-resolution"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9727846">Channel Attention
based Network for LiDAR Super-resolution</a></h2>
<p>无代码。网络架构由一个 U-Net 和一个基于通道注意力的重建块组成。</p>
<h3 id="基于通道注意力的重建块">基于通道注意力的重建块</h3>
<p>从图中看到，首先是两个转置卷积上采样四倍，然后就是不断复用卷积层和通道注意力模块，并使用残差连接。最后用两个卷积层回归深度值，并和
U-Net 提取的信息逐点相加。论文希望 U-Net
能够捕获边缘信息，使重建更准确（但是并没有对提取边缘这一点做监督或者约束，比较奇怪，可能是玄学吧）。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101160136946.png" srcset="/img/loading.gif" lazyload alt="image-20231101160136946" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>通道注意力的结构就是最基本的自注意力机制，它关注不同通道之间的相关性（原文却说“每个通道上相邻像素之间的相关性”，可能是笔误）。首先将图像特征
<span class="math inline">\(C\times V \times H\)</span> 展平成 <span class="math inline">\(C\times VH\)</span> 的特征，和 <span class="math inline">\(VH \times C\)</span> 的矩阵执行点积，通过 SoftMax
得到 <span class="math inline">\(C\times C\)</span>
的注意力矩阵，然后和原来的特征矩阵相乘，得到新的特征图。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101160511380.png" srcset="/img/loading.gif" lazyload alt="image-20231101160511380" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="环形填充">环形填充</h3>
<p>球面投影需要一个角度来分割投影图，然后展平，因此在分割处提取不到真实的局部特征。论文的方法很简单，就是把图像往两边
padding，补充回丢掉的局部信息。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101163539525.png" srcset="/img/loading.gif" lazyload alt="image-20231101163539525" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评估指标-1">评估指标</h3>
<p>只采用了一个 MAE 。</p>
<h2 id="lidar-super-resolution-based-on-segmentation-and-geometric-analysis"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9875347">LiDAR
Super-Resolution Based on Segmentation and Geometric Analysis</a></h2>
<p>无代码。这是一个步骤较多的无监督方法，并且基于点而非格网，但采用的是球面投影，因此同样保留扫描线结构。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101164701852.png" srcset="/img/loading.gif" lazyload alt="image-20231101164701852" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="地面点分割">地面点分割</h3>
<p>这一步骤在 <span class="math inline">\(xyz\)</span>
坐标上进行，更准确的说，在每一列扫描线上进行。</p>
<p>对于输入点 <span class="math inline">\(P_l\)</span>
，目标是分割得到地面点 <span class="math inline">\(P_g\)</span>
和非地面点 <span class="math inline">\(P_{ng}\)</span>
。考虑一列扫描点，点分布如下图所示。</p>
<ul>
<li>首先找到 <span class="math inline">\(z\)</span>
值最小的点，向两边顺序搜索，得到相邻点的向量 <span class="math inline">\(V_l\)</span>
；同时从最低点出发，连接所有点，得到向量 <span class="math inline">\(V_r\)</span> ；</li>
<li>求向量点积 <span class="math inline">\(V_l \cdot V_r\)</span>
，并通过点积的绝对值选取种子点（论文这里讲得不太清楚，应该就是求向量夹角）。最后通过一个
<span class="math inline">\(z\)</span> 值的低通滤波得到地面种子点；</li>
<li>基于种子点，利用最小二乘拟合一条直线，将距离直线一定阈值内的点纳入地面点，其余点纳入非地面点。对一圈的点执行上述操作，实现分割。</li>
</ul>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101170403255.png" srcset="/img/loading.gif" lazyload alt="image-20231101170403255" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="坐标重组">坐标重组</h3>
<p>坐标重组就是球面投影。但论文这里没有采用栅格化为图像的方式，而是保留三维坐标
<span class="math inline">\((h,v,d)\)</span> ，避免了任何信息损失。其中
<span class="math inline">\(h,v\)</span> 分别表示水平角和垂直角，<span class="math inline">\(d\)</span> 表示距离。</p>
<h3 id="超分辨率">超分辨率</h3>
<p>针对地面点和非地面点，采用两种上采样思路。</p>
<h4 id="地面点上采样">地面点上采样</h4>
<p>将地面点视作平面，若上下两个像素都是地面点，则考虑三角形角平分线的性质。这里的推导很简单，设前后两个点的球面坐标分别为：
<span class="math display">\[
\begin{cases}
p_A = [I_i\cdot H_{\textrm{res}},a,v_1]
\\
p_B = [I_i\cdot H_{\textrm{res}},b,v_5]
\end{cases}
\]</span> 则 <span class="math inline">\(v_3=(v_1+v_5)/2\)</span>
，只需求 <span class="math inline">\(OD\)</span> 的长度，结果如下：
<span class="math display">\[
d = \frac{2ab}{a+b}\cos\frac{\alpha}{2}
\]</span>
<img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101170807215.png" srcset="/img/loading.gif" lazyload alt="image-20231101170807215" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>地面点还有一个优化，大致是对空缺点进行了讨论，然后用局部的平滑细化点。</p>
<h4 id="非地面点上采样">非地面点上采样</h4>
<p>从俯视图上，观察到非地面点呈现簇的分布，即同一物体的点之间相距较进。简单聚类后对每个物体进行上采样，将点分为物体内的点和物体间的点。对于物体间的点，由于缺乏先验知识，无法归类，为了提升远处物体的点数量，论文直接将其归到更远的物体上。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231101172953666.png" srcset="/img/loading.gif" lazyload alt="image-20231101172953666" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评价指标-2">评价指标</h3>
<p>Hasdorff 距离和 CD 。</p>
<h2 id="fast-point-clouds-upsampling-with-uncertainty-quantification-for-autonomous-vehicles"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9811914">Fast Point Clouds
Upsampling with Uncertainty Quantification for Autonomous
Vehicles</a></h2>
<p>无代码。基本思路是用神经过程（NP）取代了
MC-Dropout，去实现更快速的不确定性量化。MC-Dropout
需要多次前向推理，会比较占用资源。从它的输出结果来看，不确定性较大的点依然是集中在边缘区域。</p>
<h3 id="使用-conv-nps-的上采样">使用 Conv-NPs 的上采样</h3>
<p>对于低分辨率图像，论文用空白的掩码 <span class="math inline">\(M_c\)</span>
替代了转置卷积，直接增加图像的行数。与之对应的有 <span class="math inline">\(M_t\)</span> ，表示已知的部分。 <span class="math display">\[
M_c(i,j)=\begin{cases}
\begin{aligned}
1&amp;, \text{if} \ \ (r_{up}|i)
\\
0&amp;, \text{otherwise}
\end{aligned}
\end{cases}
\]</span>
后续的方法分为四个模块。首先通过特征提取器，分别从掩码和扩大后的图像中提取特征图，并连接在一起。
<span class="math display">\[
\begin{cases}
e=\zeta(M_c)\in \mathbb{R}^{U_{\mathcal{H}}\times V_{\mathcal{H}}\times
K}
\\
e&#39;=\zeta(\mathcal{I_P})\in \mathbb{R}^{U_{\mathcal{H}}\times
V_{\mathcal{H}}\times K}
\\
\end{cases}
\Rightarrow
\epsilon=e \oplus e&#39;
\]</span> 通过通过卷积层聚合邻域特征： <span class="math display">\[
e_C = \gamma(\epsilon)\in \mathbb{R}^{U_{\mathcal{H}}\times
V_{\mathcal{H}}\times 2}
\]</span> 再由掩码 <span class="math inline">\(M_t\)</span> 和特征 <span class="math inline">\(e_C\)</span> 预测一组高斯分布： <span class="math display">\[
v=(\mu, \sigma)=\Phi(M_t,e_C)
\]</span> 得到了均值图像和方差图像，从而滤除不确定性较大的点。</p>
<h3 id="损失函数">损失函数</h3>
<p>由于输出了不确定性，实际上估计的是一个高斯分布。因此有<strong>条件负对数似然</strong>损失：
<span class="math display">\[
Loss = -\mathbb{E}_{\mathcal{D}}\left[ \frac{1}{U_{\mathcal{H}}\times
V_{\mathcal{H}}}\sum_{i,j}\log p_{i,j}(r_{i,j}^{g}|v_{i,j})\right]
\]</span> 其中 <span class="math inline">\(r_{i,j}^{g}\)</span>
表示像素点 <span class="math inline">\((i,j)\)</span> 上的真实距离。</p>
<h3 id="评价指标-3">评价指标</h3>
<p>仅适用了 MAE 。</p>
<h2 id="implicit-lidar-network-lidar-super-resolution-via-interpolation-weight-prediction"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.06413">Implicit LiDAR Network: LiDAR
Super-Resolution via Interpolation Weight Prediction</a></h2>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/PinocchioYS/iln">PinocchioYS/iln</a>
。整体思路比较简单，对于任意一条查询射线，对其四个邻域点的特征进行注意力，求得权重，然后对距离加权。ILN
是第一个实现任意分辨率的，并且无需不确定性量化。</p>
<h3 id="liif">LIIF</h3>
<p>LIIF 是这篇文章的灵感来源，发表在 CVPR2021 。对于二维特征图 <span class="math inline">\(M \in \mathbb{R}^{H\times W\times D}\)</span>
，定义一个对于所有图像相同的解码器 <span class="math inline">\(f_\theta\)</span> ，其作用为： <span class="math display">\[
s=f_\theta(z,x)
\]</span> 其中 <span class="math inline">\(z\)</span> 是一个向量，<span class="math inline">\(x\in \mathcal{X}\)</span> 是一个二维坐标，<span class="math inline">\(s\)</span> 为预测信号（通常为 RGB 值）。因此每一个
<span class="math inline">\(z\)</span> 对应了一个函数，即： <span class="math display">\[
z\mapsto f_\theta(z,\cdot):\mathcal{X}\rightarrow\mathcal{S},
\]</span>
假设特征向量在二维空间均匀分布，为每一个特征分配一个二维坐标。对于连续图像
<span class="math inline">\(I(i)\)</span> ，坐标 <span class="math inline">\(x_q\)</span> 处的 RGB 值定义为： <span class="math display">\[
I(x_q)=f_\theta(z^*, x_q-v^*),
\]</span> 其中 <span class="math inline">\(z^{*}\)</span> 是距离 <span class="math inline">\(x_q\)</span> 最近的一个特征向量，<span class="math inline">\(v\)</span> 是对应的坐标。</p>
<p>简而言之，对于任何一个需要预测的位置，找到离它最近的那个已知点，将该点的特征以及距离送入一个网络，输出预测值。仅此而已。这就好比点云上采样时，从一个点出发生成一系列点。</p>
<p>但这样做还不够，因为一个特征过于单调。论文使用了一个叫“特征展开”的步骤，将
<span class="math inline">\(M\)</span> 中每个位置的 <span class="math inline">\(3\times 3\)</span> 邻域串联起来，得到新的特征图：
<span class="math display">\[
M_{jk}=\text{Concat}(\{M_{j+l,k+m}\}_{l,m \in \{-1,0,1\}}),
\]</span> 此外，由于两个像素连线中点处，会发生“跳变”的情况，因为 <span class="math inline">\(z^*\)</span>
发生了变化。为保证预测的连续性，将预测图像改写为： <span class="math display">\[
I(x_q)=\sum_{t\in \{00,01,10,11\}}\frac{S_t}{S}\cdot f_\theta(z^*_t,
x_q-v^*_t),
\]</span> 也就是将最近的四个像素的预测值取加权平均。权重系数和 <span class="math inline">\(x_q\)</span> 到 <span class="math inline">\(v^*_t\)</span> 构成的矩形面积 <span class="math inline">\(S_t\)</span> 成正比。</p>
<p>除此之外还不够，由于 <span class="math inline">\(f_\theta\)</span>
预测了一个离散点的值，而我们实际上想要生成一个像素的值。这类似于 NeRF 与
Mip-NeRF 的区别，论文将像素的范围考虑在内，即： <span class="math display">\[
s=f_{cell}(z,[x,c])
\]</span> 其中 <span class="math inline">\(c=[c_h,c_w]\)</span>
，表示查询像素的大小。</p>
<h3 id="iln">ILN</h3>
<p>LIIF 通过周边信息直接预测了值，而 ILN
尝试预测权重，以在距离图像上取得比较稳定的效果。在 LIIF
中，权重是可以直接计算的。记权重函数为 <span class="math inline">\(h\)</span> ，值函数为 <span class="math inline">\(g\)</span> ，则 LIIF 可以表示为： <span class="math display">\[
\hat{r}=\sum_{t}^{4}g(\cdot)h(\cdot
|\theta)=\sum_{t}^{4}\frac{S_t}{S}\cdot h(z_t|\theta)
\]</span> 为了直接利用周边点的距离值，ILN 直接预测权重： <span class="math display">\[
\hat{r}=\sum_{t}^{4}g(\cdot |\theta)h(\cdot )=\sum_{t}^{4}
g(z_t|\theta)\cdot r_t
\]</span>
其主要思路很简单：首先对输入图像做特征提取，得到特征图；然后对于每个查询射线
<span class="math inline">\(q\)</span>
，找到最近的四个像素，将每个像素的相对距离 <span class="math inline">\(\Delta q_t\)</span> 编码后和特征 <span class="math inline">\(z_t\)</span> 组合在一起，得到 <span class="math inline">\(z_t&#39;\)</span>
向量；之后通过一组自注意力块和线性层，直接获得四个权重值。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102145918672.png" srcset="/img/loading.gif" lazyload alt="image-20231102145918672" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评价指标-4">评价指标</h3>
<p>MAE、IoU、Precision、Recall 以及 F1。</p>
<h2 id="hals-a-height-aware-lidar-super-resolution-framework-for-autonomous-driving"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2202.03901">HALS: A Height-Aware Lidar
Super-Resolution Framework for Autonomous Driving</a></h2>
<p>无代码。但这一篇写得很详细，有比较多的分析和对过往方法的总结。</p>
<h3 id="方法-2">方法</h3>
<p>作者认为距离图像的上下部分具有不同的高度分布规律，即上部分距离较远，方差较大，下部分距离较进，方差较小。这意味着上部区域具有更广泛的距离值分布，因此具有更高的空间频率。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102152124742.png" srcset="/img/loading.gif" lazyload alt="image-20231102152124742" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>因此论文在距离图的不同高度使用不同的策略。远处物体被压缩，且通常出现在上方，因此关注小区域；近处物体较大，且通常出现在下方，因此关注较大的区域。所以论文问用两个感受野提取的特征进行上采样，并预测两个感受野的掩码，从而进行加权融合。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102152552051.png" srcset="/img/loading.gif" lazyload alt="image-20231102152552051" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>DRB 是膨胀残差块，在 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2009.00206">RangeRCNN: Towards Fast and
Accurate 3D Object Detection with Range Image Representation</a>
中提出，是专为激光雷达投影后图像设计的。</p>
<blockquote>
<p>不同距离的物体的尺度表现出显着的差异。为了更好地适应不同的尺度并获得更灵活的感受野，我们设计了膨胀残差块（DRB），它将膨胀卷积插入到正常残差块中。</p>
</blockquote>
<p>应用三个具有不同扩张率 <span class="math inline">\(\{1,2,3\}\)</span>
的 <span class="math inline">\(3\times3\)</span>
卷积来提取具有不同感受野的特征。三个扩张卷积的输出被连接起来，然后是一个
1 × 1
卷积，以融合具有不同感受野的特征。残差连接用于添加融合特征和输入特征。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102161906330.png" srcset="/img/loading.gif" lazyload alt="image-20231102161906330" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>但是作者这里没有说上采样层的结构。最终预测一个 <span class="math inline">\(C+1\)</span>
维的特征图，最后一维作为掩码。两个掩码进行 SoftMax 得到权重。</p>
<h3 id="评价指标-5">评价指标</h3>
<p>EMD、CD、MAE、RMSE、IoU、Precision、Recall、F1。</p>
<h2 id="sgsr-net-structure-semantics-guided-lidar-super-resolution-network-for-indoor-lidar-slam"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/10164213">SGSR-Net: Structure
Semantics Guided LiDAR Super-Resolution Network for Indoor LiDAR
SLAM</a></h2>
<h3 id="case-模块">CASE 模块</h3>
<p>为了缓解物体边界周围的边缘膨胀和混合，采用了 squeeze and excitation
方法和注意力机制结合。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231102172250213.png" srcset="/img/loading.gif" lazyload alt="image-20231102172250213" style="zoom:70%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>具体来说，对于输入的特征图 <span class="math inline">\((C\times H
\times W)\)</span> 做平均池化，得到压缩的特征 <span class="math inline">\((C\times 1\times W)\)</span>
，再通过卷积将特征压缩到 <span class="math inline">\(C/r&#39;\)</span>
，随后对特征图做批量归一化，并输入 sigmoid 得到注意力权重 <span class="math inline">\((C/r&#39; \times 1\times W)\)</span>
，将其和原始特征矩阵相乘（没看懂咋乘的）。整体结构依然是 U-Net 。将 CASE
模块放在最前面，以避免在 Dropout 中丢失必要的信息。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103094427059.png" srcset="/img/loading.gif" lazyload alt="image-20231103094427059" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="sgr-模块">SGR 模块</h3>
<p>这部分主要是针对室内点云的特性，做一些简单的分割以引入语义信息。</p>
<p>首先统计单帧点云的 <span class="math inline">\(z\)</span>
值直方图，找出频率最高的两个，作为地面和天花板的高度 <span class="math inline">\(h_{floor},h_{ceiling}\)</span>
。为了提升相邻帧检测的一致性，取前后 <span class="math inline">\(N\)</span> 帧的中值滤波结果。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103110455119.png" srcset="/img/loading.gif" lazyload alt="image-20231103110455119" style="zoom:50%;display: block; margin-left: auto; margin-right: auto;"></p>
<p>估计 <span class="math inline">\(h_{floor},h_{ceiling}\)</span>
的主要原因是，在 MC-Dropout
估计不确定度时，天花板和地面的点距离传感器较远，容易得到较低的置信度，但对于室内场景这些点至关重要。因此对于不同的高度采用不同的系数
<span class="math inline">\(\lambda(h)\)</span>
，再和方差相乘得到置信度。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231103113108059.png" srcset="/img/loading.gif" lazyload alt="image-20231103113108059" style="zoom:80%;display: block; margin-left: auto; margin-right: auto;"></p>
<h3 id="评价指标-6">评价指标</h3>
<p>RMSE、MAR、z RMSE（垂直方向上的误差），以及应用到 SLAM
算法中的评估结果（Mean、RMSE、SSE、STD、最大漂移和相对误差）。</p>
<h3 id="结论-1">结论</h3>
<p>MC-Dropout 或其它删除不确定点的操作有利于 SLAM 的结果更稳定。</p>
<h2 id="tulip-transformer-for-upsampling-of-lidar-point-clouds"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.06733.pdf">TULIP: Transformer for
Upsampling of LiDAR Point Clouds</a></h2>
<p>暂时没有开源。其中的实验和结论值得学习。</p>
<h2 id="方法-3">方法</h2>
<p>网络建立在 Swin-Unet 基础上，其中主要使用了 Swin Transformer 块。</p>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/image-20231213141040063.png" srcset="/img/loading.gif" lazyload alt="image-20231213141040063" style="zoom:50%;"></p>
<h3 id="swin-transformer">SWIN-Transformer</h3>
<h1 id="总结">总结</h1>
<p>目前主要的问题包括：</p>
<ol type="1">
<li>现有方法将高分辨率点云下采样，然后进行监督训练，但这意味着无法准确地上采样到更高的分辨率。而使用虚拟数据的方法很难泛化到复杂的真实数据；</li>
<li>由于训练数据中大量存在平面特征，往往将物体表面也拟合成平面；</li>
<li>对于生成的噪声没有合适的约束，容易在非表面区域生成不合理的点。</li>
</ol>
<p><img src="/2023/11/28/LiDAR%20SR%20Methods/25c774a139b7d3b25450e00c352cc6d.png" srcset="/img/loading.gif" lazyload alt="25c774a139b7d3b25450e00c352cc6d" style="zoom:40%;display: block; margin-left: auto; margin-right: auto;"></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="print-no-link">#神经网络</a>
      
        <a href="/tags/%E7%82%B9%E4%BA%91/" class="print-no-link">#点云</a>
      
        <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" class="print-no-link">#论文阅读笔记</a>
      
        <a href="/tags/%E7%82%B9%E4%BA%91%E4%B8%8A%E9%87%87%E6%A0%B7/" class="print-no-link">#点云上采样</a>
      
        <a href="/tags/%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE/" class="print-no-link">#激光雷达</a>
      
        <a href="/tags/%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E8%B0%83%E7%A0%94/" class="print-no-link">#研究现状调研</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>激光雷达点云上采样调研</div>
      <div>http://zcliangyue.github.io/2023/11/28/LiDAR SR Methods/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>SGGZCL</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>November 28, 2023</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>July 2, 2025</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/12/14/%E6%8A%BD%E8%B1%A1%E4%BB%A3%E6%95%B0/" title="抽象代数笔记">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">抽象代数笔记</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/09/27/%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86/" title="个人简历">
                        <span class="hidden-mobile">个人简历</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
